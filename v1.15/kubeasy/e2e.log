I0831 14:20:57.799248      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-059459328
I0831 14:20:57.799508      15 e2e.go:243] Starting e2e run "68fb4d2d-b539-438f-85a2-f443177f1af7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1661955657 - Will randomize all specs
Will run 215 of 4413 specs

Aug 31 14:20:57.865: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:20:57.866: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug 31 14:20:57.877: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug 31 14:20:57.891: INFO: 7 / 7 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug 31 14:20:57.892: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Aug 31 14:20:57.892: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug 31 14:20:57.895: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Aug 31 14:20:57.895: INFO: e2e test version: v1.15.12
Aug 31 14:20:57.896: INFO: kube-apiserver version: v1.15.12
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:20:57.896: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
Aug 31 14:20:57.913: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug 31 14:20:57.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-6429'
Aug 31 14:20:58.137: INFO: stderr: ""
Aug 31 14:20:58.137: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:20:58.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6429'
Aug 31 14:20:58.204: INFO: stderr: ""
Aug 31 14:20:58.204: INFO: stdout: "update-demo-nautilus-65ph2 update-demo-nautilus-c896d "
Aug 31 14:20:58.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-65ph2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:20:58.257: INFO: stderr: ""
Aug 31 14:20:58.257: INFO: stdout: ""
Aug 31 14:20:58.257: INFO: update-demo-nautilus-65ph2 is created but not running
Aug 31 14:21:03.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6429'
Aug 31 14:21:03.311: INFO: stderr: ""
Aug 31 14:21:03.312: INFO: stdout: "update-demo-nautilus-65ph2 update-demo-nautilus-c896d "
Aug 31 14:21:03.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-65ph2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:03.359: INFO: stderr: ""
Aug 31 14:21:03.359: INFO: stdout: "true"
Aug 31 14:21:03.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-65ph2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:03.408: INFO: stderr: ""
Aug 31 14:21:03.408: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:21:03.408: INFO: validating pod update-demo-nautilus-65ph2
Aug 31 14:21:03.412: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:21:03.412: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:21:03.412: INFO: update-demo-nautilus-65ph2 is verified up and running
Aug 31 14:21:03.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-c896d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:03.467: INFO: stderr: ""
Aug 31 14:21:03.467: INFO: stdout: "true"
Aug 31 14:21:03.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-c896d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:03.522: INFO: stderr: ""
Aug 31 14:21:03.522: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:21:03.522: INFO: validating pod update-demo-nautilus-c896d
Aug 31 14:21:03.525: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:21:03.525: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:21:03.525: INFO: update-demo-nautilus-c896d is verified up and running
STEP: rolling-update to new replication controller
Aug 31 14:21:03.526: INFO: scanned /root for discovery docs: <nil>
Aug 31 14:21:03.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6429'
Aug 31 14:21:34.873: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 31 14:21:34.873: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:21:34.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6429'
Aug 31 14:21:34.923: INFO: stderr: ""
Aug 31 14:21:34.923: INFO: stdout: "update-demo-kitten-npdhg update-demo-kitten-pbbm5 "
Aug 31 14:21:34.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-kitten-npdhg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:34.979: INFO: stderr: ""
Aug 31 14:21:34.979: INFO: stdout: "true"
Aug 31 14:21:34.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-kitten-npdhg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:35.027: INFO: stderr: ""
Aug 31 14:21:35.027: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 31 14:21:35.027: INFO: validating pod update-demo-kitten-npdhg
Aug 31 14:21:35.031: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 31 14:21:35.031: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 31 14:21:35.031: INFO: update-demo-kitten-npdhg is verified up and running
Aug 31 14:21:35.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-kitten-pbbm5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:35.085: INFO: stderr: ""
Aug 31 14:21:35.085: INFO: stdout: "true"
Aug 31 14:21:35.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-kitten-pbbm5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6429'
Aug 31 14:21:35.137: INFO: stderr: ""
Aug 31 14:21:35.137: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug 31 14:21:35.137: INFO: validating pod update-demo-kitten-pbbm5
Aug 31 14:21:35.141: INFO: got data: {
  "image": "kitten.jpg"
}

Aug 31 14:21:35.141: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug 31 14:21:35.141: INFO: update-demo-kitten-pbbm5 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:21:35.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6429" for this suite.
Aug 31 14:21:57.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:21:57.220: INFO: namespace kubectl-6429 deletion completed in 22.076029344s

• [SLOW TEST:59.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:21:57.220: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:21:57.272: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c91dea80-4ff9-4032-b1dc-45037188b4db", Controller:(*bool)(0xc0006166e6), BlockOwnerDeletion:(*bool)(0xc0006166e7)}}
Aug 31 14:21:57.280: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"82c652ca-7953-4228-a4c9-0ef8536deb36", Controller:(*bool)(0xc000a6c20e), BlockOwnerDeletion:(*bool)(0xc000a6c20f)}}
Aug 31 14:21:57.292: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"64e6589f-40a8-4a0f-84cb-2caf7800f9cd", Controller:(*bool)(0xc000616b9e), BlockOwnerDeletion:(*bool)(0xc000616b9f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:22:02.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1506" for this suite.
Aug 31 14:22:08.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:22:08.372: INFO: namespace gc-1506 deletion completed in 6.069014681s

• [SLOW TEST:11.152 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:22:08.376: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 31 14:22:08.406: INFO: Waiting up to 5m0s for pod "pod-101b5f0c-8088-4584-b70b-0fbff81db9c4" in namespace "emptydir-4110" to be "success or failure"
Aug 31 14:22:08.411: INFO: Pod "pod-101b5f0c-8088-4584-b70b-0fbff81db9c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.842508ms
Aug 31 14:22:10.415: INFO: Pod "pod-101b5f0c-8088-4584-b70b-0fbff81db9c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.008312886s
Aug 31 14:22:12.418: INFO: Pod "pod-101b5f0c-8088-4584-b70b-0fbff81db9c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011894134s
STEP: Saw pod success
Aug 31 14:22:12.418: INFO: Pod "pod-101b5f0c-8088-4584-b70b-0fbff81db9c4" satisfied condition "success or failure"
Aug 31 14:22:12.421: INFO: Trying to get logs from node vm119042 pod pod-101b5f0c-8088-4584-b70b-0fbff81db9c4 container test-container: <nil>
STEP: delete the pod
Aug 31 14:22:12.440: INFO: Waiting for pod pod-101b5f0c-8088-4584-b70b-0fbff81db9c4 to disappear
Aug 31 14:22:12.442: INFO: Pod pod-101b5f0c-8088-4584-b70b-0fbff81db9c4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:22:12.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4110" for this suite.
Aug 31 14:22:18.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:22:18.511: INFO: namespace emptydir-4110 deletion completed in 6.064736219s

• [SLOW TEST:10.136 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:22:18.512: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 31 14:22:18.535: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 31 14:22:18.540: INFO: Waiting for terminating namespaces to be deleted...
Aug 31 14:22:18.542: INFO: 
Logging pods the kubelet thinks is on node vm119041 before test
Aug 31 14:22:18.547: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-kkc9r from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:18.547: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:18.548: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:18.548: INFO: kube-flannel-ds-r6tpw from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.548: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:18.548: INFO: metrics-server-54cdcdcd69-x5nfx from kube-system started at 2022-08-31 12:10:22 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.548: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 14:22:18.548: INFO: 
Logging pods the kubelet thinks is on node vm119042 before test
Aug 31 14:22:18.555: INFO: kube-flannel-ds-8hj77 from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.555: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:18.555: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-q6p6z from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:18.555: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:18.555: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:18.555: INFO: sonobuoy from sonobuoy started at 2022-08-31 14:20:22 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.555: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 31 14:22:18.555: INFO: 
Logging pods the kubelet thinks is on node vm119043 before test
Aug 31 14:22:18.561: INFO: coredns-545b9dffff-sq27r from kube-system started at 2022-08-31 12:10:06 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.561: INFO: 	Container coredns ready: true, restart count 0
Aug 31 14:22:18.562: INFO: kube-flannel-ds-d9h4h from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.562: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:18.562: INFO: metrics-server-54cdcdcd69-gb9zj from kube-system started at 2022-08-31 12:10:09 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.562: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 14:22:18.562: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-dtglv from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:18.562: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:18.562: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:18.562: INFO: 
Logging pods the kubelet thinks is on node vm119044 before test
Aug 31 14:22:18.574: INFO: sonobuoy-e2e-job-1bebe861b7bb41b0 from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:18.574: INFO: 	Container e2e ready: true, restart count 0
Aug 31 14:22:18.574: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:18.574: INFO: kube-flannel-ds-pgpzl from kube-system started at 2022-08-31 12:43:40 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:18.574: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:18.574: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-sdc9n from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:18.574: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:18.574: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.171073f056e514c0], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:22:19.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5071" for this suite.
Aug 31 14:22:25.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:22:25.661: INFO: namespace sched-pred-5071 deletion completed in 6.06636437s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.149 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:22:25.662: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 31 14:22:25.681: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 31 14:22:25.686: INFO: Waiting for terminating namespaces to be deleted...
Aug 31 14:22:25.688: INFO: 
Logging pods the kubelet thinks is on node vm119041 before test
Aug 31 14:22:25.691: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-kkc9r from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:25.691: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:25.692: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:25.692: INFO: kube-flannel-ds-r6tpw from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.692: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:25.692: INFO: metrics-server-54cdcdcd69-x5nfx from kube-system started at 2022-08-31 12:10:22 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.692: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 14:22:25.692: INFO: 
Logging pods the kubelet thinks is on node vm119042 before test
Aug 31 14:22:25.696: INFO: sonobuoy from sonobuoy started at 2022-08-31 14:20:22 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.697: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 31 14:22:25.697: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-q6p6z from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:25.697: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:25.697: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:25.697: INFO: kube-flannel-ds-8hj77 from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.697: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:25.697: INFO: 
Logging pods the kubelet thinks is on node vm119043 before test
Aug 31 14:22:25.701: INFO: coredns-545b9dffff-sq27r from kube-system started at 2022-08-31 12:10:06 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.701: INFO: 	Container coredns ready: true, restart count 0
Aug 31 14:22:25.701: INFO: kube-flannel-ds-d9h4h from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.701: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:25.701: INFO: metrics-server-54cdcdcd69-gb9zj from kube-system started at 2022-08-31 12:10:09 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.701: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 14:22:25.701: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-dtglv from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:25.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:25.701: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:25.701: INFO: 
Logging pods the kubelet thinks is on node vm119044 before test
Aug 31 14:22:25.706: INFO: kube-flannel-ds-pgpzl from kube-system started at 2022-08-31 12:43:40 +0000 UTC (1 container statuses recorded)
Aug 31 14:22:25.706: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 14:22:25.706: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-sdc9n from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:25.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 14:22:25.706: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 14:22:25.706: INFO: sonobuoy-e2e-job-1bebe861b7bb41b0 from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 14:22:25.706: INFO: 	Container e2e ready: true, restart count 0
Aug 31 14:22:25.706: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fcd1667e-d2a8-4873-95dd-fb53a6d1b24f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fcd1667e-d2a8-4873-95dd-fb53a6d1b24f off the node vm119042
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fcd1667e-d2a8-4873-95dd-fb53a6d1b24f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:22:29.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2489" for this suite.
Aug 31 14:22:57.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:22:57.836: INFO: namespace sched-pred-2489 deletion completed in 28.068275342s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:32.175 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:22:57.837: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 14:24:21.883: INFO: DNS probes using dns-test-e4f5182e-d073-41de-b592-213dc9e5ba78 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 14:24:23.919: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:23.922: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:23.922: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:28.927: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:28.930: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:28.930: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:33.927: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:33.931: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:33.931: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:38.927: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:38.931: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:38.931: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:43.927: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:43.931: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:43.931: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:48.931: INFO: File wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:48.934: INFO: File jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local from pod  dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb contains 'foo.example.com.
' instead of 'bar.example.com.'
Aug 31 14:24:48.934: INFO: Lookups using dns-2996/dns-test-d4afab08-3857-47f9-a994-e7375b55eccb failed for: [wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local]

Aug 31 14:24:53.929: INFO: DNS probes using dns-test-d4afab08-3857-47f9-a994-e7375b55eccb succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2996.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2996.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 14:24:55.989: INFO: DNS probes using dns-test-38104072-6100-4a46-9180-aeee8b32a02a succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:24:56.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2996" for this suite.
Aug 31 14:25:02.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:25:02.076: INFO: namespace dns-2996 deletion completed in 6.065938131s

• [SLOW TEST:124.239 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:25:02.077: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 31 14:25:02.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-7282'
Aug 31 14:25:02.198: INFO: stderr: ""
Aug 31 14:25:02.198: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:25:02.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:02.262: INFO: stderr: ""
Aug 31 14:25:02.263: INFO: stdout: "update-demo-nautilus-kf4lv update-demo-nautilus-rlq2z "
Aug 31 14:25:02.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:02.317: INFO: stderr: ""
Aug 31 14:25:02.317: INFO: stdout: ""
Aug 31 14:25:02.317: INFO: update-demo-nautilus-kf4lv is created but not running
Aug 31 14:25:07.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:07.368: INFO: stderr: ""
Aug 31 14:25:07.368: INFO: stdout: "update-demo-nautilus-kf4lv update-demo-nautilus-rlq2z "
Aug 31 14:25:07.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:07.416: INFO: stderr: ""
Aug 31 14:25:07.416: INFO: stdout: "true"
Aug 31 14:25:07.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:07.468: INFO: stderr: ""
Aug 31 14:25:07.468: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:25:07.468: INFO: validating pod update-demo-nautilus-kf4lv
Aug 31 14:25:07.474: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:25:07.474: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:25:07.474: INFO: update-demo-nautilus-kf4lv is verified up and running
Aug 31 14:25:07.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-rlq2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:07.524: INFO: stderr: ""
Aug 31 14:25:07.524: INFO: stdout: "true"
Aug 31 14:25:07.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-rlq2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:07.577: INFO: stderr: ""
Aug 31 14:25:07.577: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:25:07.577: INFO: validating pod update-demo-nautilus-rlq2z
Aug 31 14:25:07.581: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:25:07.581: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:25:07.581: INFO: update-demo-nautilus-rlq2z is verified up and running
STEP: scaling down the replication controller
Aug 31 14:25:07.582: INFO: scanned /root for discovery docs: <nil>
Aug 31 14:25:07.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7282'
Aug 31 14:25:08.658: INFO: stderr: ""
Aug 31 14:25:08.658: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:25:08.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:08.710: INFO: stderr: ""
Aug 31 14:25:08.710: INFO: stdout: "update-demo-nautilus-kf4lv update-demo-nautilus-rlq2z "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 31 14:25:13.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:13.764: INFO: stderr: ""
Aug 31 14:25:13.764: INFO: stdout: "update-demo-nautilus-kf4lv update-demo-nautilus-rlq2z "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug 31 14:25:18.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:18.820: INFO: stderr: ""
Aug 31 14:25:18.820: INFO: stdout: "update-demo-nautilus-kf4lv "
Aug 31 14:25:18.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:18.878: INFO: stderr: ""
Aug 31 14:25:18.878: INFO: stdout: "true"
Aug 31 14:25:18.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:18.931: INFO: stderr: ""
Aug 31 14:25:18.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:25:18.931: INFO: validating pod update-demo-nautilus-kf4lv
Aug 31 14:25:18.934: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:25:18.934: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:25:18.934: INFO: update-demo-nautilus-kf4lv is verified up and running
STEP: scaling up the replication controller
Aug 31 14:25:18.936: INFO: scanned /root for discovery docs: <nil>
Aug 31 14:25:18.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7282'
Aug 31 14:25:20.003: INFO: stderr: ""
Aug 31 14:25:20.003: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:25:20.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7282'
Aug 31 14:25:20.055: INFO: stderr: ""
Aug 31 14:25:20.055: INFO: stdout: "update-demo-nautilus-5l4s9 update-demo-nautilus-kf4lv "
Aug 31 14:25:20.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-5l4s9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:20.108: INFO: stderr: ""
Aug 31 14:25:20.108: INFO: stdout: "true"
Aug 31 14:25:20.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-5l4s9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:20.160: INFO: stderr: ""
Aug 31 14:25:20.160: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:25:20.160: INFO: validating pod update-demo-nautilus-5l4s9
Aug 31 14:25:20.165: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:25:20.165: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:25:20.165: INFO: update-demo-nautilus-5l4s9 is verified up and running
Aug 31 14:25:20.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:20.225: INFO: stderr: ""
Aug 31 14:25:20.225: INFO: stdout: "true"
Aug 31 14:25:20.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-kf4lv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7282'
Aug 31 14:25:20.272: INFO: stderr: ""
Aug 31 14:25:20.272: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:25:20.272: INFO: validating pod update-demo-nautilus-kf4lv
Aug 31 14:25:20.275: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:25:20.275: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:25:20.275: INFO: update-demo-nautilus-kf4lv is verified up and running
STEP: using delete to clean up resources
Aug 31 14:25:20.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-7282'
Aug 31 14:25:20.327: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 14:25:20.327: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 31 14:25:20.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7282'
Aug 31 14:25:20.397: INFO: stderr: "No resources found.\n"
Aug 31 14:25:20.397: INFO: stdout: ""
Aug 31 14:25:20.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -l name=update-demo --namespace=kubectl-7282 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 31 14:25:20.454: INFO: stderr: ""
Aug 31 14:25:20.454: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:25:20.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7282" for this suite.
Aug 31 14:25:42.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:25:42.529: INFO: namespace kubectl-7282 deletion completed in 22.070081991s

• [SLOW TEST:40.453 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:25:42.530: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:25:48.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5054" for this suite.
Aug 31 14:25:54.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:25:54.737: INFO: namespace namespaces-5054 deletion completed in 6.067875482s
STEP: Destroying namespace "nsdeletetest-4019" for this suite.
Aug 31 14:25:54.739: INFO: Namespace nsdeletetest-4019 was already deleted
STEP: Destroying namespace "nsdeletetest-1041" for this suite.
Aug 31 14:26:00.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:26:00.804: INFO: namespace nsdeletetest-1041 deletion completed in 6.065033682s

• [SLOW TEST:18.275 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:26:00.805: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-b4d9a5c7-59b4-4c4e-8837-d290cea1d578 in namespace container-probe-2047
Aug 31 14:26:04.839: INFO: Started pod test-webserver-b4d9a5c7-59b4-4c4e-8837-d290cea1d578 in namespace container-probe-2047
STEP: checking the pod's current state and verifying that restartCount is present
Aug 31 14:26:04.842: INFO: Initial restart count of pod test-webserver-b4d9a5c7-59b4-4c4e-8837-d290cea1d578 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:30:05.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2047" for this suite.
Aug 31 14:30:11.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:30:11.331: INFO: namespace container-probe-2047 deletion completed in 6.071062141s

• [SLOW TEST:250.527 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:30:11.332: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6568
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 31 14:30:11.382: INFO: Found 1 stateful pods, waiting for 3
Aug 31 14:30:21.386: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:30:21.386: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:30:21.386: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 31 14:30:21.408: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug 31 14:30:31.439: INFO: Updating stateful set ss2
Aug 31 14:30:31.448: INFO: Waiting for Pod statefulset-6568/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug 31 14:30:41.532: INFO: Found 2 stateful pods, waiting for 3
Aug 31 14:30:51.537: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:30:51.537: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:30:51.537: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug 31 14:30:51.558: INFO: Updating stateful set ss2
Aug 31 14:30:51.565: INFO: Waiting for Pod statefulset-6568/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 31 14:31:01.587: INFO: Updating stateful set ss2
Aug 31 14:31:01.592: INFO: Waiting for StatefulSet statefulset-6568/ss2 to complete update
Aug 31 14:31:01.592: INFO: Waiting for Pod statefulset-6568/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 31 14:31:11.598: INFO: Deleting all statefulset in ns statefulset-6568
Aug 31 14:31:11.601: INFO: Scaling statefulset ss2 to 0
Aug 31 14:31:31.613: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 14:31:31.615: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:31:31.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6568" for this suite.
Aug 31 14:31:37.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:31:37.699: INFO: namespace statefulset-6568 deletion completed in 6.064758911s

• [SLOW TEST:86.367 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:31:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:01.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1212" for this suite.
Aug 31 14:32:07.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:07.858: INFO: namespace namespaces-1212 deletion completed in 6.076373002s
STEP: Destroying namespace "nsdeletetest-681" for this suite.
Aug 31 14:32:07.861: INFO: Namespace nsdeletetest-681 was already deleted
STEP: Destroying namespace "nsdeletetest-4898" for this suite.
Aug 31 14:32:13.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:13.935: INFO: namespace nsdeletetest-4898 deletion completed in 6.074111213s

• [SLOW TEST:36.235 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:32:13.940: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-66fd719c-9718-4ce9-a6d3-41d8f8d254f5
STEP: Creating a pod to test consume configMaps
Aug 31 14:32:14.027: INFO: Waiting up to 5m0s for pod "pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1" in namespace "configmap-2956" to be "success or failure"
Aug 31 14:32:14.031: INFO: Pod "pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.774556ms
Aug 31 14:32:16.035: INFO: Pod "pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007986992s
STEP: Saw pod success
Aug 31 14:32:16.035: INFO: Pod "pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1" satisfied condition "success or failure"
Aug 31 14:32:16.038: INFO: Trying to get logs from node vm119042 pod pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:32:16.070: INFO: Waiting for pod pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1 to disappear
Aug 31 14:32:16.073: INFO: Pod pod-configmaps-0b6316a3-bc69-482d-82ee-c81986b7f6d1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:16.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2956" for this suite.
Aug 31 14:32:22.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:22.148: INFO: namespace configmap-2956 deletion completed in 6.071423534s

• [SLOW TEST:8.209 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:32:22.149: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 31 14:32:22.177: INFO: Waiting up to 5m0s for pod "pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792" in namespace "emptydir-8601" to be "success or failure"
Aug 31 14:32:22.179: INFO: Pod "pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742759ms
Aug 31 14:32:24.182: INFO: Pod "pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005709408s
STEP: Saw pod success
Aug 31 14:32:24.183: INFO: Pod "pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792" satisfied condition "success or failure"
Aug 31 14:32:24.185: INFO: Trying to get logs from node vm119042 pod pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792 container test-container: <nil>
STEP: delete the pod
Aug 31 14:32:24.201: INFO: Waiting for pod pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792 to disappear
Aug 31 14:32:24.203: INFO: Pod pod-4059dd69-c9ab-4a05-80a4-7fb3986b4792 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:24.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8601" for this suite.
Aug 31 14:32:30.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:30.299: INFO: namespace emptydir-8601 deletion completed in 6.087602865s

• [SLOW TEST:8.150 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:32:30.299: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0c3b8cc2-4dbc-4a01-9088-50cae2377176
STEP: Creating a pod to test consume secrets
Aug 31 14:32:30.340: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f" in namespace "projected-5535" to be "success or failure"
Aug 31 14:32:30.348: INFO: Pod "pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.921118ms
Aug 31 14:32:32.351: INFO: Pod "pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011120154s
Aug 31 14:32:34.354: INFO: Pod "pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014483707s
STEP: Saw pod success
Aug 31 14:32:34.354: INFO: Pod "pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f" satisfied condition "success or failure"
Aug 31 14:32:34.356: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 31 14:32:34.372: INFO: Waiting for pod pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f to disappear
Aug 31 14:32:34.377: INFO: Pod pod-projected-secrets-469cea1c-575b-4c6a-b2dd-98936ceb499f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:34.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5535" for this suite.
Aug 31 14:32:40.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:40.453: INFO: namespace projected-5535 deletion completed in 6.072711083s

• [SLOW TEST:10.154 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:32:40.453: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-c5c7b0d8-b5c6-4864-8ded-1c6322894ab2
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:40.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1592" for this suite.
Aug 31 14:32:46.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:32:46.551: INFO: namespace secrets-1592 deletion completed in 6.065013446s

• [SLOW TEST:6.098 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:32:46.551: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug 31 14:32:48.593: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-0184319e-018d-4a6b-b893-7a9629deb0d8,GenerateName:,Namespace:events-135,SelfLink:/api/v1/namespaces/events-135/pods/send-events-0184319e-018d-4a6b-b893-7a9629deb0d8,UID:5de06cdf-f61c-4876-a8ed-d7e6d7fee6ec,ResourceVersion:27693,Generation:0,CreationTimestamp:2022-08-31 14:32:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 576407838,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-lhplc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lhplc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-lhplc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002417420} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002417440}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:32:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:32:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:32:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:32:46 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:10.244.1.181,StartTime:2022-08-31 14:32:46 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2022-08-31 14:32:47 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://df04f38ce1ab73979201bb92156c76f9d0c0d0620af9ce69e3bb31c09e3fe06a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug 31 14:32:50.597: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug 31 14:32:52.600: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:32:52.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-135" for this suite.
Aug 31 14:33:30.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:33:30.684: INFO: namespace events-135 deletion completed in 38.068040078s

• [SLOW TEST:44.134 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:33:30.691: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:33:30.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9999" for this suite.
Aug 31 14:33:52.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:33:52.837: INFO: namespace kubelet-test-9999 deletion completed in 22.099814335s

• [SLOW TEST:22.150 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:33:52.837: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:34:52.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8826" for this suite.
Aug 31 14:35:14.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:35:15.001: INFO: namespace container-probe-8826 deletion completed in 22.107446896s

• [SLOW TEST:82.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:35:15.010: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:35:17.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9751" for this suite.
Aug 31 14:35:59.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:35:59.142: INFO: namespace kubelet-test-9751 deletion completed in 42.074873233s

• [SLOW TEST:44.132 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:35:59.143: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 31 14:36:03.213: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 31 14:36:03.217: INFO: Pod pod-with-poststart-http-hook still exists
Aug 31 14:36:05.218: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 31 14:36:05.222: INFO: Pod pod-with-poststart-http-hook still exists
Aug 31 14:36:07.218: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug 31 14:36:07.221: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:36:07.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1043" for this suite.
Aug 31 14:36:29.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:36:29.301: INFO: namespace container-lifecycle-hook-1043 deletion completed in 22.075527414s

• [SLOW TEST:30.158 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:36:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:36:29.343: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug 31 14:36:29.352: INFO: Number of nodes with available pods: 0
Aug 31 14:36:29.352: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug 31 14:36:29.374: INFO: Number of nodes with available pods: 0
Aug 31 14:36:29.375: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:30.378: INFO: Number of nodes with available pods: 0
Aug 31 14:36:30.378: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:31.379: INFO: Number of nodes with available pods: 1
Aug 31 14:36:31.379: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug 31 14:36:31.394: INFO: Number of nodes with available pods: 1
Aug 31 14:36:31.394: INFO: Number of running nodes: 0, number of available pods: 1
Aug 31 14:36:32.398: INFO: Number of nodes with available pods: 0
Aug 31 14:36:32.398: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug 31 14:36:32.408: INFO: Number of nodes with available pods: 0
Aug 31 14:36:32.408: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:33.411: INFO: Number of nodes with available pods: 0
Aug 31 14:36:33.411: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:34.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:34.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:35.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:35.413: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:36.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:36.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:37.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:37.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:38.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:38.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:39.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:39.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:40.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:40.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:41.412: INFO: Number of nodes with available pods: 0
Aug 31 14:36:41.412: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:36:42.412: INFO: Number of nodes with available pods: 1
Aug 31 14:36:42.412: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6181, will wait for the garbage collector to delete the pods
Aug 31 14:36:42.475: INFO: Deleting DaemonSet.extensions daemon-set took: 6.456126ms
Aug 31 14:36:42.576: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.950442ms
Aug 31 14:36:46.279: INFO: Number of nodes with available pods: 0
Aug 31 14:36:46.279: INFO: Number of running nodes: 0, number of available pods: 0
Aug 31 14:36:46.283: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6181/daemonsets","resourceVersion":"28249"},"items":null}

Aug 31 14:36:46.286: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6181/pods","resourceVersion":"28249"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:36:46.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6181" for this suite.
Aug 31 14:36:52.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:36:52.383: INFO: namespace daemonsets-6181 deletion completed in 6.070604929s

• [SLOW TEST:23.081 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:36:52.383: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2546
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 31 14:36:52.417: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 31 14:37:16.523: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.54:8080/dial?request=hostName&protocol=http&host=10.244.3.131&port=8080&tries=1'] Namespace:pod-network-test-2546 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:37:16.523: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:37:16.606: INFO: Waiting for endpoints: map[]
Aug 31 14:37:16.609: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.54:8080/dial?request=hostName&protocol=http&host=10.244.1.185&port=8080&tries=1'] Namespace:pod-network-test-2546 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:37:16.609: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:37:16.703: INFO: Waiting for endpoints: map[]
Aug 31 14:37:16.706: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.54:8080/dial?request=hostName&protocol=http&host=10.244.0.51&port=8080&tries=1'] Namespace:pod-network-test-2546 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:37:16.706: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:37:16.786: INFO: Waiting for endpoints: map[]
Aug 31 14:37:16.789: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.54:8080/dial?request=hostName&protocol=http&host=10.244.2.53&port=8080&tries=1'] Namespace:pod-network-test-2546 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:37:16.789: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:37:16.872: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:37:16.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2546" for this suite.
Aug 31 14:37:38.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:37:38.944: INFO: namespace pod-network-test-2546 deletion completed in 22.068514184s

• [SLOW TEST:46.561 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:37:38.944: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1dd97720-1032-4797-b2d8-2b90cd9ea3ed
STEP: Creating a pod to test consume configMaps
Aug 31 14:37:38.978: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b" in namespace "configmap-642" to be "success or failure"
Aug 31 14:37:38.980: INFO: Pod "pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.280747ms
Aug 31 14:37:40.984: INFO: Pod "pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005891099s
STEP: Saw pod success
Aug 31 14:37:40.984: INFO: Pod "pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b" satisfied condition "success or failure"
Aug 31 14:37:40.987: INFO: Trying to get logs from node vm119042 pod pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:37:41.004: INFO: Waiting for pod pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b to disappear
Aug 31 14:37:41.006: INFO: Pod pod-configmaps-4c1c3d0e-e0e6-4665-b324-279aa13bf09b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:37:41.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-642" for this suite.
Aug 31 14:37:47.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:37:47.080: INFO: namespace configmap-642 deletion completed in 6.068262373s

• [SLOW TEST:8.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:37:47.081: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-bkdm
STEP: Creating a pod to test atomic-volume-subpath
Aug 31 14:37:47.117: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-bkdm" in namespace "subpath-8801" to be "success or failure"
Aug 31 14:37:47.120: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Pending", Reason="", readiness=false. Elapsed: 3.528944ms
Aug 31 14:37:49.123: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 2.006749783s
Aug 31 14:37:51.126: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 4.009453182s
Aug 31 14:37:53.129: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 6.012495903s
Aug 31 14:37:55.132: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 8.015830338s
Aug 31 14:37:57.136: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 10.019152814s
Aug 31 14:37:59.140: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 12.022987625s
Aug 31 14:38:01.148: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 14.031525342s
Aug 31 14:38:03.152: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 16.035233625s
Aug 31 14:38:05.156: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 18.038991185s
Aug 31 14:38:07.159: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Running", Reason="", readiness=true. Elapsed: 20.042178218s
Aug 31 14:38:09.162: INFO: Pod "pod-subpath-test-secret-bkdm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.045665278s
STEP: Saw pod success
Aug 31 14:38:09.162: INFO: Pod "pod-subpath-test-secret-bkdm" satisfied condition "success or failure"
Aug 31 14:38:09.165: INFO: Trying to get logs from node vm119042 pod pod-subpath-test-secret-bkdm container test-container-subpath-secret-bkdm: <nil>
STEP: delete the pod
Aug 31 14:38:09.179: INFO: Waiting for pod pod-subpath-test-secret-bkdm to disappear
Aug 31 14:38:09.184: INFO: Pod pod-subpath-test-secret-bkdm no longer exists
STEP: Deleting pod pod-subpath-test-secret-bkdm
Aug 31 14:38:09.184: INFO: Deleting pod "pod-subpath-test-secret-bkdm" in namespace "subpath-8801"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:38:09.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8801" for this suite.
Aug 31 14:38:15.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:38:15.267: INFO: namespace subpath-8801 deletion completed in 6.075376683s

• [SLOW TEST:28.186 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:38:15.271: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:38:15.361: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533" in namespace "downward-api-7176" to be "success or failure"
Aug 31 14:38:15.366: INFO: Pod "downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533": Phase="Pending", Reason="", readiness=false. Elapsed: 5.237476ms
Aug 31 14:38:17.370: INFO: Pod "downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00930761s
STEP: Saw pod success
Aug 31 14:38:17.370: INFO: Pod "downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533" satisfied condition "success or failure"
Aug 31 14:38:17.373: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533 container client-container: <nil>
STEP: delete the pod
Aug 31 14:38:17.390: INFO: Waiting for pod downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533 to disappear
Aug 31 14:38:17.393: INFO: Pod downwardapi-volume-41018f9c-e828-4d15-91f1-736e45074533 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:38:17.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7176" for this suite.
Aug 31 14:38:23.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:38:23.472: INFO: namespace downward-api-7176 deletion completed in 6.072407583s

• [SLOW TEST:8.201 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:38:23.473: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 31 14:38:23.502: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:38:25.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9162" for this suite.
Aug 31 14:38:31.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:38:31.538: INFO: namespace init-container-9162 deletion completed in 6.07119669s

• [SLOW TEST:8.065 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:38:31.538: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug 31 14:38:31.569: INFO: Waiting up to 5m0s for pod "pod-69250a27-731f-4ca8-858f-555fac801802" in namespace "emptydir-2222" to be "success or failure"
Aug 31 14:38:31.574: INFO: Pod "pod-69250a27-731f-4ca8-858f-555fac801802": Phase="Pending", Reason="", readiness=false. Elapsed: 5.154777ms
Aug 31 14:38:33.577: INFO: Pod "pod-69250a27-731f-4ca8-858f-555fac801802": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008293741s
STEP: Saw pod success
Aug 31 14:38:33.577: INFO: Pod "pod-69250a27-731f-4ca8-858f-555fac801802" satisfied condition "success or failure"
Aug 31 14:38:33.579: INFO: Trying to get logs from node vm119042 pod pod-69250a27-731f-4ca8-858f-555fac801802 container test-container: <nil>
STEP: delete the pod
Aug 31 14:38:33.593: INFO: Waiting for pod pod-69250a27-731f-4ca8-858f-555fac801802 to disappear
Aug 31 14:38:33.598: INFO: Pod pod-69250a27-731f-4ca8-858f-555fac801802 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:38:33.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2222" for this suite.
Aug 31 14:38:39.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:38:39.676: INFO: namespace emptydir-2222 deletion completed in 6.072415981s

• [SLOW TEST:8.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:38:39.677: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug 31 14:38:43.753: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:43.774: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:45.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:45.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:47.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:47.777: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:49.775: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:49.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:51.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:51.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:53.775: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:53.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:55.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:55.777: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:57.775: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:57.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:38:59.774: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:38:59.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:39:01.775: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:39:01.778: INFO: Pod pod-with-poststart-exec-hook still exists
Aug 31 14:39:03.775: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug 31 14:39:03.778: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:39:03.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7493" for this suite.
Aug 31 14:39:25.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:39:25.891: INFO: namespace container-lifecycle-hook-7493 deletion completed in 22.108830833s

• [SLOW TEST:46.214 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:39:25.891: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-xjwg
STEP: Creating a pod to test atomic-volume-subpath
Aug 31 14:39:25.944: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xjwg" in namespace "subpath-9110" to be "success or failure"
Aug 31 14:39:25.947: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.470805ms
Aug 31 14:39:27.951: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 2.006495796s
Aug 31 14:39:29.954: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 4.009890894s
Aug 31 14:39:31.959: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 6.01406148s
Aug 31 14:39:33.962: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 8.017271856s
Aug 31 14:39:35.965: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 10.020667927s
Aug 31 14:39:37.969: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 12.024392856s
Aug 31 14:39:39.972: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 14.027527912s
Aug 31 14:39:41.975: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 16.030499009s
Aug 31 14:39:43.978: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 18.033825628s
Aug 31 14:39:45.982: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Running", Reason="", readiness=true. Elapsed: 20.037159596s
Aug 31 14:39:47.985: INFO: Pod "pod-subpath-test-downwardapi-xjwg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.040447178s
STEP: Saw pod success
Aug 31 14:39:47.985: INFO: Pod "pod-subpath-test-downwardapi-xjwg" satisfied condition "success or failure"
Aug 31 14:39:47.988: INFO: Trying to get logs from node vm119042 pod pod-subpath-test-downwardapi-xjwg container test-container-subpath-downwardapi-xjwg: <nil>
STEP: delete the pod
Aug 31 14:39:48.006: INFO: Waiting for pod pod-subpath-test-downwardapi-xjwg to disappear
Aug 31 14:39:48.011: INFO: Pod pod-subpath-test-downwardapi-xjwg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xjwg
Aug 31 14:39:48.011: INFO: Deleting pod "pod-subpath-test-downwardapi-xjwg" in namespace "subpath-9110"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:39:48.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9110" for this suite.
Aug 31 14:39:54.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:39:54.092: INFO: namespace subpath-9110 deletion completed in 6.074461072s

• [SLOW TEST:28.201 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:39:54.093: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 31 14:39:54.130: INFO: Waiting up to 5m0s for pod "downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0" in namespace "downward-api-1470" to be "success or failure"
Aug 31 14:39:54.133: INFO: Pod "downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.811479ms
Aug 31 14:39:56.137: INFO: Pod "downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007473176s
STEP: Saw pod success
Aug 31 14:39:56.137: INFO: Pod "downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0" satisfied condition "success or failure"
Aug 31 14:39:56.141: INFO: Trying to get logs from node vm119042 pod downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0 container dapi-container: <nil>
STEP: delete the pod
Aug 31 14:39:56.164: INFO: Waiting for pod downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0 to disappear
Aug 31 14:39:56.168: INFO: Pod downward-api-44d5ed8a-7a94-426d-bc49-fe92f84dafd0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:39:56.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1470" for this suite.
Aug 31 14:40:02.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:40:02.251: INFO: namespace downward-api-1470 deletion completed in 6.077593723s

• [SLOW TEST:8.158 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:40:02.252: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:40:02.287: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 31 14:40:04.296: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 31 14:40:06.320: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-7275,SelfLink:/apis/apps/v1/namespaces/deployment-7275/deployments/test-cleanup-deployment,UID:9423a47d-55fb-4aa8-ae95-2a47ca370309,ResourceVersion:28947,Generation:1,CreationTimestamp:2022-08-31 14:40:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2022-08-31 14:40:04 +0000 UTC 2022-08-31 14:40:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-31 14:40:05 +0000 UTC 2022-08-31 14:40:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 31 14:40:06.322: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-7275,SelfLink:/apis/apps/v1/namespaces/deployment-7275/replicasets/test-cleanup-deployment-55bbcbc84c,UID:3fb2674a-b64e-46ce-8d2f-08a1585f9729,ResourceVersion:28937,Generation:1,CreationTimestamp:2022-08-31 14:40:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9423a47d-55fb-4aa8-ae95-2a47ca370309 0xc002c8e697 0xc002c8e698}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 31 14:40:06.328: INFO: Pod "test-cleanup-deployment-55bbcbc84c-6qfp6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-6qfp6,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-7275,SelfLink:/api/v1/namespaces/deployment-7275/pods/test-cleanup-deployment-55bbcbc84c-6qfp6,UID:86e12ea7-a2bd-4fa4-b4bb-d902dbcd3f83,ResourceVersion:28936,Generation:0,CreationTimestamp:2022-08-31 14:40:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 3fb2674a-b64e-46ce-8d2f-08a1585f9729 0xc002c8eca7 0xc002c8eca8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-qjg46 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qjg46,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-qjg46 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c8ed20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c8ed40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:40:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:40:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:40:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:40:04 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:10.244.2.56,StartTime:2022-08-31 14:40:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2022-08-31 14:40:04 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://56056ba6f4100d2587f79fd21973a0ae8c292629e3aa8720a385dfbfcf71899a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:40:06.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7275" for this suite.
Aug 31 14:40:12.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:40:12.402: INFO: namespace deployment-7275 deletion completed in 6.070790476s

• [SLOW TEST:10.151 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:40:12.403: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0
Aug 31 14:40:12.484: INFO: Pod name my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0: Found 0 pods out of 1
Aug 31 14:40:17.488: INFO: Pod name my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0: Found 1 pods out of 1
Aug 31 14:40:17.488: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0" are running
Aug 31 14:40:17.490: INFO: Pod "my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0-fxdjb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 14:40:12 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 14:40:13 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 14:40:13 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 14:40:12 +0000 UTC Reason: Message:}])
Aug 31 14:40:17.490: INFO: Trying to dial the pod
Aug 31 14:40:22.499: INFO: Controller my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0: Got expected result from replica 1 [my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0-fxdjb]: "my-hostname-basic-fd5bccc0-7834-4eca-9c6d-c6ed3760aca0-fxdjb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:40:22.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3867" for this suite.
Aug 31 14:40:28.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:40:28.584: INFO: namespace replication-controller-3867 deletion completed in 6.082062582s

• [SLOW TEST:16.181 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:40:28.586: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:40:28.669: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b" in namespace "projected-8628" to be "success or failure"
Aug 31 14:40:28.674: INFO: Pod "downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.13713ms
Aug 31 14:40:30.677: INFO: Pod "downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007558265s
STEP: Saw pod success
Aug 31 14:40:30.677: INFO: Pod "downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b" satisfied condition "success or failure"
Aug 31 14:40:30.679: INFO: Trying to get logs from node vm119043 pod downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b container client-container: <nil>
STEP: delete the pod
Aug 31 14:40:30.696: INFO: Waiting for pod downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b to disappear
Aug 31 14:40:30.700: INFO: Pod downwardapi-volume-2f2acd19-311f-4b47-9c83-c8d58fccdb4b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:40:30.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8628" for this suite.
Aug 31 14:40:36.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:40:36.774: INFO: namespace projected-8628 deletion completed in 6.070672257s

• [SLOW TEST:8.189 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:40:36.776: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 14:40:36.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5842'
Aug 31 14:40:36.928: INFO: stderr: ""
Aug 31 14:40:36.928: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug 31 14:40:41.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pod e2e-test-nginx-pod --namespace=kubectl-5842 -o json'
Aug 31 14:40:42.034: INFO: stderr: ""
Aug 31 14:40:42.034: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-08-31T14:40:36Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5842\",\n        \"resourceVersion\": \"29088\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5842/pods/e2e-test-nginx-pod\",\n        \"uid\": \"f67ca1b6-418a-451e-999b-5a6ad783bc29\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-vpd2l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"vm119042\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-vpd2l\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-vpd2l\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-31T14:40:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-31T14:40:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-31T14:40:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-08-31T14:40:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://24e3e5f342c56431dea9c408d3aa8e633312022ff14afd08a036815dbe491358\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-08-31T14:40:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.119.42\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.196\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-08-31T14:40:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug 31 14:40:42.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 replace -f - --namespace=kubectl-5842'
Aug 31 14:40:42.147: INFO: stderr: ""
Aug 31 14:40:42.147: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Aug 31 14:40:42.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete pods e2e-test-nginx-pod --namespace=kubectl-5842'
Aug 31 14:40:46.343: INFO: stderr: ""
Aug 31 14:40:46.343: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:40:46.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5842" for this suite.
Aug 31 14:40:52.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:40:52.416: INFO: namespace kubectl-5842 deletion completed in 6.068644387s

• [SLOW TEST:15.640 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:40:52.416: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:40:52.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6" in namespace "downward-api-3659" to be "success or failure"
Aug 31 14:40:52.457: INFO: Pod "downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.08372ms
Aug 31 14:40:54.461: INFO: Pod "downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008966949s
STEP: Saw pod success
Aug 31 14:40:54.461: INFO: Pod "downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6" satisfied condition "success or failure"
Aug 31 14:40:54.464: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6 container client-container: <nil>
STEP: delete the pod
Aug 31 14:40:54.481: INFO: Waiting for pod downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6 to disappear
Aug 31 14:40:54.484: INFO: Pod downwardapi-volume-12bf9cd5-b75d-428d-9383-89f77b863ad6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:40:54.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3659" for this suite.
Aug 31 14:41:00.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:00.566: INFO: namespace downward-api-3659 deletion completed in 6.077989648s

• [SLOW TEST:8.150 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:00.567: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:00.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1071" for this suite.
Aug 31 14:41:06.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:06.673: INFO: namespace services-1071 deletion completed in 6.075796334s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.107 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:06.674: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-07046177-3c2d-458d-a81d-234faa7bfc40
STEP: Creating a pod to test consume configMaps
Aug 31 14:41:06.761: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83" in namespace "projected-9993" to be "success or failure"
Aug 31 14:41:06.769: INFO: Pod "pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83": Phase="Pending", Reason="", readiness=false. Elapsed: 7.932274ms
Aug 31 14:41:08.773: INFO: Pod "pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011625143s
STEP: Saw pod success
Aug 31 14:41:08.773: INFO: Pod "pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83" satisfied condition "success or failure"
Aug 31 14:41:08.776: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:41:08.791: INFO: Waiting for pod pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83 to disappear
Aug 31 14:41:08.794: INFO: Pod pod-projected-configmaps-c9205df3-97e5-4f7b-9ecd-af0ec03bab83 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:08.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9993" for this suite.
Aug 31 14:41:14.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:14.866: INFO: namespace projected-9993 deletion completed in 6.066805218s

• [SLOW TEST:8.192 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:14.866: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-a2e454d9-a229-4564-8872-0db78ac76b1c
STEP: Creating a pod to test consume configMaps
Aug 31 14:41:14.901: INFO: Waiting up to 5m0s for pod "pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3" in namespace "configmap-9197" to be "success or failure"
Aug 31 14:41:14.911: INFO: Pod "pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.703265ms
Aug 31 14:41:16.915: INFO: Pod "pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013754776s
STEP: Saw pod success
Aug 31 14:41:16.915: INFO: Pod "pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3" satisfied condition "success or failure"
Aug 31 14:41:16.918: INFO: Trying to get logs from node vm119042 pod pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:41:16.933: INFO: Waiting for pod pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3 to disappear
Aug 31 14:41:16.935: INFO: Pod pod-configmaps-b31b3a89-942d-4d49-9cb6-813a14119cc3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:16.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9197" for this suite.
Aug 31 14:41:22.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:23.009: INFO: namespace configmap-9197 deletion completed in 6.068996723s

• [SLOW TEST:8.143 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:23.010: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:41:23.066: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760" in namespace "projected-7314" to be "success or failure"
Aug 31 14:41:23.072: INFO: Pod "downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760": Phase="Pending", Reason="", readiness=false. Elapsed: 6.589376ms
Aug 31 14:41:25.076: INFO: Pod "downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009783105s
STEP: Saw pod success
Aug 31 14:41:25.076: INFO: Pod "downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760" satisfied condition "success or failure"
Aug 31 14:41:25.079: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760 container client-container: <nil>
STEP: delete the pod
Aug 31 14:41:25.100: INFO: Waiting for pod downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760 to disappear
Aug 31 14:41:25.103: INFO: Pod downwardapi-volume-f1e65385-3ab0-49ea-b439-129c56993760 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:25.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7314" for this suite.
Aug 31 14:41:31.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:31.200: INFO: namespace projected-7314 deletion completed in 6.093022584s

• [SLOW TEST:8.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:31.201: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug 31 14:41:31.261: INFO: Waiting up to 5m0s for pod "client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3" in namespace "containers-5948" to be "success or failure"
Aug 31 14:41:31.266: INFO: Pod "client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.803106ms
Aug 31 14:41:33.270: INFO: Pod "client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009024862s
STEP: Saw pod success
Aug 31 14:41:33.270: INFO: Pod "client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3" satisfied condition "success or failure"
Aug 31 14:41:33.271: INFO: Trying to get logs from node vm119042 pod client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3 container test-container: <nil>
STEP: delete the pod
Aug 31 14:41:33.288: INFO: Waiting for pod client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3 to disappear
Aug 31 14:41:33.291: INFO: Pod client-containers-80c85bdf-fd85-40ff-ae9d-be0ea52a9de3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:33.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5948" for this suite.
Aug 31 14:41:39.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:39.361: INFO: namespace containers-5948 deletion completed in 6.066990779s

• [SLOW TEST:8.161 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:39.362: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0e3a7cef-2f24-4b39-be76-81b60a62a726
STEP: Creating a pod to test consume secrets
Aug 31 14:41:39.405: INFO: Waiting up to 5m0s for pod "pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955" in namespace "secrets-9058" to be "success or failure"
Aug 31 14:41:39.408: INFO: Pod "pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955": Phase="Pending", Reason="", readiness=false. Elapsed: 3.205454ms
Aug 31 14:41:41.412: INFO: Pod "pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006650858s
STEP: Saw pod success
Aug 31 14:41:41.412: INFO: Pod "pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955" satisfied condition "success or failure"
Aug 31 14:41:41.415: INFO: Trying to get logs from node vm119042 pod pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 14:41:41.429: INFO: Waiting for pod pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955 to disappear
Aug 31 14:41:41.432: INFO: Pod pod-secrets-650a700e-1ff8-487e-9508-ae74160a2955 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:41:41.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9058" for this suite.
Aug 31 14:41:47.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:41:47.505: INFO: namespace secrets-9058 deletion completed in 6.069850738s

• [SLOW TEST:8.143 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:41:47.505: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-bd4e4003-a690-4130-af3e-29d03673b667 in namespace container-probe-9832
Aug 31 14:41:49.537: INFO: Started pod liveness-bd4e4003-a690-4130-af3e-29d03673b667 in namespace container-probe-9832
STEP: checking the pod's current state and verifying that restartCount is present
Aug 31 14:41:49.540: INFO: Initial restart count of pod liveness-bd4e4003-a690-4130-af3e-29d03673b667 is 0
Aug 31 14:42:09.580: INFO: Restart count of pod container-probe-9832/liveness-bd4e4003-a690-4130-af3e-29d03673b667 is now 1 (20.040662491s elapsed)
Aug 31 14:42:29.614: INFO: Restart count of pod container-probe-9832/liveness-bd4e4003-a690-4130-af3e-29d03673b667 is now 2 (40.074715195s elapsed)
Aug 31 14:42:49.650: INFO: Restart count of pod container-probe-9832/liveness-bd4e4003-a690-4130-af3e-29d03673b667 is now 3 (1m0.110040765s elapsed)
Aug 31 14:43:09.687: INFO: Restart count of pod container-probe-9832/liveness-bd4e4003-a690-4130-af3e-29d03673b667 is now 4 (1m20.147017291s elapsed)
Aug 31 14:44:09.789: INFO: Restart count of pod container-probe-9832/liveness-bd4e4003-a690-4130-af3e-29d03673b667 is now 5 (2m20.249599702s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:44:09.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9832" for this suite.
Aug 31 14:44:15.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:44:15.871: INFO: namespace container-probe-9832 deletion completed in 6.068674775s

• [SLOW TEST:148.366 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:44:15.873: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f3e1ea2e-8486-4983-ab62-0d57a5e02bb2
STEP: Creating a pod to test consume configMaps
Aug 31 14:44:15.913: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76" in namespace "projected-782" to be "success or failure"
Aug 31 14:44:15.919: INFO: Pod "pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76": Phase="Pending", Reason="", readiness=false. Elapsed: 5.292674ms
Aug 31 14:44:17.923: INFO: Pod "pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00963903s
STEP: Saw pod success
Aug 31 14:44:17.923: INFO: Pod "pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76" satisfied condition "success or failure"
Aug 31 14:44:17.926: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:44:17.941: INFO: Waiting for pod pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76 to disappear
Aug 31 14:44:17.944: INFO: Pod pod-projected-configmaps-11b29555-934f-46cb-99b4-57f08d322c76 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:44:17.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-782" for this suite.
Aug 31 14:44:23.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:44:24.028: INFO: namespace projected-782 deletion completed in 6.078304047s

• [SLOW TEST:8.155 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:44:24.028: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug 31 14:44:24.071: INFO: Waiting up to 5m0s for pod "pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08" in namespace "emptydir-6428" to be "success or failure"
Aug 31 14:44:24.075: INFO: Pod "pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08": Phase="Pending", Reason="", readiness=false. Elapsed: 3.702685ms
Aug 31 14:44:26.078: INFO: Pod "pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006384457s
STEP: Saw pod success
Aug 31 14:44:26.078: INFO: Pod "pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08" satisfied condition "success or failure"
Aug 31 14:44:26.080: INFO: Trying to get logs from node vm119042 pod pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08 container test-container: <nil>
STEP: delete the pod
Aug 31 14:44:26.096: INFO: Waiting for pod pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08 to disappear
Aug 31 14:44:26.099: INFO: Pod pod-143a489e-2c84-46f1-b7c1-ba1c20e03d08 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:44:26.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6428" for this suite.
Aug 31 14:44:32.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:44:32.174: INFO: namespace emptydir-6428 deletion completed in 6.071898062s

• [SLOW TEST:8.146 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:44:32.175: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 14:44:32.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-4167'
Aug 31 14:44:32.261: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 31 14:44:32.261: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Aug 31 14:44:34.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4167'
Aug 31 14:44:34.333: INFO: stderr: ""
Aug 31 14:44:34.334: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:44:34.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4167" for this suite.
Aug 31 14:44:56.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:44:56.404: INFO: namespace kubectl-4167 deletion completed in 22.067583498s

• [SLOW TEST:24.230 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:44:56.406: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9fb47f73-573d-44f0-8dce-7045357b014d
STEP: Creating a pod to test consume configMaps
Aug 31 14:44:56.445: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58" in namespace "projected-8190" to be "success or failure"
Aug 31 14:44:56.452: INFO: Pod "pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58": Phase="Pending", Reason="", readiness=false. Elapsed: 7.583644ms
Aug 31 14:44:58.456: INFO: Pod "pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010849325s
STEP: Saw pod success
Aug 31 14:44:58.456: INFO: Pod "pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58" satisfied condition "success or failure"
Aug 31 14:44:58.458: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:44:58.474: INFO: Waiting for pod pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58 to disappear
Aug 31 14:44:58.476: INFO: Pod pod-projected-configmaps-da296527-4f70-45dc-99c0-c08fb48e3a58 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:44:58.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8190" for this suite.
Aug 31 14:45:04.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:45:04.564: INFO: namespace projected-8190 deletion completed in 6.082856401s

• [SLOW TEST:8.159 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:45:04.565: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-0b8a585b-5553-4171-ac67-f1d77c2ab681
STEP: Creating a pod to test consume configMaps
Aug 31 14:45:04.599: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28" in namespace "projected-4399" to be "success or failure"
Aug 31 14:45:04.603: INFO: Pod "pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.321078ms
Aug 31 14:45:06.607: INFO: Pod "pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007973594s
STEP: Saw pod success
Aug 31 14:45:06.607: INFO: Pod "pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28" satisfied condition "success or failure"
Aug 31 14:45:06.609: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 14:45:06.626: INFO: Waiting for pod pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28 to disappear
Aug 31 14:45:06.629: INFO: Pod pod-projected-configmaps-a0be0acc-4b03-48a9-9d68-e3e5082d6d28 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:45:06.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4399" for this suite.
Aug 31 14:45:12.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:45:12.708: INFO: namespace projected-4399 deletion completed in 6.074880858s

• [SLOW TEST:8.143 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:45:12.713: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 31 14:45:12.745: INFO: Waiting up to 5m0s for pod "pod-9d8188f1-50b9-4874-88ac-cb117801915e" in namespace "emptydir-5904" to be "success or failure"
Aug 31 14:45:12.749: INFO: Pod "pod-9d8188f1-50b9-4874-88ac-cb117801915e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154909ms
Aug 31 14:45:14.753: INFO: Pod "pod-9d8188f1-50b9-4874-88ac-cb117801915e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007941732s
STEP: Saw pod success
Aug 31 14:45:14.753: INFO: Pod "pod-9d8188f1-50b9-4874-88ac-cb117801915e" satisfied condition "success or failure"
Aug 31 14:45:14.755: INFO: Trying to get logs from node vm119042 pod pod-9d8188f1-50b9-4874-88ac-cb117801915e container test-container: <nil>
STEP: delete the pod
Aug 31 14:45:14.776: INFO: Waiting for pod pod-9d8188f1-50b9-4874-88ac-cb117801915e to disappear
Aug 31 14:45:14.781: INFO: Pod pod-9d8188f1-50b9-4874-88ac-cb117801915e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:45:14.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5904" for this suite.
Aug 31 14:45:20.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:45:20.852: INFO: namespace emptydir-5904 deletion completed in 6.066905004s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:45:20.854: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug 31 14:46:00.904: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:46:00.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0831 14:46:00.904114      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-7132" for this suite.
Aug 31 14:46:06.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:46:06.983: INFO: namespace gc-7132 deletion completed in 6.074626933s

• [SLOW TEST:46.130 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:46:06.984: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:46:07.020: INFO: (0) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 6.971082ms)
Aug 31 14:46:07.029: INFO: (1) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 8.739633ms)
Aug 31 14:46:07.033: INFO: (2) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.065487ms)
Aug 31 14:46:07.037: INFO: (3) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.494867ms)
Aug 31 14:46:07.042: INFO: (4) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.651033ms)
Aug 31 14:46:07.046: INFO: (5) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.125244ms)
Aug 31 14:46:07.050: INFO: (6) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.744023ms)
Aug 31 14:46:07.054: INFO: (7) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.980725ms)
Aug 31 14:46:07.059: INFO: (8) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.40553ms)
Aug 31 14:46:07.062: INFO: (9) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.291514ms)
Aug 31 14:46:07.065: INFO: (10) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.815508ms)
Aug 31 14:46:07.068: INFO: (11) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.713197ms)
Aug 31 14:46:07.071: INFO: (12) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.968713ms)
Aug 31 14:46:07.073: INFO: (13) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.591115ms)
Aug 31 14:46:07.077: INFO: (14) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.455369ms)
Aug 31 14:46:07.082: INFO: (15) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.896035ms)
Aug 31 14:46:07.086: INFO: (16) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.794102ms)
Aug 31 14:46:07.090: INFO: (17) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.170543ms)
Aug 31 14:46:07.097: INFO: (18) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 7.270424ms)
Aug 31 14:46:07.101: INFO: (19) /api/v1/nodes/vm119041/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.569934ms)
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:46:07.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5280" for this suite.
Aug 31 14:46:13.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:46:13.172: INFO: namespace proxy-5280 deletion completed in 6.068259844s

• [SLOW TEST:6.188 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:46:13.173: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:46:13.269: INFO: Create a RollingUpdate DaemonSet
Aug 31 14:46:13.276: INFO: Check that daemon pods launch on every node of the cluster
Aug 31 14:46:13.297: INFO: Number of nodes with available pods: 0
Aug 31 14:46:13.297: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:46:14.304: INFO: Number of nodes with available pods: 0
Aug 31 14:46:14.304: INFO: Node vm119041 is running more than one daemon pod
Aug 31 14:46:15.304: INFO: Number of nodes with available pods: 2
Aug 31 14:46:15.304: INFO: Node vm119042 is running more than one daemon pod
Aug 31 14:46:16.303: INFO: Number of nodes with available pods: 4
Aug 31 14:46:16.303: INFO: Number of running nodes: 4, number of available pods: 4
Aug 31 14:46:16.303: INFO: Update the DaemonSet to trigger a rollout
Aug 31 14:46:16.310: INFO: Updating DaemonSet daemon-set
Aug 31 14:46:27.324: INFO: Roll back the DaemonSet before rollout is complete
Aug 31 14:46:27.332: INFO: Updating DaemonSet daemon-set
Aug 31 14:46:27.332: INFO: Make sure DaemonSet rollback is complete
Aug 31 14:46:27.336: INFO: Wrong image for pod: daemon-set-nz9md. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 31 14:46:27.337: INFO: Pod daemon-set-nz9md is not available
Aug 31 14:46:28.348: INFO: Wrong image for pod: daemon-set-nz9md. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug 31 14:46:28.348: INFO: Pod daemon-set-nz9md is not available
Aug 31 14:46:29.350: INFO: Pod daemon-set-kxwdk is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3492, will wait for the garbage collector to delete the pods
Aug 31 14:46:29.419: INFO: Deleting DaemonSet.extensions daemon-set took: 5.208718ms
Aug 31 14:46:29.519: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.274655ms
Aug 31 14:46:40.123: INFO: Number of nodes with available pods: 0
Aug 31 14:46:40.123: INFO: Number of running nodes: 0, number of available pods: 0
Aug 31 14:46:40.125: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3492/daemonsets","resourceVersion":"30348"},"items":null}

Aug 31 14:46:40.127: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3492/pods","resourceVersion":"30348"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:46:40.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3492" for this suite.
Aug 31 14:46:46.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:46:46.229: INFO: namespace daemonsets-3492 deletion completed in 6.085598291s

• [SLOW TEST:33.056 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:46:46.230: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0831 14:47:16.292897      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 31 14:47:16.292: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:47:16.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4953" for this suite.
Aug 31 14:47:22.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:47:22.382: INFO: namespace gc-4953 deletion completed in 6.082962878s

• [SLOW TEST:36.152 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:47:22.382: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-9d07e3c7-4336-4540-b82d-a75bd0159ae6
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-9d07e3c7-4336-4540-b82d-a75bd0159ae6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:47:26.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1337" for this suite.
Aug 31 14:47:48.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:47:48.530: INFO: namespace projected-1337 deletion completed in 22.06734297s

• [SLOW TEST:26.148 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:47:48.531: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2770
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 31 14:47:48.556: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 31 14:48:12.650: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.62:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:48:12.650: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:48:12.730: INFO: Found all expected endpoints: [netserver-0]
Aug 31 14:48:12.733: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.218:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:48:12.733: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:48:12.799: INFO: Found all expected endpoints: [netserver-1]
Aug 31 14:48:12.802: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.56:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:48:12.804: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:48:12.892: INFO: Found all expected endpoints: [netserver-2]
Aug 31 14:48:12.896: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.135:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2770 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 14:48:12.896: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 14:48:12.996: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:48:12.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2770" for this suite.
Aug 31 14:48:35.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:48:35.073: INFO: namespace pod-network-test-2770 deletion completed in 22.072234003s

• [SLOW TEST:46.542 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:48:35.074: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug 31 14:48:35.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-7865'
Aug 31 14:48:35.214: INFO: stderr: ""
Aug 31 14:48:35.214: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug 31 14:48:35.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7865'
Aug 31 14:48:35.292: INFO: stderr: ""
Aug 31 14:48:35.292: INFO: stdout: "update-demo-nautilus-m922m update-demo-nautilus-tgmv8 "
Aug 31 14:48:35.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-m922m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7865'
Aug 31 14:48:35.350: INFO: stderr: ""
Aug 31 14:48:35.350: INFO: stdout: ""
Aug 31 14:48:35.350: INFO: update-demo-nautilus-m922m is created but not running
Aug 31 14:48:40.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7865'
Aug 31 14:48:40.401: INFO: stderr: ""
Aug 31 14:48:40.401: INFO: stdout: "update-demo-nautilus-m922m update-demo-nautilus-tgmv8 "
Aug 31 14:48:40.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-m922m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7865'
Aug 31 14:48:40.457: INFO: stderr: ""
Aug 31 14:48:40.457: INFO: stdout: "true"
Aug 31 14:48:40.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-m922m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7865'
Aug 31 14:48:40.512: INFO: stderr: ""
Aug 31 14:48:40.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:48:40.512: INFO: validating pod update-demo-nautilus-m922m
Aug 31 14:48:40.517: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:48:40.517: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:48:40.517: INFO: update-demo-nautilus-m922m is verified up and running
Aug 31 14:48:40.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-tgmv8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7865'
Aug 31 14:48:40.574: INFO: stderr: ""
Aug 31 14:48:40.574: INFO: stdout: "true"
Aug 31 14:48:40.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods update-demo-nautilus-tgmv8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7865'
Aug 31 14:48:40.629: INFO: stderr: ""
Aug 31 14:48:40.630: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug 31 14:48:40.630: INFO: validating pod update-demo-nautilus-tgmv8
Aug 31 14:48:40.635: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug 31 14:48:40.635: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug 31 14:48:40.635: INFO: update-demo-nautilus-tgmv8 is verified up and running
STEP: using delete to clean up resources
Aug 31 14:48:40.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-7865'
Aug 31 14:48:40.695: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 14:48:40.695: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug 31 14:48:40.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7865'
Aug 31 14:48:40.777: INFO: stderr: "No resources found.\n"
Aug 31 14:48:40.777: INFO: stdout: ""
Aug 31 14:48:40.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -l name=update-demo --namespace=kubectl-7865 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 31 14:48:40.844: INFO: stderr: ""
Aug 31 14:48:40.844: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:48:40.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7865" for this suite.
Aug 31 14:49:02.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:49:02.926: INFO: namespace kubectl-7865 deletion completed in 22.077142005s

• [SLOW TEST:27.853 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:49:02.928: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:49:02.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670" in namespace "projected-6111" to be "success or failure"
Aug 31 14:49:02.973: INFO: Pod "downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670": Phase="Pending", Reason="", readiness=false. Elapsed: 10.109938ms
Aug 31 14:49:04.977: INFO: Pod "downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014096433s
STEP: Saw pod success
Aug 31 14:49:04.977: INFO: Pod "downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670" satisfied condition "success or failure"
Aug 31 14:49:04.980: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670 container client-container: <nil>
STEP: delete the pod
Aug 31 14:49:04.996: INFO: Waiting for pod downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670 to disappear
Aug 31 14:49:05.000: INFO: Pod downwardapi-volume-54dc28be-fff4-4681-b9f3-dff1067cf670 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:49:05.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6111" for this suite.
Aug 31 14:49:11.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:49:11.073: INFO: namespace projected-6111 deletion completed in 6.069182322s

• [SLOW TEST:8.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:49:11.077: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:49:34.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7596" for this suite.
Aug 31 14:49:40.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:49:40.360: INFO: namespace container-runtime-7596 deletion completed in 6.07377454s

• [SLOW TEST:29.284 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:49:40.361: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:49:40.386: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug 31 14:49:42.412: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:49:42.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2493" for this suite.
Aug 31 14:49:48.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:49:48.488: INFO: namespace replication-controller-2493 deletion completed in 6.067116816s

• [SLOW TEST:8.127 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:49:48.488: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:49:50.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9804" for this suite.
Aug 31 14:50:40.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:50:40.633: INFO: namespace kubelet-test-9804 deletion completed in 50.083993057s

• [SLOW TEST:52.145 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:50:40.634: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-339
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-339 to expose endpoints map[]
Aug 31 14:50:40.678: INFO: Get endpoints failed (7.141246ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug 31 14:50:41.683: INFO: successfully validated that service multi-endpoint-test in namespace services-339 exposes endpoints map[] (1.012072314s elapsed)
STEP: Creating pod pod1 in namespace services-339
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-339 to expose endpoints map[pod1:[100]]
Aug 31 14:50:43.712: INFO: successfully validated that service multi-endpoint-test in namespace services-339 exposes endpoints map[pod1:[100]] (2.021771186s elapsed)
STEP: Creating pod pod2 in namespace services-339
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-339 to expose endpoints map[pod1:[100] pod2:[101]]
Aug 31 14:50:45.745: INFO: successfully validated that service multi-endpoint-test in namespace services-339 exposes endpoints map[pod1:[100] pod2:[101]] (2.029410731s elapsed)
STEP: Deleting pod pod1 in namespace services-339
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-339 to expose endpoints map[pod2:[101]]
Aug 31 14:50:46.764: INFO: successfully validated that service multi-endpoint-test in namespace services-339 exposes endpoints map[pod2:[101]] (1.013520537s elapsed)
STEP: Deleting pod pod2 in namespace services-339
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-339 to expose endpoints map[]
Aug 31 14:50:47.774: INFO: successfully validated that service multi-endpoint-test in namespace services-339 exposes endpoints map[] (1.004367499s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:50:47.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-339" for this suite.
Aug 31 14:51:09.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:51:09.876: INFO: namespace services-339 deletion completed in 22.080541578s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.242 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:51:09.876: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:51:09.902: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f" in namespace "downward-api-3463" to be "success or failure"
Aug 31 14:51:09.909: INFO: Pod "downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.094885ms
Aug 31 14:51:11.912: INFO: Pod "downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010362134s
Aug 31 14:51:13.916: INFO: Pod "downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013867293s
STEP: Saw pod success
Aug 31 14:51:13.916: INFO: Pod "downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f" satisfied condition "success or failure"
Aug 31 14:51:13.918: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f container client-container: <nil>
STEP: delete the pod
Aug 31 14:51:13.936: INFO: Waiting for pod downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f to disappear
Aug 31 14:51:13.939: INFO: Pod downwardapi-volume-7cf0d038-4086-4ae9-9d13-ef8e6d7b652f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:51:13.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3463" for this suite.
Aug 31 14:51:19.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:51:20.012: INFO: namespace downward-api-3463 deletion completed in 6.069292149s

• [SLOW TEST:10.136 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:51:20.013: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 14:51:20.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-152'
Aug 31 14:51:20.223: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 31 14:51:20.223: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug 31 14:51:20.233: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug 31 14:51:20.242: INFO: scanned /root for discovery docs: <nil>
Aug 31 14:51:20.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-152'
Aug 31 14:51:35.992: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug 31 14:51:35.992: INFO: stdout: "Created e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4\nScaling up e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug 31 14:51:35.992: INFO: stdout: "Created e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4\nScaling up e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug 31 14:51:35.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-152'
Aug 31 14:51:36.043: INFO: stderr: ""
Aug 31 14:51:36.043: INFO: stdout: "e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4-d9zxz "
Aug 31 14:51:36.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4-d9zxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-152'
Aug 31 14:51:36.096: INFO: stderr: ""
Aug 31 14:51:36.096: INFO: stdout: "true"
Aug 31 14:51:36.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4-d9zxz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-152'
Aug 31 14:51:36.151: INFO: stderr: ""
Aug 31 14:51:36.151: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug 31 14:51:36.151: INFO: e2e-test-nginx-rc-16e1b1d48cff937e880459b6e220cef4-d9zxz is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Aug 31 14:51:36.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete rc e2e-test-nginx-rc --namespace=kubectl-152'
Aug 31 14:51:36.206: INFO: stderr: ""
Aug 31 14:51:36.206: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:51:36.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-152" for this suite.
Aug 31 14:51:42.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:51:42.281: INFO: namespace kubectl-152 deletion completed in 6.068167485s

• [SLOW TEST:22.268 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:51:42.282: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 31 14:51:46.336: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:46.338: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:48.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:48.343: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:50.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:50.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:52.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:52.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:54.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:54.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:56.340: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:56.343: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:51:58.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:51:58.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:52:00.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:52:00.343: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:52:02.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:52:02.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:52:04.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:52:04.342: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:52:06.340: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:52:06.345: INFO: Pod pod-with-prestop-exec-hook still exists
Aug 31 14:52:08.339: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug 31 14:52:08.342: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:52:08.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-216" for this suite.
Aug 31 14:52:30.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:52:30.415: INFO: namespace container-lifecycle-hook-216 deletion completed in 22.064513238s

• [SLOW TEST:48.134 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:52:30.416: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c0ca9c7e-6ce8-4724-aedb-de10de32bea1
STEP: Creating a pod to test consume secrets
Aug 31 14:52:30.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf" in namespace "projected-1640" to be "success or failure"
Aug 31 14:52:30.445: INFO: Pod "pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.432002ms
Aug 31 14:52:32.449: INFO: Pod "pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007458023s
STEP: Saw pod success
Aug 31 14:52:32.449: INFO: Pod "pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf" satisfied condition "success or failure"
Aug 31 14:52:32.452: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 31 14:52:32.467: INFO: Waiting for pod pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf to disappear
Aug 31 14:52:32.470: INFO: Pod pod-projected-secrets-6bf7187e-6ac3-4fec-9d69-0991b5762cbf no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:52:32.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1640" for this suite.
Aug 31 14:52:38.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:52:38.547: INFO: namespace projected-1640 deletion completed in 6.072919149s

• [SLOW TEST:8.131 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:52:38.548: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 31 14:52:38.576: INFO: Waiting up to 5m0s for pod "pod-935192a6-05c2-4dc2-90f5-a056a7af56a5" in namespace "emptydir-268" to be "success or failure"
Aug 31 14:52:38.580: INFO: Pod "pod-935192a6-05c2-4dc2-90f5-a056a7af56a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.247482ms
Aug 31 14:52:40.584: INFO: Pod "pod-935192a6-05c2-4dc2-90f5-a056a7af56a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007768878s
STEP: Saw pod success
Aug 31 14:52:40.584: INFO: Pod "pod-935192a6-05c2-4dc2-90f5-a056a7af56a5" satisfied condition "success or failure"
Aug 31 14:52:40.587: INFO: Trying to get logs from node vm119042 pod pod-935192a6-05c2-4dc2-90f5-a056a7af56a5 container test-container: <nil>
STEP: delete the pod
Aug 31 14:52:40.602: INFO: Waiting for pod pod-935192a6-05c2-4dc2-90f5-a056a7af56a5 to disappear
Aug 31 14:52:40.606: INFO: Pod pod-935192a6-05c2-4dc2-90f5-a056a7af56a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:52:40.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-268" for this suite.
Aug 31 14:52:46.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:52:46.682: INFO: namespace emptydir-268 deletion completed in 6.070863081s

• [SLOW TEST:8.134 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:52:46.683: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 31 14:52:49.236: INFO: Successfully updated pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38"
Aug 31 14:52:49.236: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38" in namespace "pods-6465" to be "terminated due to deadline exceeded"
Aug 31 14:52:49.239: INFO: Pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38": Phase="Running", Reason="", readiness=true. Elapsed: 2.50997ms
Aug 31 14:52:51.242: INFO: Pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38": Phase="Running", Reason="", readiness=true. Elapsed: 2.006047023s
Aug 31 14:52:53.246: INFO: Pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009386708s
Aug 31 14:52:53.246: INFO: Pod "pod-update-activedeadlineseconds-289079eb-3d13-4acc-a6b4-839bfc0b1a38" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:52:53.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6465" for this suite.
Aug 31 14:52:59.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:52:59.318: INFO: namespace pods-6465 deletion completed in 6.068749421s

• [SLOW TEST:12.636 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:52:59.318: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:52:59.348: INFO: (0) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 4.219604ms)
Aug 31 14:52:59.352: INFO: (1) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.61525ms)
Aug 31 14:52:59.355: INFO: (2) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.428536ms)
Aug 31 14:52:59.359: INFO: (3) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.79013ms)
Aug 31 14:52:59.362: INFO: (4) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.282384ms)
Aug 31 14:52:59.366: INFO: (5) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.25627ms)
Aug 31 14:52:59.369: INFO: (6) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.126634ms)
Aug 31 14:52:59.373: INFO: (7) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.469122ms)
Aug 31 14:52:59.376: INFO: (8) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.826032ms)
Aug 31 14:52:59.380: INFO: (9) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.862024ms)
Aug 31 14:52:59.384: INFO: (10) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.915774ms)
Aug 31 14:52:59.388: INFO: (11) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.094098ms)
Aug 31 14:52:59.391: INFO: (12) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.313231ms)
Aug 31 14:52:59.394: INFO: (13) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.637959ms)
Aug 31 14:52:59.397: INFO: (14) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.973524ms)
Aug 31 14:52:59.400: INFO: (15) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.275195ms)
Aug 31 14:52:59.403: INFO: (16) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 2.907476ms)
Aug 31 14:52:59.407: INFO: (17) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.54863ms)
Aug 31 14:52:59.410: INFO: (18) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.145354ms)
Aug 31 14:52:59.414: INFO: (19) /api/v1/nodes/vm119041:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="audit.log"... (200; 3.507147ms)
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:52:59.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9284" for this suite.
Aug 31 14:53:05.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:53:05.483: INFO: namespace proxy-9284 deletion completed in 6.065561261s

• [SLOW TEST:6.165 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:53:05.484: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:53:05.567: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8" in namespace "downward-api-2779" to be "success or failure"
Aug 31 14:53:05.572: INFO: Pod "downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.033681ms
Aug 31 14:53:07.576: INFO: Pod "downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008292823s
STEP: Saw pod success
Aug 31 14:53:07.576: INFO: Pod "downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8" satisfied condition "success or failure"
Aug 31 14:53:07.578: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8 container client-container: <nil>
STEP: delete the pod
Aug 31 14:53:07.592: INFO: Waiting for pod downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8 to disappear
Aug 31 14:53:07.595: INFO: Pod downwardapi-volume-5e3fd24e-6310-4047-af2f-d662bca116d8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:53:07.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2779" for this suite.
Aug 31 14:53:13.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:53:13.725: INFO: namespace downward-api-2779 deletion completed in 6.125050519s

• [SLOW TEST:8.241 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:53:13.726: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:53:13.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db" in namespace "downward-api-2226" to be "success or failure"
Aug 31 14:53:13.761: INFO: Pod "downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db": Phase="Pending", Reason="", readiness=false. Elapsed: 3.025847ms
Aug 31 14:53:15.764: INFO: Pod "downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006484006s
STEP: Saw pod success
Aug 31 14:53:15.764: INFO: Pod "downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db" satisfied condition "success or failure"
Aug 31 14:53:15.766: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db container client-container: <nil>
STEP: delete the pod
Aug 31 14:53:15.779: INFO: Waiting for pod downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db to disappear
Aug 31 14:53:15.782: INFO: Pod downwardapi-volume-c3a62746-386d-4346-aca6-7a294a8075db no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:53:15.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2226" for this suite.
Aug 31 14:53:21.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:53:21.859: INFO: namespace downward-api-2226 deletion completed in 6.071797589s

• [SLOW TEST:8.133 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:53:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 14:53:21.885: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug 31 14:53:26.888: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 31 14:53:26.888: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug 31 14:53:28.892: INFO: Creating deployment "test-rollover-deployment"
Aug 31 14:53:28.897: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug 31 14:53:30.903: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug 31 14:53:30.908: INFO: Ensure that both replica sets have 1 created replica
Aug 31 14:53:30.912: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug 31 14:53:30.918: INFO: Updating deployment test-rollover-deployment
Aug 31 14:53:30.918: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug 31 14:53:32.927: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug 31 14:53:32.932: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug 31 14:53:32.937: INFO: all replica sets need to contain the pod-template-hash label
Aug 31 14:53:32.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554411, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 14:53:34.942: INFO: all replica sets need to contain the pod-template-hash label
Aug 31 14:53:34.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554411, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 14:53:36.942: INFO: all replica sets need to contain the pod-template-hash label
Aug 31 14:53:36.942: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554411, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 14:53:38.943: INFO: all replica sets need to contain the pod-template-hash label
Aug 31 14:53:38.943: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554411, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 14:53:40.943: INFO: all replica sets need to contain the pod-template-hash label
Aug 31 14:53:40.943: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554411, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797554408, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 14:53:42.942: INFO: 
Aug 31 14:53:42.942: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 31 14:53:42.948: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-5807,SelfLink:/apis/apps/v1/namespaces/deployment-5807/deployments/test-rollover-deployment,UID:d6b89da6-db61-4724-98e7-78c0f959ecf0,ResourceVersion:31879,Generation:2,CreationTimestamp:2022-08-31 14:53:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2022-08-31 14:53:28 +0000 UTC 2022-08-31 14:53:28 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-31 14:53:41 +0000 UTC 2022-08-31 14:53:28 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 31 14:53:42.951: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-5807,SelfLink:/apis/apps/v1/namespaces/deployment-5807/replicasets/test-rollover-deployment-854595fc44,UID:afa35c8a-921e-48f2-8949-75d97cffb7d9,ResourceVersion:31868,Generation:2,CreationTimestamp:2022-08-31 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6b89da6-db61-4724-98e7-78c0f959ecf0 0xc0027b3da7 0xc0027b3da8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 31 14:53:42.951: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug 31 14:53:42.951: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-5807,SelfLink:/apis/apps/v1/namespaces/deployment-5807/replicasets/test-rollover-controller,UID:8eaed1a4-493f-4217-8b2d-e3e5e808ed75,ResourceVersion:31878,Generation:2,CreationTimestamp:2022-08-31 14:53:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6b89da6-db61-4724-98e7-78c0f959ecf0 0xc0027b3cd7 0xc0027b3cd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 14:53:42.951: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-5807,SelfLink:/apis/apps/v1/namespaces/deployment-5807/replicasets/test-rollover-deployment-9b8b997cf,UID:8eca9444-6033-488b-87aa-f1a3698579fd,ResourceVersion:31833,Generation:2,CreationTimestamp:2022-08-31 14:53:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment d6b89da6-db61-4724-98e7-78c0f959ecf0 0xc0027b3e70 0xc0027b3e71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 14:53:42.955: INFO: Pod "test-rollover-deployment-854595fc44-97rbh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-97rbh,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-5807,SelfLink:/api/v1/namespaces/deployment-5807/pods/test-rollover-deployment-854595fc44-97rbh,UID:b0578922-868b-432b-aa56-bf4690587912,ResourceVersion:31847,Generation:0,CreationTimestamp:2022-08-31 14:53:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 afa35c8a-921e-48f2-8949-75d97cffb7d9 0xc002e32a57 0xc002e32a58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tq6s7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tq6s7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-tq6s7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e32ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e32af0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:53:30 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:53:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:53:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:53:30 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:10.244.1.238,StartTime:2022-08-31 14:53:30 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2022-08-31 14:53:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://63e6514315e3a55d19b0d0aebb4f049157b65bc523b4a2b403542a8bd0f25235}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:53:42.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5807" for this suite.
Aug 31 14:53:48.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:53:49.038: INFO: namespace deployment-5807 deletion completed in 6.078625564s

• [SLOW TEST:27.179 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:53:49.038: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug 31 14:53:49.133: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4599,SelfLink:/api/v1/namespaces/watch-4599/configmaps/e2e-watch-test-resource-version,UID:dd7d1e0d-3acb-46b6-ad56-3cf0b13b75b0,ResourceVersion:31932,Generation:0,CreationTimestamp:2022-08-31 14:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 31 14:53:49.133: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4599,SelfLink:/api/v1/namespaces/watch-4599/configmaps/e2e-watch-test-resource-version,UID:dd7d1e0d-3acb-46b6-ad56-3cf0b13b75b0,ResourceVersion:31933,Generation:0,CreationTimestamp:2022-08-31 14:53:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:53:49.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4599" for this suite.
Aug 31 14:53:55.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:53:55.206: INFO: namespace watch-4599 deletion completed in 6.069634061s

• [SLOW TEST:6.168 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:53:55.206: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 31 14:54:01.245: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0831 14:54:01.245768      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:01.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9381" for this suite.
Aug 31 14:54:07.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:54:07.316: INFO: namespace gc-9381 deletion completed in 6.068256637s

• [SLOW TEST:12.110 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:54:07.317: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-1130f632-cc25-4071-8329-fc08faf1b6bd
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:07.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4499" for this suite.
Aug 31 14:54:13.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:54:13.459: INFO: namespace configmap-4499 deletion completed in 6.064548779s

• [SLOW TEST:6.142 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:54:13.460: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug 31 14:54:13.485: INFO: Waiting up to 5m0s for pod "var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7" in namespace "var-expansion-3833" to be "success or failure"
Aug 31 14:54:13.491: INFO: Pod "var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.59416ms
Aug 31 14:54:15.495: INFO: Pod "var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009687066s
STEP: Saw pod success
Aug 31 14:54:15.495: INFO: Pod "var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7" satisfied condition "success or failure"
Aug 31 14:54:15.498: INFO: Trying to get logs from node vm119042 pod var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7 container dapi-container: <nil>
STEP: delete the pod
Aug 31 14:54:15.514: INFO: Waiting for pod var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7 to disappear
Aug 31 14:54:15.516: INFO: Pod var-expansion-10ba0c98-4f7b-41d1-9aa5-ddf4141833e7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:15.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3833" for this suite.
Aug 31 14:54:21.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:54:21.589: INFO: namespace var-expansion-3833 deletion completed in 6.06947396s

• [SLOW TEST:8.129 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:54:21.589: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug 31 14:54:23.647: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059459328 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug 31 14:54:38.707: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:38.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7980" for this suite.
Aug 31 14:54:44.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:54:44.796: INFO: namespace pods-7980 deletion completed in 6.080105594s

• [SLOW TEST:23.207 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:54:44.796: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 31 14:54:46.841: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:46.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2654" for this suite.
Aug 31 14:54:52.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:54:52.929: INFO: namespace container-runtime-2654 deletion completed in 6.075750207s

• [SLOW TEST:8.134 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:54:52.930: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:54:52.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c" in namespace "downward-api-3388" to be "success or failure"
Aug 31 14:54:52.967: INFO: Pod "downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.37415ms
Aug 31 14:54:54.971: INFO: Pod "downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006719432s
STEP: Saw pod success
Aug 31 14:54:54.971: INFO: Pod "downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c" satisfied condition "success or failure"
Aug 31 14:54:54.975: INFO: Trying to get logs from node vm119044 pod downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c container client-container: <nil>
STEP: delete the pod
Aug 31 14:54:54.993: INFO: Waiting for pod downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c to disappear
Aug 31 14:54:54.995: INFO: Pod downwardapi-volume-33df4b51-8575-4ea1-8e0c-276fa75be20c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:54:54.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3388" for this suite.
Aug 31 14:55:01.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:55:01.077: INFO: namespace downward-api-3388 deletion completed in 6.078283763s

• [SLOW TEST:8.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:55:01.078: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:55:01.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6" in namespace "projected-65" to be "success or failure"
Aug 31 14:55:01.118: INFO: Pod "downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.667006ms
Aug 31 14:55:03.122: INFO: Pod "downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009072043s
STEP: Saw pod success
Aug 31 14:55:03.122: INFO: Pod "downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6" satisfied condition "success or failure"
Aug 31 14:55:03.124: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6 container client-container: <nil>
STEP: delete the pod
Aug 31 14:55:03.142: INFO: Waiting for pod downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6 to disappear
Aug 31 14:55:03.145: INFO: Pod downwardapi-volume-c0bae6d3-0a61-4fac-a8b6-b2663875aca6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:55:03.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-65" for this suite.
Aug 31 14:55:09.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:55:09.219: INFO: namespace projected-65 deletion completed in 6.070659954s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:55:09.219: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6136
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-6136
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6136
Aug 31 14:55:09.259: INFO: Found 0 stateful pods, waiting for 1
Aug 31 14:55:19.263: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug 31 14:55:19.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 14:55:19.398: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 14:55:19.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 14:55:19.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 14:55:19.404: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 31 14:55:29.409: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 14:55:29.409: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 14:55:29.420: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 31 14:55:29.420: INFO: ss-0  vm119042  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  }]
Aug 31 14:55:29.420: INFO: 
Aug 31 14:55:29.420: INFO: StatefulSet ss has not reached scale 3, at 1
Aug 31 14:55:30.424: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996752882s
Aug 31 14:55:31.429: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992419955s
Aug 31 14:55:32.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988443002s
Aug 31 14:55:33.436: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984832599s
Aug 31 14:55:34.440: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980977914s
Aug 31 14:55:35.444: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976832603s
Aug 31 14:55:36.448: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973172319s
Aug 31 14:55:37.452: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.969106644s
Aug 31 14:55:38.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.475104ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6136
Aug 31 14:55:39.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 14:55:39.589: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 14:55:39.589: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 14:55:39.589: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 14:55:39.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 14:55:39.735: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 31 14:55:39.735: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 14:55:39.735: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 14:55:39.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 14:55:39.881: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug 31 14:55:39.881: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 14:55:39.881: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 14:55:39.886: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Aug 31 14:55:49.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:55:49.891: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 14:55:49.891: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug 31 14:55:49.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 14:55:50.017: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 14:55:50.017: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 14:55:50.018: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 14:55:50.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 14:55:50.216: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 14:55:50.216: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 14:55:50.216: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 14:55:50.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-6136 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 14:55:50.368: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 14:55:50.368: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 14:55:50.368: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 14:55:50.368: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 14:55:50.371: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 31 14:56:00.377: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 14:56:00.377: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 14:56:00.377: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 14:56:00.385: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 31 14:56:00.385: INFO: ss-0  vm119042  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  }]
Aug 31 14:56:00.385: INFO: ss-1  vm119044  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  }]
Aug 31 14:56:00.385: INFO: ss-2  vm119041  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  }]
Aug 31 14:56:00.385: INFO: 
Aug 31 14:56:00.385: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 31 14:56:01.389: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 31 14:56:01.389: INFO: ss-0  vm119042  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  }]
Aug 31 14:56:01.389: INFO: ss-1  vm119044  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  }]
Aug 31 14:56:01.389: INFO: ss-2  vm119041  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  }]
Aug 31 14:56:01.389: INFO: 
Aug 31 14:56:01.389: INFO: StatefulSet ss has not reached scale 0, at 3
Aug 31 14:56:02.393: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Aug 31 14:56:02.393: INFO: ss-0  vm119042  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:09 +0000 UTC  }]
Aug 31 14:56:02.393: INFO: ss-2  vm119041  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:50 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 14:55:29 +0000 UTC  }]
Aug 31 14:56:02.393: INFO: 
Aug 31 14:56:02.393: INFO: StatefulSet ss has not reached scale 0, at 2
Aug 31 14:56:03.404: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.9889029s
Aug 31 14:56:04.408: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978664193s
Aug 31 14:56:05.411: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.974631882s
Aug 31 14:56:06.415: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.971070701s
Aug 31 14:56:07.418: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.967591123s
Aug 31 14:56:08.421: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.964371859s
Aug 31 14:56:09.424: INFO: Verifying statefulset ss doesn't scale past 0 for another 961.401964ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6136
Aug 31 14:56:10.427: INFO: Scaling statefulset ss to 0
Aug 31 14:56:10.438: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 31 14:56:10.440: INFO: Deleting all statefulset in ns statefulset-6136
Aug 31 14:56:10.443: INFO: Scaling statefulset ss to 0
Aug 31 14:56:10.452: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 14:56:10.457: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:56:10.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6136" for this suite.
Aug 31 14:56:16.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:56:16.550: INFO: namespace statefulset-6136 deletion completed in 6.07411769s

• [SLOW TEST:67.331 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:56:16.551: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:56:16.583: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542" in namespace "downward-api-7187" to be "success or failure"
Aug 31 14:56:16.589: INFO: Pod "downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542": Phase="Pending", Reason="", readiness=false. Elapsed: 6.193386ms
Aug 31 14:56:18.593: INFO: Pod "downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009663017s
STEP: Saw pod success
Aug 31 14:56:18.593: INFO: Pod "downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542" satisfied condition "success or failure"
Aug 31 14:56:18.595: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542 container client-container: <nil>
STEP: delete the pod
Aug 31 14:56:18.610: INFO: Waiting for pod downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542 to disappear
Aug 31 14:56:18.613: INFO: Pod downwardapi-volume-b8ba484a-adfd-413a-9c3f-59b2aae2a542 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:56:18.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7187" for this suite.
Aug 31 14:56:24.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:56:24.687: INFO: namespace downward-api-7187 deletion completed in 6.069900808s

• [SLOW TEST:8.136 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:56:24.688: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 14:56:24.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2" in namespace "downward-api-5316" to be "success or failure"
Aug 31 14:56:24.720: INFO: Pod "downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.822114ms
Aug 31 14:56:26.725: INFO: Pod "downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008451237s
STEP: Saw pod success
Aug 31 14:56:26.725: INFO: Pod "downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2" satisfied condition "success or failure"
Aug 31 14:56:26.727: INFO: Trying to get logs from node vm119044 pod downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2 container client-container: <nil>
STEP: delete the pod
Aug 31 14:56:26.740: INFO: Waiting for pod downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2 to disappear
Aug 31 14:56:26.743: INFO: Pod downwardapi-volume-1a9beaf7-6cb0-4423-95e9-543e7896ede2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:56:26.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5316" for this suite.
Aug 31 14:56:32.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:56:32.827: INFO: namespace downward-api-5316 deletion completed in 6.081293593s

• [SLOW TEST:8.139 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:56:32.829: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 31 14:56:32.909: INFO: Waiting up to 5m0s for pod "downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac" in namespace "downward-api-7392" to be "success or failure"
Aug 31 14:56:32.913: INFO: Pod "downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.5647ms
Aug 31 14:56:34.916: INFO: Pod "downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006758876s
STEP: Saw pod success
Aug 31 14:56:34.916: INFO: Pod "downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac" satisfied condition "success or failure"
Aug 31 14:56:34.918: INFO: Trying to get logs from node vm119042 pod downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac container dapi-container: <nil>
STEP: delete the pod
Aug 31 14:56:34.932: INFO: Waiting for pod downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac to disappear
Aug 31 14:56:34.935: INFO: Pod downward-api-de24dabb-3f9d-485b-aeda-93a58cf403ac no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:56:34.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7392" for this suite.
Aug 31 14:56:40.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:56:41.006: INFO: namespace downward-api-7392 deletion completed in 6.066308857s

• [SLOW TEST:8.177 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:56:41.007: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug 31 14:56:43.553: INFO: Successfully updated pod "pod-update-dd9c654c-44cc-4977-accb-f21fa2778f61"
STEP: verifying the updated pod is in kubernetes
Aug 31 14:56:43.559: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:56:43.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4391" for this suite.
Aug 31 14:57:05.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:57:05.631: INFO: namespace pods-4391 deletion completed in 22.067837568s

• [SLOW TEST:24.624 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:57:05.632: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-350d4d66-18dd-4f4d-9125-7f29705c39c3
STEP: Creating configMap with name cm-test-opt-upd-ca443cfc-139a-4486-ad78-f2740d3a1752
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-350d4d66-18dd-4f4d-9125-7f29705c39c3
STEP: Updating configmap cm-test-opt-upd-ca443cfc-139a-4486-ad78-f2740d3a1752
STEP: Creating configMap with name cm-test-opt-create-c9ff6e2e-8089-4855-b902-75858c2787bc
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:57:11.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3133" for this suite.
Aug 31 14:57:33.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:57:33.822: INFO: namespace projected-3133 deletion completed in 22.068290931s

• [SLOW TEST:28.190 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:57:33.822: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Aug 31 14:57:33.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3735'
Aug 31 14:57:33.961: INFO: stderr: ""
Aug 31 14:57:33.961: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug 31 14:57:34.964: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 14:57:34.964: INFO: Found 0 / 1
Aug 31 14:57:35.966: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 14:57:35.966: INFO: Found 1 / 1
Aug 31 14:57:35.966: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 31 14:57:35.969: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 14:57:35.969: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug 31 14:57:35.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735'
Aug 31 14:57:36.032: INFO: stderr: ""
Aug 31 14:57:36.032: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Aug 14:57:34.605 # Server started, Redis version 3.2.12\n1:M 31 Aug 14:57:34.605 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Aug 14:57:34.605 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug 31 14:57:36.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735 --tail=1'
Aug 31 14:57:36.099: INFO: stderr: ""
Aug 31 14:57:36.099: INFO: stdout: "1:M 31 Aug 14:57:34.605 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug 31 14:57:36.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735 --limit-bytes=1'
Aug 31 14:57:36.162: INFO: stderr: ""
Aug 31 14:57:36.162: INFO: stdout: " "
STEP: exposing timestamps
Aug 31 14:57:36.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735 --tail=1 --timestamps'
Aug 31 14:57:36.222: INFO: stderr: ""
Aug 31 14:57:36.222: INFO: stdout: "2022-08-31T14:57:34.606620811Z 1:M 31 Aug 14:57:34.605 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug 31 14:57:38.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735 --since=1s'
Aug 31 14:57:38.783: INFO: stderr: ""
Aug 31 14:57:38.783: INFO: stdout: ""
Aug 31 14:57:38.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-6gpkr redis-master --namespace=kubectl-3735 --since=24h'
Aug 31 14:57:38.842: INFO: stderr: ""
Aug 31 14:57:38.842: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Aug 14:57:34.605 # Server started, Redis version 3.2.12\n1:M 31 Aug 14:57:34.605 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Aug 14:57:34.605 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Aug 31 14:57:38.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3735'
Aug 31 14:57:38.905: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 14:57:38.905: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug 31 14:57:38.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3735'
Aug 31 14:57:38.965: INFO: stderr: "No resources found.\n"
Aug 31 14:57:38.965: INFO: stdout: ""
Aug 31 14:57:38.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -l name=nginx --namespace=kubectl-3735 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 31 14:57:39.021: INFO: stderr: ""
Aug 31 14:57:39.021: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:57:39.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3735" for this suite.
Aug 31 14:57:45.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:57:45.102: INFO: namespace kubectl-3735 deletion completed in 6.073930602s

• [SLOW TEST:11.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:57:45.102: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug 31 14:57:48.152: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:57:48.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8748" for this suite.
Aug 31 14:58:10.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:58:10.253: INFO: namespace replicaset-8748 deletion completed in 22.076227909s

• [SLOW TEST:25.151 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:58:10.254: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug 31 14:58:10.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 api-versions'
Aug 31 14:58:10.329: INFO: stderr: ""
Aug 31 14:58:10.329: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:58:10.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2654" for this suite.
Aug 31 14:58:16.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:58:16.407: INFO: namespace kubectl-2654 deletion completed in 6.067853458s

• [SLOW TEST:6.154 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:58:16.408: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 14:58:16.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6523'
Aug 31 14:58:16.547: INFO: stderr: ""
Aug 31 14:58:16.547: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Aug 31 14:58:16.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete pods e2e-test-nginx-pod --namespace=kubectl-6523'
Aug 31 14:58:26.344: INFO: stderr: ""
Aug 31 14:58:26.344: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:58:26.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6523" for this suite.
Aug 31 14:58:32.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:58:32.417: INFO: namespace kubectl-6523 deletion completed in 6.068632527s

• [SLOW TEST:16.008 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:58:32.417: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-bq2s
STEP: Creating a pod to test atomic-volume-subpath
Aug 31 14:58:32.452: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-bq2s" in namespace "subpath-8099" to be "success or failure"
Aug 31 14:58:32.455: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Pending", Reason="", readiness=false. Elapsed: 2.69215ms
Aug 31 14:58:34.459: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 2.006445812s
Aug 31 14:58:36.462: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 4.010012987s
Aug 31 14:58:38.466: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 6.013233042s
Aug 31 14:58:40.470: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 8.017173291s
Aug 31 14:58:42.473: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 10.021129113s
Aug 31 14:58:44.477: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 12.024483194s
Aug 31 14:58:46.480: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 14.027317462s
Aug 31 14:58:48.484: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 16.031200016s
Aug 31 14:58:50.487: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 18.034842876s
Aug 31 14:58:52.491: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Running", Reason="", readiness=true. Elapsed: 20.03824739s
Aug 31 14:58:54.494: INFO: Pod "pod-subpath-test-projected-bq2s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.041987329s
STEP: Saw pod success
Aug 31 14:58:54.494: INFO: Pod "pod-subpath-test-projected-bq2s" satisfied condition "success or failure"
Aug 31 14:58:54.498: INFO: Trying to get logs from node vm119042 pod pod-subpath-test-projected-bq2s container test-container-subpath-projected-bq2s: <nil>
STEP: delete the pod
Aug 31 14:58:54.511: INFO: Waiting for pod pod-subpath-test-projected-bq2s to disappear
Aug 31 14:58:54.514: INFO: Pod pod-subpath-test-projected-bq2s no longer exists
STEP: Deleting pod pod-subpath-test-projected-bq2s
Aug 31 14:58:54.514: INFO: Deleting pod "pod-subpath-test-projected-bq2s" in namespace "subpath-8099"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:58:54.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8099" for this suite.
Aug 31 14:59:00.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:59:00.588: INFO: namespace subpath-8099 deletion completed in 6.068467215s

• [SLOW TEST:28.171 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:59:00.588: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 31 14:59:03.142: INFO: Successfully updated pod "labelsupdatec47ea902-9da2-4100-9ba6-7c5dae8c44a7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:59:07.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9903" for this suite.
Aug 31 14:59:29.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:59:29.239: INFO: namespace projected-9903 deletion completed in 22.072903353s

• [SLOW TEST:28.651 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:59:29.241: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4865
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4865
STEP: Creating statefulset with conflicting port in namespace statefulset-4865
STEP: Waiting until pod test-pod will start running in namespace statefulset-4865
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4865
Aug 31 14:59:33.334: INFO: Observed stateful pod in namespace: statefulset-4865, name: ss-0, uid: 631fba63-58ae-45c8-9cc9-d087c322c79e, status phase: Failed. Waiting for statefulset controller to delete.
Aug 31 14:59:33.335: INFO: Observed stateful pod in namespace: statefulset-4865, name: ss-0, uid: 631fba63-58ae-45c8-9cc9-d087c322c79e, status phase: Failed. Waiting for statefulset controller to delete.
Aug 31 14:59:33.340: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4865
STEP: Removing pod with conflicting port in namespace statefulset-4865
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4865 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 31 14:59:35.359: INFO: Deleting all statefulset in ns statefulset-4865
Aug 31 14:59:35.362: INFO: Scaling statefulset ss to 0
Aug 31 14:59:45.375: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 14:59:45.377: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:59:45.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4865" for this suite.
Aug 31 14:59:51.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 14:59:51.460: INFO: namespace statefulset-4865 deletion completed in 6.070963182s

• [SLOW TEST:22.219 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 14:59:51.461: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 31 14:59:54.014: INFO: Successfully updated pod "annotationupdate86901106-31f7-41c5-8bc5-f46006921158"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 14:59:58.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9361" for this suite.
Aug 31 15:00:20.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:00:20.109: INFO: namespace projected-9361 deletion completed in 22.072971836s

• [SLOW TEST:28.648 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:00:20.109: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:00:20.145: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug 31 15:00:20.156: INFO: Number of nodes with available pods: 0
Aug 31 15:00:20.156: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:00:21.163: INFO: Number of nodes with available pods: 0
Aug 31 15:00:21.163: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:00:22.163: INFO: Number of nodes with available pods: 4
Aug 31 15:00:22.163: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug 31 15:00:22.183: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:22.183: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:22.183: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:22.183: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:23.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:23.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:23.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:23.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:24.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:24.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:24.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:24.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:25.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:25.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:25.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:25.192: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:25.192: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:26.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:26.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:26.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:26.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:26.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:27.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:27.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:27.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:27.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:27.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:28.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:28.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:28.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:28.192: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:28.192: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:29.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:29.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:29.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:29.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:29.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:30.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:30.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:30.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:30.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:30.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:31.193: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:31.193: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:31.193: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:31.193: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:31.193: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:32.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:32.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:32.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:32.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:32.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:33.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:33.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:33.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:33.192: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:33.192: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:34.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:34.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:34.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:34.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:34.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:35.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:35.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:35.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:35.192: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:35.192: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:36.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:36.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:36.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:36.191: INFO: Wrong image for pod: daemon-set-jpczb. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:36.191: INFO: Pod daemon-set-jpczb is not available
Aug 31 15:00:37.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:37.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:37.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:37.191: INFO: Pod daemon-set-n6824 is not available
Aug 31 15:00:38.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:38.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:38.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:39.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:39.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:39.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:39.192: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:40.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:40.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:40.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:40.192: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:41.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:41.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:41.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:41.192: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:42.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:42.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:42.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:42.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:43.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:43.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:43.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:43.192: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:44.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:44.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:44.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:44.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:45.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:45.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:45.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:45.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:46.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:46.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:46.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:46.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:47.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:47.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:47.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:47.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:48.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:48.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:48.191: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:48.191: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:49.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:49.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:49.192: INFO: Wrong image for pod: daemon-set-65c6x. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:49.192: INFO: Pod daemon-set-65c6x is not available
Aug 31 15:00:50.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:50.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:50.191: INFO: Pod daemon-set-wp9d9 is not available
Aug 31 15:00:51.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:51.192: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:51.192: INFO: Pod daemon-set-wp9d9 is not available
Aug 31 15:00:52.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:52.191: INFO: Wrong image for pod: daemon-set-58ghh. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:52.191: INFO: Pod daemon-set-58ghh is not available
Aug 31 15:00:53.195: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:53.195: INFO: Pod daemon-set-mfwgs is not available
Aug 31 15:00:54.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:55.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:55.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:00:56.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:56.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:00:57.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:57.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:00:58.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:58.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:00:59.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:00:59.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:00.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:00.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:01.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:01.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:02.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:02.192: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:03.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:03.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:04.191: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:04.191: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:05.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:05.192: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:06.192: INFO: Wrong image for pod: daemon-set-42dph. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug 31 15:01:06.192: INFO: Pod daemon-set-42dph is not available
Aug 31 15:01:07.191: INFO: Pod daemon-set-m22nk is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug 31 15:01:07.200: INFO: Number of nodes with available pods: 3
Aug 31 15:01:07.200: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:01:08.207: INFO: Number of nodes with available pods: 4
Aug 31 15:01:08.207: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8043, will wait for the garbage collector to delete the pods
Aug 31 15:01:08.280: INFO: Deleting DaemonSet.extensions daemon-set took: 5.88163ms
Aug 31 15:01:08.381: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.145672ms
Aug 31 15:01:20.084: INFO: Number of nodes with available pods: 0
Aug 31 15:01:20.084: INFO: Number of running nodes: 0, number of available pods: 0
Aug 31 15:01:20.087: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8043/daemonsets","resourceVersion":"34128"},"items":null}

Aug 31 15:01:20.089: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8043/pods","resourceVersion":"34128"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:01:20.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8043" for this suite.
Aug 31 15:01:26.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:01:26.177: INFO: namespace daemonsets-8043 deletion completed in 6.072350321s

• [SLOW TEST:66.068 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:01:26.179: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug 31 15:01:26.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34200,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 31 15:01:26.213: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34200,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug 31 15:01:36.220: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34216,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 31 15:01:36.220: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34216,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug 31 15:01:46.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34233,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 31 15:01:46.229: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34233,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug 31 15:01:56.234: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34249,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 31 15:01:56.235: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-a,UID:23074c7a-599f-4665-b436-aa5e7a24efe5,ResourceVersion:34249,Generation:0,CreationTimestamp:2022-08-31 15:01:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug 31 15:02:06.245: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-b,UID:a77e1ff8-2f02-4fe2-864e-52e79b379698,ResourceVersion:34267,Generation:0,CreationTimestamp:2022-08-31 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 31 15:02:06.245: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-b,UID:a77e1ff8-2f02-4fe2-864e-52e79b379698,ResourceVersion:34267,Generation:0,CreationTimestamp:2022-08-31 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug 31 15:02:16.255: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-b,UID:a77e1ff8-2f02-4fe2-864e-52e79b379698,ResourceVersion:34284,Generation:0,CreationTimestamp:2022-08-31 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 31 15:02:16.256: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-9333,SelfLink:/api/v1/namespaces/watch-9333/configmaps/e2e-watch-test-configmap-b,UID:a77e1ff8-2f02-4fe2-864e-52e79b379698,ResourceVersion:34284,Generation:0,CreationTimestamp:2022-08-31 15:02:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:02:26.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9333" for this suite.
Aug 31 15:02:32.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:02:32.342: INFO: namespace watch-9333 deletion completed in 6.081975038s

• [SLOW TEST:66.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:02:32.343: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-83da2546-91c6-439b-8e58-fda6e2673a36
STEP: Creating secret with name s-test-opt-upd-42e422b2-4943-4bc4-bbf2-353dc0079fba
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-83da2546-91c6-439b-8e58-fda6e2673a36
STEP: Updating secret s-test-opt-upd-42e422b2-4943-4bc4-bbf2-353dc0079fba
STEP: Creating secret with name s-test-opt-create-45f0d622-acc5-4831-a306-a0be21371a26
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:02:36.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9395" for this suite.
Aug 31 15:02:58.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:02:58.521: INFO: namespace secrets-9395 deletion completed in 22.070405007s

• [SLOW TEST:26.178 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:02:58.521: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug 31 15:02:58.548: INFO: Waiting up to 5m0s for pod "client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640" in namespace "containers-3107" to be "success or failure"
Aug 31 15:02:58.556: INFO: Pod "client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640": Phase="Pending", Reason="", readiness=false. Elapsed: 7.948029ms
Aug 31 15:03:00.560: INFO: Pod "client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011818875s
STEP: Saw pod success
Aug 31 15:03:00.560: INFO: Pod "client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640" satisfied condition "success or failure"
Aug 31 15:03:00.564: INFO: Trying to get logs from node vm119042 pod client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640 container test-container: <nil>
STEP: delete the pod
Aug 31 15:03:00.577: INFO: Waiting for pod client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640 to disappear
Aug 31 15:03:00.579: INFO: Pod client-containers-45af730f-7cf5-4853-a8bf-30e4c3e3d640 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:03:00.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3107" for this suite.
Aug 31 15:03:06.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:03:06.652: INFO: namespace containers-3107 deletion completed in 6.070147216s

• [SLOW TEST:8.134 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:03:06.658: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 15:03:06.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-8638'
Aug 31 15:03:06.803: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 31 15:03:06.803: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Aug 31 15:03:08.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete deployment e2e-test-nginx-deployment --namespace=kubectl-8638'
Aug 31 15:03:08.876: INFO: stderr: ""
Aug 31 15:03:08.876: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:03:08.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8638" for this suite.
Aug 31 15:03:30.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:03:30.951: INFO: namespace kubectl-8638 deletion completed in 22.069845716s

• [SLOW TEST:24.293 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:03:30.952: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-1788
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1788
STEP: Deleting pre-stop pod
Aug 31 15:05:02.028: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:05:02.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1788" for this suite.
Aug 31 15:05:42.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:05:42.120: INFO: namespace prestop-1788 deletion completed in 40.072645786s

• [SLOW TEST:131.168 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:05:42.121: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:05:45.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9810" for this suite.
Aug 31 15:06:07.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:06:07.243: INFO: namespace replication-controller-9810 deletion completed in 22.072409094s

• [SLOW TEST:25.123 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:06:07.244: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 31 15:06:07.277: INFO: Waiting up to 5m0s for pod "downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27" in namespace "downward-api-1390" to be "success or failure"
Aug 31 15:06:07.280: INFO: Pod "downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27": Phase="Pending", Reason="", readiness=false. Elapsed: 3.466367ms
Aug 31 15:06:09.286: INFO: Pod "downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008822373s
STEP: Saw pod success
Aug 31 15:06:09.286: INFO: Pod "downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27" satisfied condition "success or failure"
Aug 31 15:06:09.290: INFO: Trying to get logs from node vm119043 pod downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27 container dapi-container: <nil>
STEP: delete the pod
Aug 31 15:06:09.309: INFO: Waiting for pod downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27 to disappear
Aug 31 15:06:09.312: INFO: Pod downward-api-7cfa3fe0-d5be-4319-b190-6bc836393f27 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:06:09.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1390" for this suite.
Aug 31 15:06:15.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:06:15.386: INFO: namespace downward-api-1390 deletion completed in 6.070588089s

• [SLOW TEST:8.142 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:06:15.386: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-2b44bedc-3658-4b89-ac4b-d3339dbde48b
STEP: Creating a pod to test consume configMaps
Aug 31 15:06:15.422: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0" in namespace "projected-9478" to be "success or failure"
Aug 31 15:06:15.432: INFO: Pod "pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.896784ms
Aug 31 15:06:17.436: INFO: Pod "pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013875752s
STEP: Saw pod success
Aug 31 15:06:17.436: INFO: Pod "pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0" satisfied condition "success or failure"
Aug 31 15:06:17.439: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:06:17.452: INFO: Waiting for pod pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0 to disappear
Aug 31 15:06:17.455: INFO: Pod pod-projected-configmaps-de503bc0-2326-4c5b-922c-f27b0f5926b0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:06:17.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9478" for this suite.
Aug 31 15:06:23.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:06:23.539: INFO: namespace projected-9478 deletion completed in 6.081129946s

• [SLOW TEST:8.153 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:06:23.540: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-221ddde7-d70b-4260-b630-c841b3666e2f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-221ddde7-d70b-4260-b630-c841b3666e2f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:06:27.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5468" for this suite.
Aug 31 15:06:49.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:06:49.680: INFO: namespace configmap-5468 deletion completed in 22.06886983s

• [SLOW TEST:26.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:06:49.680: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-b2ea57b3-a1b6-45a3-9921-1c98dfbe7177
STEP: Creating a pod to test consume configMaps
Aug 31 15:06:49.709: INFO: Waiting up to 5m0s for pod "pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be" in namespace "configmap-1158" to be "success or failure"
Aug 31 15:06:49.711: INFO: Pod "pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477415ms
Aug 31 15:06:51.716: INFO: Pod "pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006815468s
Aug 31 15:06:53.719: INFO: Pod "pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009939014s
STEP: Saw pod success
Aug 31 15:06:53.719: INFO: Pod "pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be" satisfied condition "success or failure"
Aug 31 15:06:53.721: INFO: Trying to get logs from node vm119042 pod pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:06:53.735: INFO: Waiting for pod pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be to disappear
Aug 31 15:06:53.738: INFO: Pod pod-configmaps-bbb7ecb3-248f-47be-af7b-46fff88947be no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:06:53.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1158" for this suite.
Aug 31 15:06:59.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:06:59.814: INFO: namespace configmap-1158 deletion completed in 6.072175806s

• [SLOW TEST:10.134 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:06:59.814: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1194, will wait for the garbage collector to delete the pods
Aug 31 15:07:01.903: INFO: Deleting Job.batch foo took: 5.209373ms
Aug 31 15:07:02.003: INFO: Terminating Job.batch foo pods took: 100.427228ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:07:46.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1194" for this suite.
Aug 31 15:07:52.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:07:52.487: INFO: namespace job-1194 deletion completed in 6.075144034s

• [SLOW TEST:52.673 seconds]
[sig-apps] Job
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:07:52.489: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug 31 15:07:52.514: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059459328 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:07:52.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3457" for this suite.
Aug 31 15:07:58.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:07:58.649: INFO: namespace kubectl-3457 deletion completed in 6.073228602s

• [SLOW TEST:6.160 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:07:58.651: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 31 15:07:58.682: INFO: Waiting up to 5m0s for pod "downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed" in namespace "downward-api-7671" to be "success or failure"
Aug 31 15:07:58.689: INFO: Pod "downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070091ms
Aug 31 15:08:00.692: INFO: Pod "downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009722347s
STEP: Saw pod success
Aug 31 15:08:00.692: INFO: Pod "downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed" satisfied condition "success or failure"
Aug 31 15:08:00.695: INFO: Trying to get logs from node vm119043 pod downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed container dapi-container: <nil>
STEP: delete the pod
Aug 31 15:08:00.712: INFO: Waiting for pod downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed to disappear
Aug 31 15:08:00.716: INFO: Pod downward-api-bdcc57a7-b398-4bb0-b1e2-e1e79911b9ed no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:00.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7671" for this suite.
Aug 31 15:08:06.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:08:06.791: INFO: namespace downward-api-7671 deletion completed in 6.072354063s

• [SLOW TEST:8.140 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:08:06.791: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-1d87d515-d319-4729-8e39-b9221bc2bc20
STEP: Creating a pod to test consume secrets
Aug 31 15:08:06.826: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5" in namespace "projected-2540" to be "success or failure"
Aug 31 15:08:06.837: INFO: Pod "pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.632355ms
Aug 31 15:08:08.841: INFO: Pod "pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014629219s
STEP: Saw pod success
Aug 31 15:08:08.841: INFO: Pod "pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5" satisfied condition "success or failure"
Aug 31 15:08:08.843: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:08:08.860: INFO: Waiting for pod pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5 to disappear
Aug 31 15:08:08.862: INFO: Pod pod-projected-secrets-85c79c2b-3b09-4947-84a8-c65f367b17b5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:08.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2540" for this suite.
Aug 31 15:08:14.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:08:14.942: INFO: namespace projected-2540 deletion completed in 6.075892557s

• [SLOW TEST:8.151 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:08:14.942: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug 31 15:08:14.972: INFO: Waiting up to 5m0s for pod "client-containers-38cbcb63-4126-413c-9cb8-980c74818684" in namespace "containers-8393" to be "success or failure"
Aug 31 15:08:14.981: INFO: Pod "client-containers-38cbcb63-4126-413c-9cb8-980c74818684": Phase="Pending", Reason="", readiness=false. Elapsed: 8.530595ms
Aug 31 15:08:16.984: INFO: Pod "client-containers-38cbcb63-4126-413c-9cb8-980c74818684": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012424269s
STEP: Saw pod success
Aug 31 15:08:16.985: INFO: Pod "client-containers-38cbcb63-4126-413c-9cb8-980c74818684" satisfied condition "success or failure"
Aug 31 15:08:16.990: INFO: Trying to get logs from node vm119042 pod client-containers-38cbcb63-4126-413c-9cb8-980c74818684 container test-container: <nil>
STEP: delete the pod
Aug 31 15:08:17.006: INFO: Waiting for pod client-containers-38cbcb63-4126-413c-9cb8-980c74818684 to disappear
Aug 31 15:08:17.012: INFO: Pod client-containers-38cbcb63-4126-413c-9cb8-980c74818684 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:17.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8393" for this suite.
Aug 31 15:08:23.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:08:23.087: INFO: namespace containers-8393 deletion completed in 6.071085281s

• [SLOW TEST:8.145 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:08:23.087: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug 31 15:08:23.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 --namespace=kubectl-5262 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug 31 15:08:24.874: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug 31 15:08:24.874: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:26.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5262" for this suite.
Aug 31 15:08:32.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:08:32.957: INFO: namespace kubectl-5262 deletion completed in 6.073720858s

• [SLOW TEST:9.869 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:08:32.958: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:08:32.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4" in namespace "downward-api-2891" to be "success or failure"
Aug 31 15:08:32.994: INFO: Pod "downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.294375ms
Aug 31 15:08:34.997: INFO: Pod "downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007636244s
STEP: Saw pod success
Aug 31 15:08:34.997: INFO: Pod "downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4" satisfied condition "success or failure"
Aug 31 15:08:35.000: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4 container client-container: <nil>
STEP: delete the pod
Aug 31 15:08:35.020: INFO: Waiting for pod downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4 to disappear
Aug 31 15:08:35.022: INFO: Pod downwardapi-volume-4c81d1c6-02da-44a1-bdd0-87d4987039c4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:35.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2891" for this suite.
Aug 31 15:08:41.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:08:41.107: INFO: namespace downward-api-2891 deletion completed in 6.081974579s

• [SLOW TEST:8.148 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:08:41.108: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-cdac5528-0df3-4022-8ea9-dfb1ddeede12
STEP: Creating secret with name s-test-opt-upd-1fa3be9b-557d-48dc-80c7-8c8436b2fc9e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cdac5528-0df3-4022-8ea9-dfb1ddeede12
STEP: Updating secret s-test-opt-upd-1fa3be9b-557d-48dc-80c7-8c8436b2fc9e
STEP: Creating secret with name s-test-opt-create-4fc024dd-6191-478d-b62b-1ee052525053
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:08:47.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6657" for this suite.
Aug 31 15:09:09.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:09:09.291: INFO: namespace projected-6657 deletion completed in 22.07339254s

• [SLOW TEST:28.184 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:09:09.292: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:09:09.378: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:09:11.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2759" for this suite.
Aug 31 15:09:57.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:09:57.484: INFO: namespace pods-2759 deletion completed in 46.072987766s

• [SLOW TEST:48.192 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:09:57.485: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 15:09:57.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2654'
Aug 31 15:09:57.618: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 31 15:09:57.618: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug 31 15:09:57.632: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xz5gp]
Aug 31 15:09:57.632: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xz5gp" in namespace "kubectl-2654" to be "running and ready"
Aug 31 15:09:57.639: INFO: Pod "e2e-test-nginx-rc-xz5gp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994473ms
Aug 31 15:09:59.643: INFO: Pod "e2e-test-nginx-rc-xz5gp": Phase="Running", Reason="", readiness=true. Elapsed: 2.010243771s
Aug 31 15:09:59.643: INFO: Pod "e2e-test-nginx-rc-xz5gp" satisfied condition "running and ready"
Aug 31 15:09:59.643: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xz5gp]
Aug 31 15:09:59.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs rc/e2e-test-nginx-rc --namespace=kubectl-2654'
Aug 31 15:09:59.712: INFO: stderr: ""
Aug 31 15:09:59.712: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Aug 31 15:09:59.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete rc e2e-test-nginx-rc --namespace=kubectl-2654'
Aug 31 15:09:59.771: INFO: stderr: ""
Aug 31 15:09:59.771: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:09:59.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2654" for this suite.
Aug 31 15:10:21.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:10:21.852: INFO: namespace kubectl-2654 deletion completed in 22.075303111s

• [SLOW TEST:24.367 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:10:21.852: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:10:21.874: INFO: Creating deployment "test-recreate-deployment"
Aug 31 15:10:21.878: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug 31 15:10:21.886: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug 31 15:10:23.892: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug 31 15:10:23.894: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797555421, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797555421, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797555421, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797555421, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:10:25.899: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug 31 15:10:25.907: INFO: Updating deployment test-recreate-deployment
Aug 31 15:10:25.907: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 31 15:10:25.963: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2333,SelfLink:/apis/apps/v1/namespaces/deployment-2333/deployments/test-recreate-deployment,UID:918616b5-1c8c-483e-836d-26ac9d252b1b,ResourceVersion:35680,Generation:2,CreationTimestamp:2022-08-31 15:10:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2022-08-31 15:10:25 +0000 UTC 2022-08-31 15:10:25 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2022-08-31 15:10:25 +0000 UTC 2022-08-31 15:10:21 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug 31 15:10:25.968: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-2333,SelfLink:/apis/apps/v1/namespaces/deployment-2333/replicasets/test-recreate-deployment-5c8c9cc69d,UID:cc3e57bc-8c8e-4740-88bc-15418f384e95,ResourceVersion:35678,Generation:1,CreationTimestamp:2022-08-31 15:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 918616b5-1c8c-483e-836d-26ac9d252b1b 0xc002ee3597 0xc002ee3598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 15:10:25.968: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug 31 15:10:25.968: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-2333,SelfLink:/apis/apps/v1/namespaces/deployment-2333/replicasets/test-recreate-deployment-6df85df6b9,UID:9bf2856c-7847-412c-86ec-f93e3573a453,ResourceVersion:35668,Generation:2,CreationTimestamp:2022-08-31 15:10:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 918616b5-1c8c-483e-836d-26ac9d252b1b 0xc002ee3667 0xc002ee3668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 15:10:25.972: INFO: Pod "test-recreate-deployment-5c8c9cc69d-hbnlv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-hbnlv,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-2333,SelfLink:/api/v1/namespaces/deployment-2333/pods/test-recreate-deployment-5c8c9cc69d-hbnlv,UID:c52ad8cf-e084-4500-8c29-c793d0a6d4a9,ResourceVersion:35679,Generation:0,CreationTimestamp:2022-08-31 15:10:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d cc3e57bc-8c8e-4740-88bc-15418f384e95 0xc002ee3f57 0xc002ee3f58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-td6lr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-td6lr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-td6lr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002ee3fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002ee3ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:10:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:10:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:10:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:10:25 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:10:25 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:10:25.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2333" for this suite.
Aug 31 15:10:31.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:10:32.056: INFO: namespace deployment-2333 deletion completed in 6.079292431s

• [SLOW TEST:10.204 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:10:32.057: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 31 15:10:34.612: INFO: Successfully updated pod "annotationupdate76da7714-ec43-48e9-8145-3bf65c6d5c02"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:10:36.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4758" for this suite.
Aug 31 15:10:58.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:10:58.713: INFO: namespace downward-api-4758 deletion completed in 22.081257627s

• [SLOW TEST:26.656 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:10:58.713: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug 31 15:10:58.744: INFO: Waiting up to 5m0s for pod "pod-2d33996f-6084-45d8-9c08-fc3cfa713da9" in namespace "emptydir-8032" to be "success or failure"
Aug 31 15:10:58.747: INFO: Pod "pod-2d33996f-6084-45d8-9c08-fc3cfa713da9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.508798ms
Aug 31 15:11:00.750: INFO: Pod "pod-2d33996f-6084-45d8-9c08-fc3cfa713da9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005977939s
STEP: Saw pod success
Aug 31 15:11:00.750: INFO: Pod "pod-2d33996f-6084-45d8-9c08-fc3cfa713da9" satisfied condition "success or failure"
Aug 31 15:11:00.754: INFO: Trying to get logs from node vm119042 pod pod-2d33996f-6084-45d8-9c08-fc3cfa713da9 container test-container: <nil>
STEP: delete the pod
Aug 31 15:11:00.769: INFO: Waiting for pod pod-2d33996f-6084-45d8-9c08-fc3cfa713da9 to disappear
Aug 31 15:11:00.771: INFO: Pod pod-2d33996f-6084-45d8-9c08-fc3cfa713da9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:11:00.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8032" for this suite.
Aug 31 15:11:06.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:11:06.841: INFO: namespace emptydir-8032 deletion completed in 6.067400666s

• [SLOW TEST:8.127 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:11:06.841: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:11:06.867: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94" in namespace "projected-2561" to be "success or failure"
Aug 31 15:11:06.871: INFO: Pod "downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.849796ms
Aug 31 15:11:08.874: INFO: Pod "downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00743636s
STEP: Saw pod success
Aug 31 15:11:08.874: INFO: Pod "downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94" satisfied condition "success or failure"
Aug 31 15:11:08.877: INFO: Trying to get logs from node vm119043 pod downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94 container client-container: <nil>
STEP: delete the pod
Aug 31 15:11:08.893: INFO: Waiting for pod downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94 to disappear
Aug 31 15:11:08.897: INFO: Pod downwardapi-volume-c14605ab-4d6b-46a2-9ebe-de653e1cbd94 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:11:08.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2561" for this suite.
Aug 31 15:11:14.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:11:14.977: INFO: namespace projected-2561 deletion completed in 6.076105333s

• [SLOW TEST:8.136 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:11:14.978: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug 31 15:11:15.003: INFO: Waiting up to 5m0s for pod "client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59" in namespace "containers-694" to be "success or failure"
Aug 31 15:11:15.006: INFO: Pod "client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.627465ms
Aug 31 15:11:17.009: INFO: Pod "client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006300677s
STEP: Saw pod success
Aug 31 15:11:17.009: INFO: Pod "client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59" satisfied condition "success or failure"
Aug 31 15:11:17.012: INFO: Trying to get logs from node vm119042 pod client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59 container test-container: <nil>
STEP: delete the pod
Aug 31 15:11:17.026: INFO: Waiting for pod client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59 to disappear
Aug 31 15:11:17.030: INFO: Pod client-containers-2542247a-ecc2-4179-98b0-5b54e9165c59 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:11:17.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-694" for this suite.
Aug 31 15:11:23.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:11:23.100: INFO: namespace containers-694 deletion completed in 6.065449479s

• [SLOW TEST:8.122 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:11:23.100: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:11:41.138: INFO: Container started at 2022-08-31 15:11:23 +0000 UTC, pod became ready at 2022-08-31 15:11:40 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:11:41.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4307" for this suite.
Aug 31 15:12:03.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:12:03.212: INFO: namespace container-probe-4307 deletion completed in 22.070495838s

• [SLOW TEST:40.112 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:12:03.212: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-44d15cbe-ba94-48e8-9ece-940bc6b7eab4
STEP: Creating a pod to test consume secrets
Aug 31 15:12:03.244: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442" in namespace "projected-1694" to be "success or failure"
Aug 31 15:12:03.248: INFO: Pod "pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419587ms
Aug 31 15:12:05.252: INFO: Pod "pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007892115s
STEP: Saw pod success
Aug 31 15:12:05.252: INFO: Pod "pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442" satisfied condition "success or failure"
Aug 31 15:12:05.254: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:12:05.269: INFO: Waiting for pod pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442 to disappear
Aug 31 15:12:05.272: INFO: Pod pod-projected-secrets-b86e8152-17f6-4e08-9f1f-6f8d83b9f442 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:12:05.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1694" for this suite.
Aug 31 15:12:11.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:12:11.353: INFO: namespace projected-1694 deletion completed in 6.077300568s

• [SLOW TEST:8.141 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:12:11.354: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 31 15:12:13.448: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:12:13.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9812" for this suite.
Aug 31 15:12:19.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:12:19.534: INFO: namespace container-runtime-9812 deletion completed in 6.072394014s

• [SLOW TEST:8.180 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:12:19.535: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-c41a62a0-804f-4f2c-b60b-4f3fde75de43
STEP: Creating a pod to test consume configMaps
Aug 31 15:12:19.567: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11" in namespace "configmap-8462" to be "success or failure"
Aug 31 15:12:19.571: INFO: Pod "pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.222385ms
Aug 31 15:12:21.575: INFO: Pod "pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007796247s
STEP: Saw pod success
Aug 31 15:12:21.575: INFO: Pod "pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11" satisfied condition "success or failure"
Aug 31 15:12:21.577: INFO: Trying to get logs from node vm119042 pod pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:12:21.590: INFO: Waiting for pod pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11 to disappear
Aug 31 15:12:21.593: INFO: Pod pod-configmaps-ba58e86b-d73e-471f-b2f5-9d6e5f367e11 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:12:21.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8462" for this suite.
Aug 31 15:12:27.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:12:27.680: INFO: namespace configmap-8462 deletion completed in 6.083120312s

• [SLOW TEST:8.145 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:12:27.685: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:12:31.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5684" for this suite.
Aug 31 15:12:37.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:12:37.799: INFO: namespace kubelet-test-5684 deletion completed in 6.076202294s

• [SLOW TEST:10.113 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:12:37.799: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-1d62e0b4-dbfd-481f-9105-3570c1637987
STEP: Creating configMap with name cm-test-opt-upd-c3a2b2be-7b89-417a-8fa6-adfc010f2ec0
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1d62e0b4-dbfd-481f-9105-3570c1637987
STEP: Updating configmap cm-test-opt-upd-c3a2b2be-7b89-417a-8fa6-adfc010f2ec0
STEP: Creating configMap with name cm-test-opt-create-ecbd92ed-4cfc-4079-a071-d73ce8fa30d8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:12:43.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2051" for this suite.
Aug 31 15:13:05.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:13:05.986: INFO: namespace configmap-2051 deletion completed in 22.077132093s

• [SLOW TEST:28.187 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:13:05.986: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug 31 15:13:06.011: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:13:16.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5815" for this suite.
Aug 31 15:13:22.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:13:22.418: INFO: namespace pods-5815 deletion completed in 6.072171258s

• [SLOW TEST:16.432 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:13:22.419: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug 31 15:13:24.457: INFO: Pod pod-hostip-a03d258d-dba9-434c-9bd2-3831c00c7c41 has hostIP: 192.168.119.42
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:13:24.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2619" for this suite.
Aug 31 15:13:46.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:13:46.531: INFO: namespace pods-2619 deletion completed in 22.069305354s

• [SLOW TEST:24.113 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:13:46.531: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8903
I0831 15:13:46.557064      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8903, replica count: 1
I0831 15:13:47.608308      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:13:48.608707      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:13:49.610011      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 31 15:13:49.717: INFO: Created: latency-svc-twthz
Aug 31 15:13:49.731: INFO: Got endpoints: latency-svc-twthz [20.61786ms]
Aug 31 15:13:49.763: INFO: Created: latency-svc-d497b
Aug 31 15:13:49.774: INFO: Got endpoints: latency-svc-d497b [42.661665ms]
Aug 31 15:13:49.777: INFO: Created: latency-svc-wrgc9
Aug 31 15:13:49.794: INFO: Got endpoints: latency-svc-wrgc9 [62.156572ms]
Aug 31 15:13:49.817: INFO: Created: latency-svc-9cvv9
Aug 31 15:13:49.817: INFO: Created: latency-svc-xdslq
Aug 31 15:13:49.817: INFO: Created: latency-svc-vmccm
Aug 31 15:13:49.837: INFO: Created: latency-svc-fwlsf
Aug 31 15:13:49.846: INFO: Got endpoints: latency-svc-xdslq [113.746502ms]
Aug 31 15:13:49.846: INFO: Got endpoints: latency-svc-vmccm [114.461795ms]
Aug 31 15:13:49.846: INFO: Got endpoints: latency-svc-9cvv9 [114.841833ms]
Aug 31 15:13:49.877: INFO: Created: latency-svc-w68tv
Aug 31 15:13:49.878: INFO: Got endpoints: latency-svc-w68tv [146.360232ms]
Aug 31 15:13:49.879: INFO: Got endpoints: latency-svc-fwlsf [146.771347ms]
Aug 31 15:13:49.880: INFO: Created: latency-svc-plzkh
Aug 31 15:13:49.888: INFO: Got endpoints: latency-svc-plzkh [155.889677ms]
Aug 31 15:13:49.893: INFO: Created: latency-svc-mr4rv
Aug 31 15:13:49.900: INFO: Got endpoints: latency-svc-mr4rv [167.867658ms]
Aug 31 15:13:49.913: INFO: Created: latency-svc-gdr4j
Aug 31 15:13:49.913: INFO: Got endpoints: latency-svc-gdr4j [179.904418ms]
Aug 31 15:13:49.918: INFO: Created: latency-svc-s2n2d
Aug 31 15:13:49.923: INFO: Created: latency-svc-tj5dz
Aug 31 15:13:49.929: INFO: Got endpoints: latency-svc-s2n2d [195.583078ms]
Aug 31 15:13:49.936: INFO: Got endpoints: latency-svc-tj5dz [202.951408ms]
Aug 31 15:13:49.937: INFO: Created: latency-svc-5j4kb
Aug 31 15:13:49.943: INFO: Created: latency-svc-qnqnt
Aug 31 15:13:49.952: INFO: Created: latency-svc-4hwgr
Aug 31 15:13:49.952: INFO: Got endpoints: latency-svc-qnqnt [218.347419ms]
Aug 31 15:13:49.952: INFO: Got endpoints: latency-svc-5j4kb [218.77742ms]
Aug 31 15:13:49.958: INFO: Got endpoints: latency-svc-4hwgr [224.421394ms]
Aug 31 15:13:49.964: INFO: Created: latency-svc-9mrzp
Aug 31 15:13:49.967: INFO: Got endpoints: latency-svc-9mrzp [192.923524ms]
Aug 31 15:13:49.971: INFO: Created: latency-svc-dsjz9
Aug 31 15:13:49.975: INFO: Got endpoints: latency-svc-dsjz9 [180.911159ms]
Aug 31 15:13:49.982: INFO: Created: latency-svc-dhjhr
Aug 31 15:13:49.987: INFO: Created: latency-svc-l5bh5
Aug 31 15:13:49.988: INFO: Got endpoints: latency-svc-dhjhr [142.589914ms]
Aug 31 15:13:49.995: INFO: Got endpoints: latency-svc-l5bh5 [149.002995ms]
Aug 31 15:13:50.013: INFO: Created: latency-svc-bgwg4
Aug 31 15:13:50.013: INFO: Got endpoints: latency-svc-bgwg4 [166.535607ms]
Aug 31 15:13:50.028: INFO: Created: latency-svc-p5qcw
Aug 31 15:13:50.035: INFO: Created: latency-svc-89vhj
Aug 31 15:13:50.045: INFO: Got endpoints: latency-svc-p5qcw [167.356966ms]
Aug 31 15:13:50.050: INFO: Got endpoints: latency-svc-89vhj [170.866248ms]
Aug 31 15:13:50.058: INFO: Created: latency-svc-jn22l
Aug 31 15:13:50.067: INFO: Created: latency-svc-7zb5h
Aug 31 15:13:50.072: INFO: Got endpoints: latency-svc-jn22l [183.898106ms]
Aug 31 15:13:50.080: INFO: Created: latency-svc-pstjn
Aug 31 15:13:50.081: INFO: Got endpoints: latency-svc-7zb5h [180.015374ms]
Aug 31 15:13:50.089: INFO: Got endpoints: latency-svc-pstjn [176.79713ms]
Aug 31 15:13:50.091: INFO: Created: latency-svc-cwh4w
Aug 31 15:13:50.104: INFO: Got endpoints: latency-svc-cwh4w [175.348065ms]
Aug 31 15:13:50.106: INFO: Created: latency-svc-qk44n
Aug 31 15:13:50.115: INFO: Got endpoints: latency-svc-qk44n [179.200717ms]
Aug 31 15:13:50.123: INFO: Created: latency-svc-mlcxw
Aug 31 15:13:50.128: INFO: Got endpoints: latency-svc-mlcxw [176.264051ms]
Aug 31 15:13:50.134: INFO: Created: latency-svc-gjjlj
Aug 31 15:13:50.134: INFO: Created: latency-svc-mfcct
Aug 31 15:13:50.142: INFO: Got endpoints: latency-svc-mfcct [190.244459ms]
Aug 31 15:13:50.146: INFO: Got endpoints: latency-svc-gjjlj [187.525043ms]
Aug 31 15:13:50.151: INFO: Created: latency-svc-wts7h
Aug 31 15:13:50.154: INFO: Got endpoints: latency-svc-wts7h [187.180472ms]
Aug 31 15:13:50.158: INFO: Created: latency-svc-f7tvr
Aug 31 15:13:50.165: INFO: Got endpoints: latency-svc-f7tvr [22.135266ms]
Aug 31 15:13:50.168: INFO: Created: latency-svc-4zt5h
Aug 31 15:13:50.172: INFO: Got endpoints: latency-svc-4zt5h [196.917662ms]
Aug 31 15:13:50.180: INFO: Created: latency-svc-9wtd4
Aug 31 15:13:50.186: INFO: Created: latency-svc-lwgvf
Aug 31 15:13:50.187: INFO: Got endpoints: latency-svc-9wtd4 [198.203274ms]
Aug 31 15:13:50.190: INFO: Got endpoints: latency-svc-lwgvf [194.902119ms]
Aug 31 15:13:50.198: INFO: Created: latency-svc-tm6rg
Aug 31 15:13:50.207: INFO: Got endpoints: latency-svc-tm6rg [194.28608ms]
Aug 31 15:13:50.210: INFO: Created: latency-svc-mtlt8
Aug 31 15:13:50.217: INFO: Got endpoints: latency-svc-mtlt8 [171.736855ms]
Aug 31 15:13:50.224: INFO: Created: latency-svc-2mstl
Aug 31 15:13:50.235: INFO: Got endpoints: latency-svc-2mstl [184.500609ms]
Aug 31 15:13:50.245: INFO: Created: latency-svc-rmkj9
Aug 31 15:13:50.246: INFO: Got endpoints: latency-svc-rmkj9 [173.904458ms]
Aug 31 15:13:50.250: INFO: Created: latency-svc-wrjz6
Aug 31 15:13:50.277: INFO: Created: latency-svc-dqdzw
Aug 31 15:13:50.278: INFO: Got endpoints: latency-svc-wrjz6 [197.735868ms]
Aug 31 15:13:50.289: INFO: Created: latency-svc-49wg2
Aug 31 15:13:50.300: INFO: Got endpoints: latency-svc-dqdzw [210.39082ms]
Aug 31 15:13:50.308: INFO: Got endpoints: latency-svc-49wg2 [204.442205ms]
Aug 31 15:13:50.309: INFO: Created: latency-svc-4b9nk
Aug 31 15:13:50.321: INFO: Got endpoints: latency-svc-4b9nk [205.177444ms]
Aug 31 15:13:50.330: INFO: Created: latency-svc-966w7
Aug 31 15:13:50.334: INFO: Got endpoints: latency-svc-966w7 [205.972972ms]
Aug 31 15:13:50.351: INFO: Created: latency-svc-mlbpx
Aug 31 15:13:50.358: INFO: Got endpoints: latency-svc-mlbpx [212.517126ms]
Aug 31 15:13:50.363: INFO: Created: latency-svc-zl4q5
Aug 31 15:13:50.368: INFO: Created: latency-svc-nkhwc
Aug 31 15:13:50.385: INFO: Created: latency-svc-vffxb
Aug 31 15:13:50.385: INFO: Got endpoints: latency-svc-nkhwc [220.390912ms]
Aug 31 15:13:50.385: INFO: Got endpoints: latency-svc-zl4q5 [231.326171ms]
Aug 31 15:13:50.396: INFO: Created: latency-svc-rw27l
Aug 31 15:13:50.399: INFO: Got endpoints: latency-svc-vffxb [226.234443ms]
Aug 31 15:13:50.400: INFO: Got endpoints: latency-svc-rw27l [213.74051ms]
Aug 31 15:13:50.414: INFO: Created: latency-svc-crlxk
Aug 31 15:13:50.417: INFO: Got endpoints: latency-svc-crlxk [226.733707ms]
Aug 31 15:13:50.427: INFO: Created: latency-svc-jkksm
Aug 31 15:13:50.433: INFO: Got endpoints: latency-svc-jkksm [225.789895ms]
Aug 31 15:13:50.438: INFO: Created: latency-svc-kd5mm
Aug 31 15:13:50.441: INFO: Created: latency-svc-b9z7w
Aug 31 15:13:50.443: INFO: Got endpoints: latency-svc-kd5mm [226.29683ms]
Aug 31 15:13:50.451: INFO: Created: latency-svc-bqpvn
Aug 31 15:13:50.456: INFO: Got endpoints: latency-svc-b9z7w [221.0868ms]
Aug 31 15:13:50.457: INFO: Created: latency-svc-tjtbg
Aug 31 15:13:50.459: INFO: Got endpoints: latency-svc-bqpvn [212.990218ms]
Aug 31 15:13:50.472: INFO: Got endpoints: latency-svc-tjtbg [193.234742ms]
Aug 31 15:13:50.473: INFO: Created: latency-svc-k5pff
Aug 31 15:13:50.480: INFO: Got endpoints: latency-svc-k5pff [180.130756ms]
Aug 31 15:13:50.485: INFO: Created: latency-svc-rnt88
Aug 31 15:13:50.489: INFO: Got endpoints: latency-svc-rnt88 [180.808167ms]
Aug 31 15:13:50.493: INFO: Created: latency-svc-99prt
Aug 31 15:13:50.503: INFO: Got endpoints: latency-svc-99prt [182.340286ms]
Aug 31 15:13:50.506: INFO: Created: latency-svc-rzmch
Aug 31 15:13:50.508: INFO: Created: latency-svc-9d5bt
Aug 31 15:13:50.519: INFO: Created: latency-svc-8ppmv
Aug 31 15:13:50.523: INFO: Got endpoints: latency-svc-rzmch [188.444402ms]
Aug 31 15:13:50.523: INFO: Got endpoints: latency-svc-9d5bt [165.206137ms]
Aug 31 15:13:50.529: INFO: Got endpoints: latency-svc-8ppmv [143.73121ms]
Aug 31 15:13:50.529: INFO: Created: latency-svc-l4r79
Aug 31 15:13:50.532: INFO: Got endpoints: latency-svc-l4r79 [147.088474ms]
Aug 31 15:13:50.539: INFO: Created: latency-svc-lk8dp
Aug 31 15:13:50.544: INFO: Got endpoints: latency-svc-lk8dp [144.070537ms]
Aug 31 15:13:50.546: INFO: Created: latency-svc-5dtcp
Aug 31 15:13:50.552: INFO: Created: latency-svc-rlrgh
Aug 31 15:13:50.552: INFO: Got endpoints: latency-svc-5dtcp [151.585691ms]
Aug 31 15:13:50.557: INFO: Created: latency-svc-rd5zw
Aug 31 15:13:50.559: INFO: Got endpoints: latency-svc-rlrgh [141.544212ms]
Aug 31 15:13:50.568: INFO: Created: latency-svc-l8dnk
Aug 31 15:13:50.570: INFO: Got endpoints: latency-svc-rd5zw [137.071355ms]
Aug 31 15:13:50.576: INFO: Got endpoints: latency-svc-l8dnk [132.95397ms]
Aug 31 15:13:50.582: INFO: Created: latency-svc-s4dpj
Aug 31 15:13:50.585: INFO: Created: latency-svc-drs9f
Aug 31 15:13:50.591: INFO: Got endpoints: latency-svc-s4dpj [135.272424ms]
Aug 31 15:13:50.594: INFO: Got endpoints: latency-svc-drs9f [134.759016ms]
Aug 31 15:13:50.602: INFO: Created: latency-svc-mz5pl
Aug 31 15:13:50.603: INFO: Got endpoints: latency-svc-mz5pl [131.396647ms]
Aug 31 15:13:50.610: INFO: Created: latency-svc-6htzr
Aug 31 15:13:50.614: INFO: Created: latency-svc-ddnfz
Aug 31 15:13:50.620: INFO: Got endpoints: latency-svc-6htzr [140.162776ms]
Aug 31 15:13:50.622: INFO: Got endpoints: latency-svc-ddnfz [132.533723ms]
Aug 31 15:13:50.628: INFO: Created: latency-svc-hzqz8
Aug 31 15:13:50.635: INFO: Got endpoints: latency-svc-hzqz8 [131.61424ms]
Aug 31 15:13:50.636: INFO: Created: latency-svc-pxspf
Aug 31 15:13:50.645: INFO: Got endpoints: latency-svc-pxspf [121.888699ms]
Aug 31 15:13:50.654: INFO: Created: latency-svc-p8zmw
Aug 31 15:13:50.659: INFO: Created: latency-svc-s9v7k
Aug 31 15:13:50.659: INFO: Got endpoints: latency-svc-p8zmw [135.822713ms]
Aug 31 15:13:50.665: INFO: Got endpoints: latency-svc-s9v7k [136.023207ms]
Aug 31 15:13:50.672: INFO: Created: latency-svc-4982c
Aug 31 15:13:50.674: INFO: Created: latency-svc-srpfx
Aug 31 15:13:50.675: INFO: Got endpoints: latency-svc-4982c [142.798567ms]
Aug 31 15:13:50.681: INFO: Got endpoints: latency-svc-srpfx [136.739422ms]
Aug 31 15:13:50.684: INFO: Created: latency-svc-zk7nw
Aug 31 15:13:50.694: INFO: Got endpoints: latency-svc-zk7nw [141.585503ms]
Aug 31 15:13:50.695: INFO: Created: latency-svc-9js2p
Aug 31 15:13:50.707: INFO: Created: latency-svc-nt7t2
Aug 31 15:13:50.707: INFO: Created: latency-svc-8pnpq
Aug 31 15:13:50.710: INFO: Got endpoints: latency-svc-8pnpq [139.896102ms]
Aug 31 15:13:50.710: INFO: Got endpoints: latency-svc-9js2p [151.414442ms]
Aug 31 15:13:50.714: INFO: Got endpoints: latency-svc-nt7t2 [137.722544ms]
Aug 31 15:13:50.718: INFO: Created: latency-svc-jbm9t
Aug 31 15:13:50.722: INFO: Got endpoints: latency-svc-jbm9t [127.908285ms]
Aug 31 15:13:50.732: INFO: Created: latency-svc-qqszf
Aug 31 15:13:50.740: INFO: Created: latency-svc-6b9bp
Aug 31 15:13:50.740: INFO: Got endpoints: latency-svc-qqszf [148.545878ms]
Aug 31 15:13:50.743: INFO: Got endpoints: latency-svc-6b9bp [139.404376ms]
Aug 31 15:13:50.745: INFO: Created: latency-svc-wzvgj
Aug 31 15:13:50.753: INFO: Created: latency-svc-9rvsn
Aug 31 15:13:50.756: INFO: Got endpoints: latency-svc-9rvsn [133.306678ms]
Aug 31 15:13:50.756: INFO: Got endpoints: latency-svc-wzvgj [135.325651ms]
Aug 31 15:13:50.763: INFO: Created: latency-svc-t87hs
Aug 31 15:13:50.766: INFO: Got endpoints: latency-svc-t87hs [131.143874ms]
Aug 31 15:13:50.768: INFO: Created: latency-svc-5zt5z
Aug 31 15:13:50.774: INFO: Got endpoints: latency-svc-5zt5z [128.680551ms]
Aug 31 15:13:50.782: INFO: Created: latency-svc-zr87z
Aug 31 15:13:50.782: INFO: Created: latency-svc-gdcjt
Aug 31 15:13:50.784: INFO: Got endpoints: latency-svc-gdcjt [124.875352ms]
Aug 31 15:13:50.789: INFO: Got endpoints: latency-svc-zr87z [124.361325ms]
Aug 31 15:13:50.798: INFO: Created: latency-svc-pw5dh
Aug 31 15:13:50.799: INFO: Got endpoints: latency-svc-pw5dh [124.065634ms]
Aug 31 15:13:50.806: INFO: Created: latency-svc-rxndq
Aug 31 15:13:50.810: INFO: Got endpoints: latency-svc-rxndq [129.597038ms]
Aug 31 15:13:50.813: INFO: Created: latency-svc-8d82n
Aug 31 15:13:50.818: INFO: Got endpoints: latency-svc-8d82n [123.75441ms]
Aug 31 15:13:50.819: INFO: Created: latency-svc-pc4b9
Aug 31 15:13:50.828: INFO: Got endpoints: latency-svc-pc4b9 [117.929344ms]
Aug 31 15:13:50.841: INFO: Created: latency-svc-5ls6j
Aug 31 15:13:50.841: INFO: Got endpoints: latency-svc-5ls6j [131.136675ms]
Aug 31 15:13:50.848: INFO: Created: latency-svc-xzlzj
Aug 31 15:13:50.852: INFO: Got endpoints: latency-svc-xzlzj [137.809034ms]
Aug 31 15:13:50.858: INFO: Created: latency-svc-mxgwf
Aug 31 15:13:50.861: INFO: Got endpoints: latency-svc-mxgwf [138.851796ms]
Aug 31 15:13:50.865: INFO: Created: latency-svc-97gxn
Aug 31 15:13:50.872: INFO: Got endpoints: latency-svc-97gxn [132.378177ms]
Aug 31 15:13:50.874: INFO: Created: latency-svc-86db4
Aug 31 15:13:50.877: INFO: Got endpoints: latency-svc-86db4 [134.593229ms]
Aug 31 15:13:50.882: INFO: Created: latency-svc-nrq56
Aug 31 15:13:50.888: INFO: Got endpoints: latency-svc-nrq56 [131.851837ms]
Aug 31 15:13:50.894: INFO: Created: latency-svc-6gx2x
Aug 31 15:13:50.895: INFO: Got endpoints: latency-svc-6gx2x [139.418667ms]
Aug 31 15:13:50.903: INFO: Created: latency-svc-8gwgc
Aug 31 15:13:50.906: INFO: Got endpoints: latency-svc-8gwgc [139.759171ms]
Aug 31 15:13:50.913: INFO: Created: latency-svc-m2gp2
Aug 31 15:13:50.920: INFO: Created: latency-svc-vt54m
Aug 31 15:13:50.922: INFO: Got endpoints: latency-svc-m2gp2 [148.12586ms]
Aug 31 15:13:50.930: INFO: Created: latency-svc-flx8k
Aug 31 15:13:50.933: INFO: Got endpoints: latency-svc-vt54m [148.938364ms]
Aug 31 15:13:50.937: INFO: Got endpoints: latency-svc-flx8k [147.727573ms]
Aug 31 15:13:50.940: INFO: Created: latency-svc-9bv4m
Aug 31 15:13:50.942: INFO: Got endpoints: latency-svc-9bv4m [142.875175ms]
Aug 31 15:13:50.951: INFO: Created: latency-svc-mpw5m
Aug 31 15:13:50.956: INFO: Created: latency-svc-q527t
Aug 31 15:13:50.956: INFO: Got endpoints: latency-svc-mpw5m [145.70992ms]
Aug 31 15:13:50.960: INFO: Got endpoints: latency-svc-q527t [142.092457ms]
Aug 31 15:13:50.970: INFO: Created: latency-svc-ft8wz
Aug 31 15:13:50.971: INFO: Created: latency-svc-6r2h2
Aug 31 15:13:50.976: INFO: Got endpoints: latency-svc-ft8wz [147.896067ms]
Aug 31 15:13:50.981: INFO: Got endpoints: latency-svc-6r2h2 [139.746136ms]
Aug 31 15:13:50.992: INFO: Created: latency-svc-7kkkt
Aug 31 15:13:50.993: INFO: Created: latency-svc-gbbfh
Aug 31 15:13:51.001: INFO: Got endpoints: latency-svc-7kkkt [148.726223ms]
Aug 31 15:13:51.001: INFO: Got endpoints: latency-svc-gbbfh [140.104794ms]
Aug 31 15:13:51.006: INFO: Created: latency-svc-lsqhl
Aug 31 15:13:51.010: INFO: Created: latency-svc-v9pxh
Aug 31 15:13:51.015: INFO: Got endpoints: latency-svc-lsqhl [142.386665ms]
Aug 31 15:13:51.018: INFO: Got endpoints: latency-svc-v9pxh [140.39008ms]
Aug 31 15:13:51.022: INFO: Created: latency-svc-nhtjz
Aug 31 15:13:51.028: INFO: Got endpoints: latency-svc-nhtjz [139.839786ms]
Aug 31 15:13:51.031: INFO: Created: latency-svc-jkg24
Aug 31 15:13:51.036: INFO: Got endpoints: latency-svc-jkg24 [140.804704ms]
Aug 31 15:13:51.038: INFO: Created: latency-svc-mc9bv
Aug 31 15:13:51.040: INFO: Got endpoints: latency-svc-mc9bv [134.508291ms]
Aug 31 15:13:51.060: INFO: Created: latency-svc-w9jn9
Aug 31 15:13:51.066: INFO: Got endpoints: latency-svc-w9jn9 [144.411321ms]
Aug 31 15:13:51.073: INFO: Created: latency-svc-jvcjp
Aug 31 15:13:51.077: INFO: Got endpoints: latency-svc-jvcjp [143.988809ms]
Aug 31 15:13:51.080: INFO: Created: latency-svc-52ndl
Aug 31 15:13:51.083: INFO: Got endpoints: latency-svc-52ndl [146.255422ms]
Aug 31 15:13:51.089: INFO: Created: latency-svc-7gv8z
Aug 31 15:13:51.096: INFO: Got endpoints: latency-svc-7gv8z [153.289489ms]
Aug 31 15:13:51.097: INFO: Created: latency-svc-86fpb
Aug 31 15:13:51.104: INFO: Got endpoints: latency-svc-86fpb [148.257276ms]
Aug 31 15:13:51.120: INFO: Created: latency-svc-d6vh7
Aug 31 15:13:51.126: INFO: Created: latency-svc-tr48h
Aug 31 15:13:51.133: INFO: Got endpoints: latency-svc-d6vh7 [173.530833ms]
Aug 31 15:13:51.153: INFO: Got endpoints: latency-svc-tr48h [176.51302ms]
Aug 31 15:13:51.153: INFO: Created: latency-svc-p9ww2
Aug 31 15:13:51.172: INFO: Got endpoints: latency-svc-p9ww2 [190.583551ms]
Aug 31 15:13:51.192: INFO: Created: latency-svc-5wt7s
Aug 31 15:13:51.192: INFO: Got endpoints: latency-svc-5wt7s [191.445657ms]
Aug 31 15:13:51.199: INFO: Created: latency-svc-cdrj4
Aug 31 15:13:51.204: INFO: Got endpoints: latency-svc-cdrj4 [203.088433ms]
Aug 31 15:13:51.208: INFO: Created: latency-svc-2d2fr
Aug 31 15:13:51.225: INFO: Got endpoints: latency-svc-2d2fr [209.610357ms]
Aug 31 15:13:51.230: INFO: Created: latency-svc-zvn7j
Aug 31 15:13:51.238: INFO: Got endpoints: latency-svc-zvn7j [220.62541ms]
Aug 31 15:13:51.243: INFO: Created: latency-svc-vdr7z
Aug 31 15:13:51.268: INFO: Got endpoints: latency-svc-vdr7z [240.278761ms]
Aug 31 15:13:51.269: INFO: Created: latency-svc-nsq7q
Aug 31 15:13:51.273: INFO: Got endpoints: latency-svc-nsq7q [232.233511ms]
Aug 31 15:13:51.359: INFO: Created: latency-svc-kr5vt
Aug 31 15:13:51.360: INFO: Got endpoints: latency-svc-kr5vt [323.909965ms]
Aug 31 15:13:51.367: INFO: Created: latency-svc-x5xwp
Aug 31 15:13:51.378: INFO: Got endpoints: latency-svc-x5xwp [311.976161ms]
Aug 31 15:13:51.380: INFO: Created: latency-svc-222qc
Aug 31 15:13:51.385: INFO: Got endpoints: latency-svc-222qc [305.309833ms]
Aug 31 15:13:51.393: INFO: Created: latency-svc-sshzz
Aug 31 15:13:51.397: INFO: Got endpoints: latency-svc-sshzz [313.200841ms]
Aug 31 15:13:51.400: INFO: Created: latency-svc-lscm4
Aug 31 15:13:51.407: INFO: Got endpoints: latency-svc-lscm4 [311.498014ms]
Aug 31 15:13:51.411: INFO: Created: latency-svc-ns928
Aug 31 15:13:51.418: INFO: Created: latency-svc-2cjm5
Aug 31 15:13:51.419: INFO: Got endpoints: latency-svc-ns928 [314.793793ms]
Aug 31 15:13:51.424: INFO: Got endpoints: latency-svc-2cjm5 [290.903263ms]
Aug 31 15:13:51.432: INFO: Created: latency-svc-rfv5f
Aug 31 15:13:51.435: INFO: Created: latency-svc-fdm55
Aug 31 15:13:51.439: INFO: Got endpoints: latency-svc-rfv5f [286.50604ms]
Aug 31 15:13:51.444: INFO: Got endpoints: latency-svc-fdm55 [271.788664ms]
Aug 31 15:13:51.459: INFO: Created: latency-svc-nqps9
Aug 31 15:13:51.463: INFO: Created: latency-svc-kwqjg
Aug 31 15:13:51.466: INFO: Got endpoints: latency-svc-nqps9 [273.2282ms]
Aug 31 15:13:51.473: INFO: Created: latency-svc-mcc2q
Aug 31 15:13:51.473: INFO: Got endpoints: latency-svc-kwqjg [268.180899ms]
Aug 31 15:13:51.481: INFO: Got endpoints: latency-svc-mcc2q [256.517764ms]
Aug 31 15:13:51.484: INFO: Created: latency-svc-fl8bb
Aug 31 15:13:51.489: INFO: Got endpoints: latency-svc-fl8bb [250.2051ms]
Aug 31 15:13:51.494: INFO: Created: latency-svc-9f88p
Aug 31 15:13:51.500: INFO: Created: latency-svc-qnmd9
Aug 31 15:13:51.504: INFO: Got endpoints: latency-svc-9f88p [236.07981ms]
Aug 31 15:13:51.507: INFO: Created: latency-svc-n45fb
Aug 31 15:13:51.512: INFO: Got endpoints: latency-svc-qnmd9 [238.917931ms]
Aug 31 15:13:51.518: INFO: Got endpoints: latency-svc-n45fb [158.305947ms]
Aug 31 15:13:51.522: INFO: Created: latency-svc-pq6qt
Aug 31 15:13:51.525: INFO: Created: latency-svc-2lr96
Aug 31 15:13:51.529: INFO: Got endpoints: latency-svc-pq6qt [150.694735ms]
Aug 31 15:13:51.540: INFO: Created: latency-svc-lzzxr
Aug 31 15:13:51.540: INFO: Got endpoints: latency-svc-2lr96 [154.592605ms]
Aug 31 15:13:51.545: INFO: Got endpoints: latency-svc-lzzxr [148.435041ms]
Aug 31 15:13:51.548: INFO: Created: latency-svc-jmbgs
Aug 31 15:13:51.552: INFO: Created: latency-svc-42wj4
Aug 31 15:13:51.552: INFO: Got endpoints: latency-svc-42wj4 [145.013839ms]
Aug 31 15:13:51.560: INFO: Got endpoints: latency-svc-jmbgs [140.81357ms]
Aug 31 15:13:51.564: INFO: Created: latency-svc-9wq4p
Aug 31 15:13:51.571: INFO: Created: latency-svc-psqdv
Aug 31 15:13:51.576: INFO: Got endpoints: latency-svc-9wq4p [151.823303ms]
Aug 31 15:13:51.580: INFO: Got endpoints: latency-svc-psqdv [140.81332ms]
Aug 31 15:13:51.585: INFO: Created: latency-svc-zh4mw
Aug 31 15:13:51.589: INFO: Got endpoints: latency-svc-zh4mw [145.064959ms]
Aug 31 15:13:51.594: INFO: Created: latency-svc-g99gm
Aug 31 15:13:51.603: INFO: Created: latency-svc-k7ssv
Aug 31 15:13:51.609: INFO: Got endpoints: latency-svc-k7ssv [135.87967ms]
Aug 31 15:13:51.610: INFO: Created: latency-svc-sbqp7
Aug 31 15:13:51.614: INFO: Got endpoints: latency-svc-g99gm [148.205669ms]
Aug 31 15:13:51.616: INFO: Got endpoints: latency-svc-sbqp7 [134.836225ms]
Aug 31 15:13:51.624: INFO: Created: latency-svc-hcwr6
Aug 31 15:13:51.625: INFO: Got endpoints: latency-svc-hcwr6 [136.476527ms]
Aug 31 15:13:51.629: INFO: Created: latency-svc-tjwqv
Aug 31 15:13:51.634: INFO: Created: latency-svc-z69tn
Aug 31 15:13:51.635: INFO: Got endpoints: latency-svc-tjwqv [130.307962ms]
Aug 31 15:13:51.640: INFO: Got endpoints: latency-svc-z69tn [128.452521ms]
Aug 31 15:13:51.647: INFO: Created: latency-svc-q76d6
Aug 31 15:13:51.650: INFO: Got endpoints: latency-svc-q76d6 [132.027689ms]
Aug 31 15:13:51.658: INFO: Created: latency-svc-fqcdr
Aug 31 15:13:51.662: INFO: Created: latency-svc-d55jp
Aug 31 15:13:51.666: INFO: Got endpoints: latency-svc-fqcdr [136.889827ms]
Aug 31 15:13:51.670: INFO: Got endpoints: latency-svc-d55jp [129.855945ms]
Aug 31 15:13:51.671: INFO: Created: latency-svc-4kfgh
Aug 31 15:13:51.691: INFO: Created: latency-svc-ffk72
Aug 31 15:13:51.698: INFO: Got endpoints: latency-svc-4kfgh [152.542697ms]
Aug 31 15:13:51.703: INFO: Got endpoints: latency-svc-ffk72 [151.30945ms]
Aug 31 15:13:51.707: INFO: Created: latency-svc-lp5p6
Aug 31 15:13:51.714: INFO: Created: latency-svc-j8bxf
Aug 31 15:13:51.714: INFO: Got endpoints: latency-svc-lp5p6 [154.028125ms]
Aug 31 15:13:51.719: INFO: Got endpoints: latency-svc-j8bxf [142.734007ms]
Aug 31 15:13:51.725: INFO: Created: latency-svc-zggtk
Aug 31 15:13:51.729: INFO: Created: latency-svc-w8bpx
Aug 31 15:13:51.731: INFO: Got endpoints: latency-svc-zggtk [151.343579ms]
Aug 31 15:13:51.733: INFO: Got endpoints: latency-svc-w8bpx [143.897585ms]
Aug 31 15:13:51.740: INFO: Created: latency-svc-tg767
Aug 31 15:13:51.743: INFO: Got endpoints: latency-svc-tg767 [134.734721ms]
Aug 31 15:13:51.750: INFO: Created: latency-svc-zpb4g
Aug 31 15:13:51.750: INFO: Got endpoints: latency-svc-zpb4g [136.298761ms]
Aug 31 15:13:51.763: INFO: Created: latency-svc-hcd28
Aug 31 15:13:51.764: INFO: Created: latency-svc-pncxl
Aug 31 15:13:51.764: INFO: Got endpoints: latency-svc-pncxl [147.358536ms]
Aug 31 15:13:51.770: INFO: Got endpoints: latency-svc-hcd28 [144.351149ms]
Aug 31 15:13:51.779: INFO: Created: latency-svc-gkmqh
Aug 31 15:13:51.780: INFO: Created: latency-svc-rvcbc
Aug 31 15:13:51.780: INFO: Got endpoints: latency-svc-rvcbc [145.04647ms]
Aug 31 15:13:51.790: INFO: Created: latency-svc-k64w8
Aug 31 15:13:51.791: INFO: Got endpoints: latency-svc-gkmqh [150.713099ms]
Aug 31 15:13:51.796: INFO: Got endpoints: latency-svc-k64w8 [145.884345ms]
Aug 31 15:13:51.798: INFO: Created: latency-svc-6zzfz
Aug 31 15:13:51.803: INFO: Got endpoints: latency-svc-6zzfz [137.02018ms]
Aug 31 15:13:51.807: INFO: Created: latency-svc-z666z
Aug 31 15:13:51.813: INFO: Got endpoints: latency-svc-z666z [143.273508ms]
Aug 31 15:13:51.817: INFO: Created: latency-svc-fnp5t
Aug 31 15:13:51.821: INFO: Got endpoints: latency-svc-fnp5t [123.688878ms]
Aug 31 15:13:51.829: INFO: Created: latency-svc-f49cc
Aug 31 15:13:51.836: INFO: Got endpoints: latency-svc-f49cc [132.519341ms]
Aug 31 15:13:51.838: INFO: Created: latency-svc-vfc6t
Aug 31 15:13:51.848: INFO: Got endpoints: latency-svc-vfc6t [133.698652ms]
Aug 31 15:13:51.848: INFO: Created: latency-svc-mn7z5
Aug 31 15:13:51.848: INFO: Got endpoints: latency-svc-mn7z5 [129.158565ms]
Aug 31 15:13:51.852: INFO: Created: latency-svc-2fj95
Aug 31 15:13:51.858: INFO: Got endpoints: latency-svc-2fj95 [126.345431ms]
Aug 31 15:13:51.864: INFO: Created: latency-svc-mqtl8
Aug 31 15:13:51.869: INFO: Got endpoints: latency-svc-mqtl8 [136.176973ms]
Aug 31 15:13:51.871: INFO: Created: latency-svc-gv2dr
Aug 31 15:13:51.878: INFO: Created: latency-svc-2gj78
Aug 31 15:13:51.881: INFO: Got endpoints: latency-svc-gv2dr [137.694195ms]
Aug 31 15:13:51.884: INFO: Got endpoints: latency-svc-2gj78 [133.160771ms]
Aug 31 15:13:51.887: INFO: Created: latency-svc-pjbwn
Aug 31 15:13:51.898: INFO: Created: latency-svc-9fvv4
Aug 31 15:13:51.899: INFO: Got endpoints: latency-svc-pjbwn [134.908546ms]
Aug 31 15:13:51.899: INFO: Got endpoints: latency-svc-9fvv4 [129.040917ms]
Aug 31 15:13:51.906: INFO: Created: latency-svc-6gzqf
Aug 31 15:13:51.906: INFO: Got endpoints: latency-svc-6gzqf [126.183699ms]
Aug 31 15:13:51.914: INFO: Created: latency-svc-mklvn
Aug 31 15:13:51.914: INFO: Created: latency-svc-lh4hw
Aug 31 15:13:51.920: INFO: Got endpoints: latency-svc-mklvn [128.799918ms]
Aug 31 15:13:51.923: INFO: Got endpoints: latency-svc-lh4hw [126.429549ms]
Aug 31 15:13:51.925: INFO: Created: latency-svc-htpq7
Aug 31 15:13:51.931: INFO: Got endpoints: latency-svc-htpq7 [128.16182ms]
Aug 31 15:13:51.934: INFO: Created: latency-svc-kmhbq
Aug 31 15:13:51.937: INFO: Got endpoints: latency-svc-kmhbq [124.134428ms]
Aug 31 15:13:51.954: INFO: Created: latency-svc-lg5r2
Aug 31 15:13:51.958: INFO: Got endpoints: latency-svc-lg5r2 [136.477796ms]
Aug 31 15:13:51.963: INFO: Created: latency-svc-6kvcp
Aug 31 15:13:51.978: INFO: Created: latency-svc-7gsjg
Aug 31 15:13:51.979: INFO: Got endpoints: latency-svc-6kvcp [142.829926ms]
Aug 31 15:13:51.984: INFO: Created: latency-svc-5gpgn
Aug 31 15:13:51.986: INFO: Got endpoints: latency-svc-7gsjg [138.357846ms]
Aug 31 15:13:51.991: INFO: Got endpoints: latency-svc-5gpgn [142.502692ms]
Aug 31 15:13:51.992: INFO: Created: latency-svc-s9kf7
Aug 31 15:13:51.999: INFO: Got endpoints: latency-svc-s9kf7 [141.03581ms]
Aug 31 15:13:51.999: INFO: Latencies: [22.135266ms 42.661665ms 62.156572ms 113.746502ms 114.461795ms 114.841833ms 117.929344ms 121.888699ms 123.688878ms 123.75441ms 124.065634ms 124.134428ms 124.361325ms 124.875352ms 126.183699ms 126.345431ms 126.429549ms 127.908285ms 128.16182ms 128.452521ms 128.680551ms 128.799918ms 129.040917ms 129.158565ms 129.597038ms 129.855945ms 130.307962ms 131.136675ms 131.143874ms 131.396647ms 131.61424ms 131.851837ms 132.027689ms 132.378177ms 132.519341ms 132.533723ms 132.95397ms 133.160771ms 133.306678ms 133.698652ms 134.508291ms 134.593229ms 134.734721ms 134.759016ms 134.836225ms 134.908546ms 135.272424ms 135.325651ms 135.822713ms 135.87967ms 136.023207ms 136.176973ms 136.298761ms 136.476527ms 136.477796ms 136.739422ms 136.889827ms 137.02018ms 137.071355ms 137.694195ms 137.722544ms 137.809034ms 138.357846ms 138.851796ms 139.404376ms 139.418667ms 139.746136ms 139.759171ms 139.839786ms 139.896102ms 140.104794ms 140.162776ms 140.39008ms 140.804704ms 140.81332ms 140.81357ms 141.03581ms 141.544212ms 141.585503ms 142.092457ms 142.386665ms 142.502692ms 142.589914ms 142.734007ms 142.798567ms 142.829926ms 142.875175ms 143.273508ms 143.73121ms 143.897585ms 143.988809ms 144.070537ms 144.351149ms 144.411321ms 145.013839ms 145.04647ms 145.064959ms 145.70992ms 145.884345ms 146.255422ms 146.360232ms 146.771347ms 147.088474ms 147.358536ms 147.727573ms 147.896067ms 148.12586ms 148.205669ms 148.257276ms 148.435041ms 148.545878ms 148.726223ms 148.938364ms 149.002995ms 150.694735ms 150.713099ms 151.30945ms 151.343579ms 151.414442ms 151.585691ms 151.823303ms 152.542697ms 153.289489ms 154.028125ms 154.592605ms 155.889677ms 158.305947ms 165.206137ms 166.535607ms 167.356966ms 167.867658ms 170.866248ms 171.736855ms 173.530833ms 173.904458ms 175.348065ms 176.264051ms 176.51302ms 176.79713ms 179.200717ms 179.904418ms 180.015374ms 180.130756ms 180.808167ms 180.911159ms 182.340286ms 183.898106ms 184.500609ms 187.180472ms 187.525043ms 188.444402ms 190.244459ms 190.583551ms 191.445657ms 192.923524ms 193.234742ms 194.28608ms 194.902119ms 195.583078ms 196.917662ms 197.735868ms 198.203274ms 202.951408ms 203.088433ms 204.442205ms 205.177444ms 205.972972ms 209.610357ms 210.39082ms 212.517126ms 212.990218ms 213.74051ms 218.347419ms 218.77742ms 220.390912ms 220.62541ms 221.0868ms 224.421394ms 225.789895ms 226.234443ms 226.29683ms 226.733707ms 231.326171ms 232.233511ms 236.07981ms 238.917931ms 240.278761ms 250.2051ms 256.517764ms 268.180899ms 271.788664ms 273.2282ms 286.50604ms 290.903263ms 305.309833ms 311.498014ms 311.976161ms 313.200841ms 314.793793ms 323.909965ms]
Aug 31 15:13:51.999: INFO: 50 %ile: 146.360232ms
Aug 31 15:13:51.999: INFO: 90 %ile: 226.29683ms
Aug 31 15:13:51.999: INFO: 99 %ile: 314.793793ms
Aug 31 15:13:51.999: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:13:51.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8903" for this suite.
Aug 31 15:14:12.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:14:12.087: INFO: namespace svc-latency-8903 deletion completed in 20.079608031s

• [SLOW TEST:25.555 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:14:12.092: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-67e8cb27-d826-4622-b658-06a89c10d12e
STEP: Creating a pod to test consume secrets
Aug 31 15:14:12.123: INFO: Waiting up to 5m0s for pod "pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893" in namespace "secrets-7298" to be "success or failure"
Aug 31 15:14:12.131: INFO: Pod "pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893": Phase="Pending", Reason="", readiness=false. Elapsed: 8.350103ms
Aug 31 15:14:14.135: INFO: Pod "pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011721919s
STEP: Saw pod success
Aug 31 15:14:14.135: INFO: Pod "pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893" satisfied condition "success or failure"
Aug 31 15:14:14.138: INFO: Trying to get logs from node vm119042 pod pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:14:14.151: INFO: Waiting for pod pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893 to disappear
Aug 31 15:14:14.154: INFO: Pod pod-secrets-3d2c56b3-d1bb-4b21-82fc-20862efd8893 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:14:14.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7298" for this suite.
Aug 31 15:14:20.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:14:20.234: INFO: namespace secrets-7298 deletion completed in 6.076836023s

• [SLOW TEST:8.143 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:14:20.235: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-4c03856a-f86e-4197-a97a-e06ae6439d5f
STEP: Creating a pod to test consume secrets
Aug 31 15:14:20.263: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7" in namespace "projected-2369" to be "success or failure"
Aug 31 15:14:20.266: INFO: Pod "pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.981839ms
Aug 31 15:14:22.270: INFO: Pod "pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006632893s
STEP: Saw pod success
Aug 31 15:14:22.270: INFO: Pod "pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7" satisfied condition "success or failure"
Aug 31 15:14:22.273: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:14:22.286: INFO: Waiting for pod pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7 to disappear
Aug 31 15:14:22.288: INFO: Pod pod-projected-secrets-1a84624c-d5db-4451-9619-a99f7150a8e7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:14:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2369" for this suite.
Aug 31 15:14:28.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:14:28.373: INFO: namespace projected-2369 deletion completed in 6.081091604s

• [SLOW TEST:8.138 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:14:28.375: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug 31 15:14:38.418: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0831 15:14:38.417972      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:14:38.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8339" for this suite.
Aug 31 15:14:44.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:14:44.506: INFO: namespace gc-8339 deletion completed in 6.082487657s

• [SLOW TEST:16.131 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:14:44.506: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug 31 15:14:46.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec pod-sharedvolume-956de926-428f-4df6-848f-988b088c2711 -c busybox-main-container --namespace=emptydir-8764 -- cat /usr/share/volumeshare/shareddata.txt'
Aug 31 15:14:46.784: INFO: stderr: ""
Aug 31 15:14:46.784: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:14:46.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8764" for this suite.
Aug 31 15:14:52.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:14:52.856: INFO: namespace emptydir-8764 deletion completed in 6.067501292s

• [SLOW TEST:8.350 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:14:52.858: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:14:54.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-852" for this suite.
Aug 31 15:15:38.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:15:38.970: INFO: namespace kubelet-test-852 deletion completed in 44.066457855s

• [SLOW TEST:46.112 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:15:38.971: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-464
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-464
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-464
Aug 31 15:15:39.021: INFO: Found 0 stateful pods, waiting for 1
Aug 31 15:15:49.026: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug 31 15:15:49.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:15:49.174: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:15:49.174: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:15:49.174: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 15:15:49.177: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug 31 15:15:59.180: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 15:15:59.180: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 15:15:59.198: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999038s
Aug 31 15:16:00.202: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990466154s
Aug 31 15:16:01.206: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.986504087s
Aug 31 15:16:02.210: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982804832s
Aug 31 15:16:03.213: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979011835s
Aug 31 15:16:04.217: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97549098s
Aug 31 15:16:05.221: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97127557s
Aug 31 15:16:06.225: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967616041s
Aug 31 15:16:07.229: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.963689677s
Aug 31 15:16:08.235: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.476346ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-464
Aug 31 15:16:09.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:16:09.369: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:16:09.369: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:16:09.369: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 15:16:09.375: INFO: Found 1 stateful pods, waiting for 3
Aug 31 15:16:19.378: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 15:16:19.378: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 15:16:19.378: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug 31 15:16:19.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:16:19.528: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:16:19.529: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:16:19.529: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 15:16:19.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:16:19.681: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:16:19.681: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:16:19.681: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 15:16:19.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:16:19.841: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:16:19.841: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:16:19.841: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 15:16:19.841: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 15:16:19.845: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug 31 15:16:29.850: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 15:16:29.850: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 15:16:29.850: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug 31 15:16:29.861: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999639s
Aug 31 15:16:30.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995566832s
Aug 31 15:16:31.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991612669s
Aug 31 15:16:32.872: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987463653s
Aug 31 15:16:33.879: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.984496148s
Aug 31 15:16:34.883: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976718794s
Aug 31 15:16:35.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973437777s
Aug 31 15:16:36.890: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969550757s
Aug 31 15:16:37.895: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965438299s
Aug 31 15:16:38.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.010432ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-464
Aug 31 15:16:39.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:16:40.042: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:16:40.042: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:16:40.042: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 15:16:40.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:16:40.170: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:16:40.170: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:16:40.170: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 15:16:40.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-464 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:16:40.308: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:16:40.308: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:16:40.308: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 15:16:40.308: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 31 15:17:00.321: INFO: Deleting all statefulset in ns statefulset-464
Aug 31 15:17:00.324: INFO: Scaling statefulset ss to 0
Aug 31 15:17:00.334: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 15:17:00.336: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:17:00.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-464" for this suite.
Aug 31 15:17:06.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:17:06.417: INFO: namespace statefulset-464 deletion completed in 6.069574853s

• [SLOW TEST:87.446 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:17:06.417: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-9hs7w in namespace proxy-5376
I0831 15:17:06.461711      15 runners.go:180] Created replication controller with name: proxy-service-9hs7w, namespace: proxy-5376, replica count: 1
I0831 15:17:07.512381      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:08.513040      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:09.513518      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:10.514232      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:11.514581      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:12.515273      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:13.516158      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:14.516649      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:15.516977      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:16.517391      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:17.517703      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:18.518089      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:19.518559      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:20.518954      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:21.519574      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:22.520413      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:23.520781      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:24.521627      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:25.522058      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0831 15:17:26.523189      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0831 15:17:27.524131      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0831 15:17:28.524650      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0831 15:17:29.525798      15 runners.go:180] proxy-service-9hs7w Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug 31 15:17:29.528: INFO: setup took 23.090859885s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug 31 15:17:29.541: INFO: (0) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 12.412625ms)
Aug 31 15:17:29.541: INFO: (0) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 12.635029ms)
Aug 31 15:17:29.542: INFO: (0) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 12.974061ms)
Aug 31 15:17:29.546: INFO: (0) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 16.891157ms)
Aug 31 15:17:29.546: INFO: (0) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 16.886498ms)
Aug 31 15:17:29.549: INFO: (0) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 19.909088ms)
Aug 31 15:17:29.549: INFO: (0) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 19.915721ms)
Aug 31 15:17:29.549: INFO: (0) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 20.120783ms)
Aug 31 15:17:29.549: INFO: (0) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 20.511691ms)
Aug 31 15:17:29.550: INFO: (0) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 20.7857ms)
Aug 31 15:17:29.550: INFO: (0) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 21.006442ms)
Aug 31 15:17:29.552: INFO: (0) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 23.357992ms)
Aug 31 15:17:29.552: INFO: (0) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 23.205237ms)
Aug 31 15:17:29.552: INFO: (0) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 23.301527ms)
Aug 31 15:17:29.553: INFO: (0) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 23.848445ms)
Aug 31 15:17:29.557: INFO: (0) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 28.330644ms)
Aug 31 15:17:29.566: INFO: (1) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 8.699532ms)
Aug 31 15:17:29.566: INFO: (1) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 8.998707ms)
Aug 31 15:17:29.566: INFO: (1) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 9.079625ms)
Aug 31 15:17:29.574: INFO: (1) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 16.792774ms)
Aug 31 15:17:29.575: INFO: (1) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 17.094246ms)
Aug 31 15:17:29.575: INFO: (1) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 17.330666ms)
Aug 31 15:17:29.575: INFO: (1) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 17.361945ms)
Aug 31 15:17:29.575: INFO: (1) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 17.89403ms)
Aug 31 15:17:29.578: INFO: (1) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 20.542138ms)
Aug 31 15:17:29.578: INFO: (1) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 20.665387ms)
Aug 31 15:17:29.578: INFO: (1) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 20.835895ms)
Aug 31 15:17:29.584: INFO: (1) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 26.680227ms)
Aug 31 15:17:29.584: INFO: (1) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 26.828232ms)
Aug 31 15:17:29.584: INFO: (1) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 26.816971ms)
Aug 31 15:17:29.584: INFO: (1) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 26.84373ms)
Aug 31 15:17:29.584: INFO: (1) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 27.092424ms)
Aug 31 15:17:29.596: INFO: (2) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 11.764899ms)
Aug 31 15:17:29.600: INFO: (2) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 15.574696ms)
Aug 31 15:17:29.602: INFO: (2) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 17.388349ms)
Aug 31 15:17:29.602: INFO: (2) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 17.376437ms)
Aug 31 15:17:29.602: INFO: (2) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 17.382027ms)
Aug 31 15:17:29.602: INFO: (2) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 17.556942ms)
Aug 31 15:17:29.602: INFO: (2) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 17.701282ms)
Aug 31 15:17:29.604: INFO: (2) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 19.015054ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 20.040544ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 20.318602ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 20.337958ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 20.693751ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 20.778438ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 20.76312ms)
Aug 31 15:17:29.605: INFO: (2) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 20.764573ms)
Aug 31 15:17:29.607: INFO: (2) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 22.395742ms)
Aug 31 15:17:29.619: INFO: (3) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 11.26371ms)
Aug 31 15:17:29.627: INFO: (3) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 19.940497ms)
Aug 31 15:17:29.633: INFO: (3) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 24.633099ms)
Aug 31 15:17:29.633: INFO: (3) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 25.456191ms)
Aug 31 15:17:29.637: INFO: (3) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 28.945771ms)
Aug 31 15:17:29.638: INFO: (3) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 29.484034ms)
Aug 31 15:17:29.638: INFO: (3) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 29.983374ms)
Aug 31 15:17:29.638: INFO: (3) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 30.387016ms)
Aug 31 15:17:29.639: INFO: (3) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 30.828698ms)
Aug 31 15:17:29.644: INFO: (3) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 35.289577ms)
Aug 31 15:17:29.645: INFO: (3) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 37.001546ms)
Aug 31 15:17:29.649: INFO: (3) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 40.940563ms)
Aug 31 15:17:29.650: INFO: (3) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 41.778554ms)
Aug 31 15:17:29.650: INFO: (3) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 41.887798ms)
Aug 31 15:17:29.650: INFO: (3) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 41.811195ms)
Aug 31 15:17:29.658: INFO: (3) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 49.307107ms)
Aug 31 15:17:29.678: INFO: (4) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 19.803557ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 37.981122ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 39.175798ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 38.09809ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 38.375968ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 38.099222ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 38.034992ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 38.089043ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 37.654769ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 37.383103ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 37.237803ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 37.290431ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 37.576623ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 37.266195ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 37.409974ms)
Aug 31 15:17:29.697: INFO: (4) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 39.086281ms)
Aug 31 15:17:29.703: INFO: (5) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 5.251026ms)
Aug 31 15:17:29.711: INFO: (5) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 13.693696ms)
Aug 31 15:17:29.712: INFO: (5) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 14.328869ms)
Aug 31 15:17:29.712: INFO: (5) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 14.239273ms)
Aug 31 15:17:29.712: INFO: (5) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 14.357793ms)
Aug 31 15:17:29.716: INFO: (5) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 17.756389ms)
Aug 31 15:17:29.716: INFO: (5) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 17.785243ms)
Aug 31 15:17:29.716: INFO: (5) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 18.524886ms)
Aug 31 15:17:29.720: INFO: (5) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 22.422391ms)
Aug 31 15:17:29.722: INFO: (5) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 24.554952ms)
Aug 31 15:17:29.722: INFO: (5) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 24.606418ms)
Aug 31 15:17:29.722: INFO: (5) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 24.786664ms)
Aug 31 15:17:29.727: INFO: (5) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 29.260066ms)
Aug 31 15:17:29.727: INFO: (5) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 29.57862ms)
Aug 31 15:17:29.727: INFO: (5) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 29.290243ms)
Aug 31 15:17:29.727: INFO: (5) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 29.760539ms)
Aug 31 15:17:29.737: INFO: (6) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 9.578406ms)
Aug 31 15:17:29.737: INFO: (6) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 9.349082ms)
Aug 31 15:17:29.737: INFO: (6) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 9.571687ms)
Aug 31 15:17:29.738: INFO: (6) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 10.443683ms)
Aug 31 15:17:29.741: INFO: (6) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 13.447067ms)
Aug 31 15:17:29.741: INFO: (6) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 13.822707ms)
Aug 31 15:17:29.741: INFO: (6) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 14.038369ms)
Aug 31 15:17:29.744: INFO: (6) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 15.999542ms)
Aug 31 15:17:29.745: INFO: (6) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 17.50739ms)
Aug 31 15:17:29.745: INFO: (6) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 17.13172ms)
Aug 31 15:17:29.746: INFO: (6) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 18.750621ms)
Aug 31 15:17:29.747: INFO: (6) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 18.817135ms)
Aug 31 15:17:29.747: INFO: (6) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 19.192806ms)
Aug 31 15:17:29.747: INFO: (6) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 19.252747ms)
Aug 31 15:17:29.747: INFO: (6) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 19.442329ms)
Aug 31 15:17:29.747: INFO: (6) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 19.686124ms)
Aug 31 15:17:29.756: INFO: (7) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 7.374075ms)
Aug 31 15:17:29.758: INFO: (7) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 10.479134ms)
Aug 31 15:17:29.760: INFO: (7) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 11.473437ms)
Aug 31 15:17:29.760: INFO: (7) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 11.758187ms)
Aug 31 15:17:29.763: INFO: (7) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 15.040866ms)
Aug 31 15:17:29.765: INFO: (7) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 15.229938ms)
Aug 31 15:17:29.765: INFO: (7) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 15.579589ms)
Aug 31 15:17:29.765: INFO: (7) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 15.628711ms)
Aug 31 15:17:29.765: INFO: (7) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 15.847008ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 16.212508ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 16.876355ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 16.83608ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 16.826963ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 16.537404ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 16.971442ms)
Aug 31 15:17:29.766: INFO: (7) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 16.466482ms)
Aug 31 15:17:29.776: INFO: (8) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 9.412507ms)
Aug 31 15:17:29.779: INFO: (8) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 11.90989ms)
Aug 31 15:17:29.779: INFO: (8) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 12.251266ms)
Aug 31 15:17:29.781: INFO: (8) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 13.900583ms)
Aug 31 15:17:29.781: INFO: (8) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 14.330874ms)
Aug 31 15:17:29.783: INFO: (8) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 17.000892ms)
Aug 31 15:17:29.784: INFO: (8) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 16.561674ms)
Aug 31 15:17:29.787: INFO: (8) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 19.043376ms)
Aug 31 15:17:29.787: INFO: (8) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 20.368635ms)
Aug 31 15:17:29.787: INFO: (8) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 20.59656ms)
Aug 31 15:17:29.787: INFO: (8) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 20.710261ms)
Aug 31 15:17:29.789: INFO: (8) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 22.425967ms)
Aug 31 15:17:29.789: INFO: (8) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 22.382857ms)
Aug 31 15:17:29.789: INFO: (8) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 22.621261ms)
Aug 31 15:17:29.789: INFO: (8) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 21.672484ms)
Aug 31 15:17:29.789: INFO: (8) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 22.495848ms)
Aug 31 15:17:29.804: INFO: (9) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 14.042617ms)
Aug 31 15:17:29.804: INFO: (9) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 14.10349ms)
Aug 31 15:17:29.811: INFO: (9) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 18.660453ms)
Aug 31 15:17:29.811: INFO: (9) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 18.502108ms)
Aug 31 15:17:29.811: INFO: (9) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 19.293132ms)
Aug 31 15:17:29.811: INFO: (9) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 19.785915ms)
Aug 31 15:17:29.811: INFO: (9) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 20.349084ms)
Aug 31 15:17:29.818: INFO: (9) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 26.951903ms)
Aug 31 15:17:29.818: INFO: (9) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 26.495853ms)
Aug 31 15:17:29.818: INFO: (9) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 25.798067ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 27.372611ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 29.150257ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 28.481842ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 29.160196ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 28.947049ms)
Aug 31 15:17:29.819: INFO: (9) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 29.907198ms)
Aug 31 15:17:29.830: INFO: (10) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 10.57095ms)
Aug 31 15:17:29.830: INFO: (10) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 10.767291ms)
Aug 31 15:17:29.830: INFO: (10) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 10.664199ms)
Aug 31 15:17:29.832: INFO: (10) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 12.18414ms)
Aug 31 15:17:29.834: INFO: (10) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 14.520991ms)
Aug 31 15:17:29.836: INFO: (10) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 16.215504ms)
Aug 31 15:17:29.836: INFO: (10) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 16.20777ms)
Aug 31 15:17:29.837: INFO: (10) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 17.819442ms)
Aug 31 15:17:29.839: INFO: (10) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 19.11752ms)
Aug 31 15:17:29.839: INFO: (10) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 19.101179ms)
Aug 31 15:17:29.840: INFO: (10) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 20.490898ms)
Aug 31 15:17:29.840: INFO: (10) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 20.615851ms)
Aug 31 15:17:29.840: INFO: (10) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 20.590674ms)
Aug 31 15:17:29.841: INFO: (10) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 21.699039ms)
Aug 31 15:17:29.841: INFO: (10) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 22.061293ms)
Aug 31 15:17:29.841: INFO: (10) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 21.857193ms)
Aug 31 15:17:29.846: INFO: (11) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 4.316806ms)
Aug 31 15:17:29.850: INFO: (11) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 7.915605ms)
Aug 31 15:17:29.850: INFO: (11) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 8.840888ms)
Aug 31 15:17:29.852: INFO: (11) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 9.950915ms)
Aug 31 15:17:29.854: INFO: (11) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 10.752828ms)
Aug 31 15:17:29.854: INFO: (11) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 11.689218ms)
Aug 31 15:17:29.855: INFO: (11) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 12.229019ms)
Aug 31 15:17:29.856: INFO: (11) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 13.142601ms)
Aug 31 15:17:29.857: INFO: (11) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 14.026818ms)
Aug 31 15:17:29.857: INFO: (11) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 13.805866ms)
Aug 31 15:17:29.857: INFO: (11) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 15.019136ms)
Aug 31 15:17:29.857: INFO: (11) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 14.911927ms)
Aug 31 15:17:29.857: INFO: (11) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 15.186498ms)
Aug 31 15:17:29.858: INFO: (11) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 14.486955ms)
Aug 31 15:17:29.858: INFO: (11) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 14.836406ms)
Aug 31 15:17:29.860: INFO: (11) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 17.310328ms)
Aug 31 15:17:29.867: INFO: (12) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 7.152358ms)
Aug 31 15:17:29.868: INFO: (12) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 7.172024ms)
Aug 31 15:17:29.868: INFO: (12) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 7.64742ms)
Aug 31 15:17:29.872: INFO: (12) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 10.576406ms)
Aug 31 15:17:29.872: INFO: (12) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 10.596533ms)
Aug 31 15:17:29.872: INFO: (12) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 11.948341ms)
Aug 31 15:17:29.872: INFO: (12) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 11.867471ms)
Aug 31 15:17:29.873: INFO: (12) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 11.579244ms)
Aug 31 15:17:29.873: INFO: (12) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 11.771893ms)
Aug 31 15:17:29.874: INFO: (12) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 12.969448ms)
Aug 31 15:17:29.874: INFO: (12) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 13.565949ms)
Aug 31 15:17:29.874: INFO: (12) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 13.294844ms)
Aug 31 15:17:29.875: INFO: (12) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 13.057381ms)
Aug 31 15:17:29.875: INFO: (12) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 13.645487ms)
Aug 31 15:17:29.875: INFO: (12) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 14.011249ms)
Aug 31 15:17:29.877: INFO: (12) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 16.229821ms)
Aug 31 15:17:29.885: INFO: (13) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 7.990103ms)
Aug 31 15:17:29.887: INFO: (13) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 10.146816ms)
Aug 31 15:17:29.889: INFO: (13) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 11.557148ms)
Aug 31 15:17:29.890: INFO: (13) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 11.553956ms)
Aug 31 15:17:29.890: INFO: (13) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 12.86275ms)
Aug 31 15:17:29.891: INFO: (13) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 13.489507ms)
Aug 31 15:17:29.895: INFO: (13) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 17.604947ms)
Aug 31 15:17:29.896: INFO: (13) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 18.346463ms)
Aug 31 15:17:29.896: INFO: (13) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 18.551244ms)
Aug 31 15:17:29.896: INFO: (13) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 17.972597ms)
Aug 31 15:17:29.897: INFO: (13) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 18.669155ms)
Aug 31 15:17:29.897: INFO: (13) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 18.853949ms)
Aug 31 15:17:29.899: INFO: (13) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 20.226991ms)
Aug 31 15:17:29.899: INFO: (13) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 21.071745ms)
Aug 31 15:17:29.899: INFO: (13) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 20.907269ms)
Aug 31 15:17:29.901: INFO: (13) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 22.895873ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 11.091525ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 10.206557ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 10.309218ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 10.153598ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 10.522625ms)
Aug 31 15:17:29.912: INFO: (14) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 10.622882ms)
Aug 31 15:17:29.913: INFO: (14) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 11.869294ms)
Aug 31 15:17:29.915: INFO: (14) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 12.219075ms)
Aug 31 15:17:29.915: INFO: (14) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 13.314245ms)
Aug 31 15:17:29.915: INFO: (14) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 13.051015ms)
Aug 31 15:17:29.916: INFO: (14) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 13.179424ms)
Aug 31 15:17:29.916: INFO: (14) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 13.029896ms)
Aug 31 15:17:29.916: INFO: (14) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 15.233811ms)
Aug 31 15:17:29.917: INFO: (14) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 15.092147ms)
Aug 31 15:17:29.918: INFO: (14) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 15.44808ms)
Aug 31 15:17:29.920: INFO: (14) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 17.866164ms)
Aug 31 15:17:29.931: INFO: (15) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 11.026774ms)
Aug 31 15:17:29.931: INFO: (15) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 11.384871ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 30.120234ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 30.097291ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 30.153977ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 30.234427ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 30.30067ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 30.169135ms)
Aug 31 15:17:29.951: INFO: (15) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 30.220161ms)
Aug 31 15:17:29.954: INFO: (15) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 33.377441ms)
Aug 31 15:17:29.954: INFO: (15) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 32.948467ms)
Aug 31 15:17:29.954: INFO: (15) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 32.983562ms)
Aug 31 15:17:29.954: INFO: (15) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 33.043383ms)
Aug 31 15:17:29.954: INFO: (15) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 32.956692ms)
Aug 31 15:17:29.958: INFO: (15) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 36.89617ms)
Aug 31 15:17:29.958: INFO: (15) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 37.469743ms)
Aug 31 15:17:29.976: INFO: (16) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 17.302785ms)
Aug 31 15:17:29.978: INFO: (16) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 19.136831ms)
Aug 31 15:17:29.979: INFO: (16) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 21.011703ms)
Aug 31 15:17:29.984: INFO: (16) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 25.343923ms)
Aug 31 15:17:29.991: INFO: (16) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 31.676298ms)
Aug 31 15:17:29.993: INFO: (16) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 33.914101ms)
Aug 31 15:17:29.994: INFO: (16) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 34.81529ms)
Aug 31 15:17:29.997: INFO: (16) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 37.326733ms)
Aug 31 15:17:29.997: INFO: (16) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 38.512522ms)
Aug 31 15:17:29.998: INFO: (16) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 38.781102ms)
Aug 31 15:17:30.000: INFO: (16) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 40.234418ms)
Aug 31 15:17:30.002: INFO: (16) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 42.446924ms)
Aug 31 15:17:30.002: INFO: (16) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 41.645006ms)
Aug 31 15:17:30.010: INFO: (16) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 51.055079ms)
Aug 31 15:17:30.010: INFO: (16) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 49.981705ms)
Aug 31 15:17:30.010: INFO: (16) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 49.799606ms)
Aug 31 15:17:30.019: INFO: (17) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 7.378063ms)
Aug 31 15:17:30.021: INFO: (17) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 9.382446ms)
Aug 31 15:17:30.027: INFO: (17) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 15.650076ms)
Aug 31 15:17:30.033: INFO: (17) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 21.73506ms)
Aug 31 15:17:30.034: INFO: (17) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 23.215117ms)
Aug 31 15:17:30.034: INFO: (17) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 22.977886ms)
Aug 31 15:17:30.034: INFO: (17) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 23.848978ms)
Aug 31 15:17:30.035: INFO: (17) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 22.949442ms)
Aug 31 15:17:30.035: INFO: (17) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 24.059299ms)
Aug 31 15:17:30.037: INFO: (17) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 25.494337ms)
Aug 31 15:17:30.037: INFO: (17) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 25.79374ms)
Aug 31 15:17:30.037: INFO: (17) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 26.027165ms)
Aug 31 15:17:30.037: INFO: (17) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 26.090072ms)
Aug 31 15:17:30.037: INFO: (17) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 26.269231ms)
Aug 31 15:17:30.039: INFO: (17) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 28.09129ms)
Aug 31 15:17:30.042: INFO: (17) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 30.946283ms)
Aug 31 15:17:30.054: INFO: (18) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 12.251108ms)
Aug 31 15:17:30.056: INFO: (18) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 14.169854ms)
Aug 31 15:17:30.066: INFO: (18) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 23.733753ms)
Aug 31 15:17:30.066: INFO: (18) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 24.196445ms)
Aug 31 15:17:30.068: INFO: (18) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 26.030636ms)
Aug 31 15:17:30.068: INFO: (18) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 26.402483ms)
Aug 31 15:17:30.069: INFO: (18) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 27.35851ms)
Aug 31 15:17:30.069: INFO: (18) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 27.175119ms)
Aug 31 15:17:30.070: INFO: (18) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 27.19231ms)
Aug 31 15:17:30.070: INFO: (18) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 27.998061ms)
Aug 31 15:17:30.071: INFO: (18) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 28.254388ms)
Aug 31 15:17:30.071: INFO: (18) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 28.299943ms)
Aug 31 15:17:30.071: INFO: (18) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 28.250972ms)
Aug 31 15:17:30.072: INFO: (18) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 30.027552ms)
Aug 31 15:17:30.073: INFO: (18) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 30.963144ms)
Aug 31 15:17:30.076: INFO: (18) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 33.714569ms)
Aug 31 15:17:30.086: INFO: (19) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:443/proxy/tlsrewritem... (200; 9.790727ms)
Aug 31 15:17:30.086: INFO: (19) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq/proxy/rewriteme">test</a> (200; 9.870721ms)
Aug 31 15:17:30.088: INFO: (19) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 11.876567ms)
Aug 31 15:17:30.090: INFO: (19) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname1/proxy/: foo (200; 14.016764ms)
Aug 31 15:17:30.090: INFO: (19) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname1/proxy/: foo (200; 14.304105ms)
Aug 31 15:17:30.090: INFO: (19) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">test<... (200; 14.134919ms)
Aug 31 15:17:30.097: INFO: (19) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:160/proxy/: foo (200; 20.345517ms)
Aug 31 15:17:30.097: INFO: (19) /api/v1/namespaces/proxy-5376/services/http:proxy-service-9hs7w:portname2/proxy/: bar (200; 20.232251ms)
Aug 31 15:17:30.097: INFO: (19) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:460/proxy/: tls baz (200; 20.437168ms)
Aug 31 15:17:30.109: INFO: (19) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 32.563836ms)
Aug 31 15:17:30.109: INFO: (19) /api/v1/namespaces/proxy-5376/pods/https:proxy-service-9hs7w-22mcq:462/proxy/: tls qux (200; 32.627064ms)
Aug 31 15:17:30.109: INFO: (19) /api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/: <a href="/api/v1/namespaces/proxy-5376/pods/http:proxy-service-9hs7w-22mcq:1080/proxy/rewriteme">... (200; 32.962589ms)
Aug 31 15:17:30.112: INFO: (19) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname2/proxy/: tls qux (200; 35.88939ms)
Aug 31 15:17:30.112: INFO: (19) /api/v1/namespaces/proxy-5376/pods/proxy-service-9hs7w-22mcq:162/proxy/: bar (200; 35.920108ms)
Aug 31 15:17:30.113: INFO: (19) /api/v1/namespaces/proxy-5376/services/https:proxy-service-9hs7w:tlsportname1/proxy/: tls baz (200; 36.844284ms)
Aug 31 15:17:30.116: INFO: (19) /api/v1/namespaces/proxy-5376/services/proxy-service-9hs7w:portname2/proxy/: bar (200; 40.211451ms)
STEP: deleting ReplicationController proxy-service-9hs7w in namespace proxy-5376, will wait for the garbage collector to delete the pods
Aug 31 15:17:30.181: INFO: Deleting ReplicationController proxy-service-9hs7w took: 4.471685ms
Aug 31 15:17:30.282: INFO: Terminating ReplicationController proxy-service-9hs7w pods took: 100.492294ms
[AfterEach] version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:17:36.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5376" for this suite.
Aug 31 15:17:42.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:17:42.452: INFO: namespace proxy-5376 deletion completed in 6.064157259s

• [SLOW TEST:36.035 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:17:42.452: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5fb22663-f7cf-4775-8a5c-1fee1447442c
STEP: Creating a pod to test consume secrets
Aug 31 15:17:42.503: INFO: Waiting up to 5m0s for pod "pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286" in namespace "secrets-6623" to be "success or failure"
Aug 31 15:17:42.506: INFO: Pod "pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286": Phase="Pending", Reason="", readiness=false. Elapsed: 2.922424ms
Aug 31 15:17:44.509: INFO: Pod "pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005986718s
STEP: Saw pod success
Aug 31 15:17:44.509: INFO: Pod "pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286" satisfied condition "success or failure"
Aug 31 15:17:44.511: INFO: Trying to get logs from node vm119042 pod pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:17:44.527: INFO: Waiting for pod pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286 to disappear
Aug 31 15:17:44.529: INFO: Pod pod-secrets-721fa145-bdce-47f7-b47d-ab428216e286 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:17:44.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6623" for this suite.
Aug 31 15:17:50.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:17:50.602: INFO: namespace secrets-6623 deletion completed in 6.068609944s
STEP: Destroying namespace "secret-namespace-944" for this suite.
Aug 31 15:17:56.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:17:56.759: INFO: namespace secret-namespace-944 deletion completed in 6.156772188s

• [SLOW TEST:14.307 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:17:56.760: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug 31 15:17:59.322: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9477 pod-service-account-c2d6e3ba-7d39-4f16-b658-b7003c0c98c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug 31 15:17:59.458: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9477 pod-service-account-c2d6e3ba-7d39-4f16-b658-b7003c0c98c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug 31 15:17:59.585: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9477 pod-service-account-c2d6e3ba-7d39-4f16-b658-b7003c0c98c1 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:17:59.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9477" for this suite.
Aug 31 15:18:05.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:18:05.792: INFO: namespace svcaccounts-9477 deletion completed in 6.068070042s

• [SLOW TEST:9.032 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:18:05.795: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug 31 15:18:05.873: INFO: Waiting up to 5m0s for pod "pod-d225fc03-86dc-4796-812f-cbc94107b0b7" in namespace "emptydir-2608" to be "success or failure"
Aug 31 15:18:05.875: INFO: Pod "pod-d225fc03-86dc-4796-812f-cbc94107b0b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.347663ms
Aug 31 15:18:07.878: INFO: Pod "pod-d225fc03-86dc-4796-812f-cbc94107b0b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005750993s
Aug 31 15:18:09.882: INFO: Pod "pod-d225fc03-86dc-4796-812f-cbc94107b0b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00926708s
STEP: Saw pod success
Aug 31 15:18:09.882: INFO: Pod "pod-d225fc03-86dc-4796-812f-cbc94107b0b7" satisfied condition "success or failure"
Aug 31 15:18:09.884: INFO: Trying to get logs from node vm119042 pod pod-d225fc03-86dc-4796-812f-cbc94107b0b7 container test-container: <nil>
STEP: delete the pod
Aug 31 15:18:09.896: INFO: Waiting for pod pod-d225fc03-86dc-4796-812f-cbc94107b0b7 to disappear
Aug 31 15:18:09.899: INFO: Pod pod-d225fc03-86dc-4796-812f-cbc94107b0b7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:18:09.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2608" for this suite.
Aug 31 15:18:15.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:18:15.969: INFO: namespace emptydir-2608 deletion completed in 6.066586504s

• [SLOW TEST:10.175 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:18:15.969: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:18:15.991: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:18:17.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6430" for this suite.
Aug 31 15:18:23.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:18:23.100: INFO: namespace custom-resource-definition-6430 deletion completed in 6.072956705s

• [SLOW TEST:7.131 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:18:23.101: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:18:27.158: INFO: Waiting up to 5m0s for pod "client-envvars-3579462a-141c-4ada-979e-84c9037db4eb" in namespace "pods-9982" to be "success or failure"
Aug 31 15:18:27.166: INFO: Pod "client-envvars-3579462a-141c-4ada-979e-84c9037db4eb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.787365ms
Aug 31 15:18:29.169: INFO: Pod "client-envvars-3579462a-141c-4ada-979e-84c9037db4eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011135674s
STEP: Saw pod success
Aug 31 15:18:29.169: INFO: Pod "client-envvars-3579462a-141c-4ada-979e-84c9037db4eb" satisfied condition "success or failure"
Aug 31 15:18:29.172: INFO: Trying to get logs from node vm119042 pod client-envvars-3579462a-141c-4ada-979e-84c9037db4eb container env3cont: <nil>
STEP: delete the pod
Aug 31 15:18:29.188: INFO: Waiting for pod client-envvars-3579462a-141c-4ada-979e-84c9037db4eb to disappear
Aug 31 15:18:29.191: INFO: Pod client-envvars-3579462a-141c-4ada-979e-84c9037db4eb no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:18:29.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9982" for this suite.
Aug 31 15:19:19.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:19:19.281: INFO: namespace pods-9982 deletion completed in 50.07977493s

• [SLOW TEST:56.181 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:19:19.283: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-d367a766-ea99-4229-ba1c-eaa536b7c65c
STEP: Creating a pod to test consume secrets
Aug 31 15:19:19.312: INFO: Waiting up to 5m0s for pod "pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513" in namespace "secrets-4476" to be "success or failure"
Aug 31 15:19:19.314: INFO: Pod "pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513": Phase="Pending", Reason="", readiness=false. Elapsed: 2.586568ms
Aug 31 15:19:21.317: INFO: Pod "pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005819501s
STEP: Saw pod success
Aug 31 15:19:21.318: INFO: Pod "pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513" satisfied condition "success or failure"
Aug 31 15:19:21.320: INFO: Trying to get logs from node vm119042 pod pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:19:21.332: INFO: Waiting for pod pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513 to disappear
Aug 31 15:19:21.335: INFO: Pod pod-secrets-53a28272-dc59-4463-9869-15ef4aa38513 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:19:21.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4476" for this suite.
Aug 31 15:19:27.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:19:27.405: INFO: namespace secrets-4476 deletion completed in 6.066887941s

• [SLOW TEST:8.122 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:19:27.406: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-2d021ccc-88d8-4fe3-8866-a70aedaece5b
STEP: Creating a pod to test consume secrets
Aug 31 15:19:27.435: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4" in namespace "projected-5307" to be "success or failure"
Aug 31 15:19:27.438: INFO: Pod "pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.986473ms
Aug 31 15:19:29.442: INFO: Pod "pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007232379s
STEP: Saw pod success
Aug 31 15:19:29.442: INFO: Pod "pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4" satisfied condition "success or failure"
Aug 31 15:19:29.445: INFO: Trying to get logs from node vm119042 pod pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:19:29.459: INFO: Waiting for pod pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4 to disappear
Aug 31 15:19:29.461: INFO: Pod pod-projected-secrets-85e532bd-814c-4b7b-84b9-1de6196f70a4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:19:29.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5307" for this suite.
Aug 31 15:19:35.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:19:35.531: INFO: namespace projected-5307 deletion completed in 6.066728824s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:19:35.533: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug 31 15:19:35.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 cluster-info'
Aug 31 15:19:35.611: INFO: stderr: ""
Aug 31 15:19:35.611: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:19:35.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8051" for this suite.
Aug 31 15:19:41.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:19:41.688: INFO: namespace kubectl-8051 deletion completed in 6.07305013s

• [SLOW TEST:6.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:19:41.690: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:19:41.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-4502'
Aug 31 15:19:41.874: INFO: stderr: ""
Aug 31 15:19:41.874: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug 31 15:19:41.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-4502'
Aug 31 15:19:42.007: INFO: stderr: ""
Aug 31 15:19:42.007: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 31 15:19:43.010: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:19:43.010: INFO: Found 0 / 1
Aug 31 15:19:44.010: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:19:44.010: INFO: Found 1 / 1
Aug 31 15:19:44.010: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 31 15:19:44.013: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:19:44.013: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 31 15:19:44.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 describe pod redis-master-v4g29 --namespace=kubectl-4502'
Aug 31 15:19:44.072: INFO: stderr: ""
Aug 31 15:19:44.072: INFO: stdout: "Name:           redis-master-v4g29\nNamespace:      kubectl-4502\nPriority:       0\nNode:           vm119042/192.168.119.42\nStart Time:     Wed, 31 Aug 2022 15:19:41 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.244.1.47\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://fb54ec009d0901d5fda52cad44bd8ba7ff0ce892d45999dd2ec5c0883caf3f77\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 31 Aug 2022 15:19:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-b8ql9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-b8ql9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-b8ql9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-4502/redis-master-v4g29 to vm119042\n  Normal  Pulled     2s    kubelet, vm119042  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, vm119042  Created container redis-master\n  Normal  Started    2s    kubelet, vm119042  Started container redis-master\n"
Aug 31 15:19:44.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 describe rc redis-master --namespace=kubectl-4502'
Aug 31 15:19:44.139: INFO: stderr: ""
Aug 31 15:19:44.140: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4502\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-v4g29\n"
Aug 31 15:19:44.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 describe service redis-master --namespace=kubectl-4502'
Aug 31 15:19:44.201: INFO: stderr: ""
Aug 31 15:19:44.201: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4502\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.147.252\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.47:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug 31 15:19:44.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 describe node vm119041'
Aug 31 15:19:44.284: INFO: stderr: ""
Aug 31 15:19:44.284: INFO: stdout: "Name:               vm119041\nRoles:              control-plane,master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=vm119041\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VNI\":1,\"VtepMAC\":\"9e:e3:50:f0:26:c7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.119.41\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 31 Aug 2022 12:05:20 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 31 Aug 2022 12:10:19 +0000   Wed, 31 Aug 2022 12:10:19 +0000   FlannelIsUp                  Flannel is running on this node\n  MemoryPressure       False   Wed, 31 Aug 2022 15:19:08 +0000   Wed, 31 Aug 2022 12:05:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Wed, 31 Aug 2022 15:19:08 +0000   Wed, 31 Aug 2022 12:05:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Wed, 31 Aug 2022 15:19:08 +0000   Wed, 31 Aug 2022 12:05:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Wed, 31 Aug 2022 15:19:08 +0000   Wed, 31 Aug 2022 12:10:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  192.168.119.41\n  Hostname:    vm119041\nCapacity:\n cpu:                2\n ephemeral-storage:  19688064Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3994664Ki\n pods:               110\nAllocatable:\n cpu:                1500m\n ephemeral-storage:  16546489929\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2229288Ki\n pods:               110\nSystem Info:\n Machine ID:                 d48a5767cf734c37b5964a74690c62e7\n System UUID:                7d8b4d56-784a-e00d-675a-b988749eff84\n Boot ID:                    37742871-b92b-4af5-bf80-35407a15e52b\n Kernel Version:             5.4.0-125-generic\n OS Image:                   Ubuntu 20.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://19.3.9\n Kubelet Version:            v1.15.12\n Kube-Proxy Version:         v1.15.12\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (3 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                kube-flannel-ds-r6tpw                                      100m (6%)     100m (6%)   50Mi (2%)        50Mi (2%)      3h10m\n  kube-system                metrics-server-54cdcdcd69-x5nfx                            100m (6%)     0 (0%)      200Mi (9%)       0 (0%)         3h10m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-673f990a21f74630-kkc9r    0 (0%)        0 (0%)      0 (0%)           0 (0%)         59m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                200m (13%)   100m (6%)\n  memory             250Mi (11%)  50Mi (2%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:\n  Type    Reason                   Age                    From                  Message\n  ----    ------                   ----                   ----                  -------\n  Normal  Starting                 3h14m                  kubelet, vm119041     Starting kubelet.\n  Normal  NodeHasSufficientMemory  3h14m (x2 over 3h14m)  kubelet, vm119041     Node vm119041 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    3h14m (x2 over 3h14m)  kubelet, vm119041     Node vm119041 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     3h14m (x2 over 3h14m)  kubelet, vm119041     Node vm119041 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  3h14m                  kubelet, vm119041     Updated Node Allocatable limit across pods\n  Normal  Starting                 3h13m                  kube-proxy, vm119041  Starting kube-proxy.\n  Normal  NodeReady                3h9m                   kubelet, vm119041     Node vm119041 status is now: NodeReady\n"
Aug 31 15:19:44.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 describe namespace kubectl-4502'
Aug 31 15:19:44.340: INFO: stderr: ""
Aug 31 15:19:44.340: INFO: stdout: "Name:         kubectl-4502\nLabels:       e2e-framework=kubectl\n              e2e-run=68fb4d2d-b539-438f-85a2-f443177f1af7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:19:44.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4502" for this suite.
Aug 31 15:20:06.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:20:06.409: INFO: namespace kubectl-4502 deletion completed in 22.064091839s

• [SLOW TEST:24.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:20:06.409: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug 31 15:20:06.438: INFO: Waiting up to 5m0s for pod "pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2" in namespace "emptydir-5865" to be "success or failure"
Aug 31 15:20:06.441: INFO: Pod "pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.266119ms
Aug 31 15:20:08.445: INFO: Pod "pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006646301s
STEP: Saw pod success
Aug 31 15:20:08.445: INFO: Pod "pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2" satisfied condition "success or failure"
Aug 31 15:20:08.447: INFO: Trying to get logs from node vm119042 pod pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2 container test-container: <nil>
STEP: delete the pod
Aug 31 15:20:08.460: INFO: Waiting for pod pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2 to disappear
Aug 31 15:20:08.462: INFO: Pod pod-a301b8c2-31d4-4ff0-96da-fccd823c9df2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:20:08.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5865" for this suite.
Aug 31 15:20:14.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:20:14.551: INFO: namespace emptydir-5865 deletion completed in 6.083593694s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:20:14.552: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3274.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3274.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 15:20:18.607: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:18.610: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:18.617: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:18.620: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:18.620: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:23.630: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:23.633: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:23.642: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:23.644: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:23.644: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:28.638: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:28.643: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:28.653: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:28.656: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:28.656: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:33.628: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:33.631: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:33.639: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:33.643: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:33.643: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:38.630: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:38.633: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:38.640: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:38.642: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:38.642: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:43.629: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:43.631: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:43.639: INFO: Unable to read jessie_udp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:43.641: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b: the server could not find the requested resource (get pods dns-test-3d26a703-edde-44c7-ba59-263ca428023b)
Aug 31 15:20:43.641: INFO: Lookups using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:20:48.642: INFO: DNS probes using dns-3274/dns-test-3d26a703-edde-44c7-ba59-263ca428023b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:20:48.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3274" for this suite.
Aug 31 15:20:54.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:20:54.719: INFO: namespace dns-3274 deletion completed in 6.064520418s

• [SLOW TEST:40.167 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:20:54.719: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug 31 15:20:54.745: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6322" to be "success or failure"
Aug 31 15:20:54.749: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.966388ms
Aug 31 15:20:56.752: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007379036s
STEP: Saw pod success
Aug 31 15:20:56.752: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug 31 15:20:56.756: INFO: Trying to get logs from node vm119042 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug 31 15:20:56.768: INFO: Waiting for pod pod-host-path-test to disappear
Aug 31 15:20:56.771: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:20:56.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6322" for this suite.
Aug 31 15:21:02.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:21:02.839: INFO: namespace hostpath-6322 deletion completed in 6.065479253s

• [SLOW TEST:8.120 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:21:02.841: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug 31 15:21:06.899: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 31 15:21:06.903: INFO: Pod pod-with-prestop-http-hook still exists
Aug 31 15:21:08.903: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 31 15:21:08.906: INFO: Pod pod-with-prestop-http-hook still exists
Aug 31 15:21:10.903: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug 31 15:21:10.906: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:21:10.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5998" for this suite.
Aug 31 15:21:32.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:21:32.984: INFO: namespace container-lifecycle-hook-5998 deletion completed in 22.067490566s

• [SLOW TEST:30.143 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:21:32.985: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 31 15:21:33.006: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:21:36.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1662" for this suite.
Aug 31 15:21:58.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:21:58.800: INFO: namespace init-container-1662 deletion completed in 22.067898947s

• [SLOW TEST:25.815 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:21:58.800: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-40cf0e65-bf11-47ac-b0ef-e03f6b90dccf
STEP: Creating a pod to test consume secrets
Aug 31 15:21:58.831: INFO: Waiting up to 5m0s for pod "pod-secrets-abd19d93-aa06-498c-9881-256acc332041" in namespace "secrets-3388" to be "success or failure"
Aug 31 15:21:58.837: INFO: Pod "pod-secrets-abd19d93-aa06-498c-9881-256acc332041": Phase="Pending", Reason="", readiness=false. Elapsed: 6.623412ms
Aug 31 15:22:00.841: INFO: Pod "pod-secrets-abd19d93-aa06-498c-9881-256acc332041": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009918342s
STEP: Saw pod success
Aug 31 15:22:00.841: INFO: Pod "pod-secrets-abd19d93-aa06-498c-9881-256acc332041" satisfied condition "success or failure"
Aug 31 15:22:00.844: INFO: Trying to get logs from node vm119042 pod pod-secrets-abd19d93-aa06-498c-9881-256acc332041 container secret-env-test: <nil>
STEP: delete the pod
Aug 31 15:22:00.859: INFO: Waiting for pod pod-secrets-abd19d93-aa06-498c-9881-256acc332041 to disappear
Aug 31 15:22:00.862: INFO: Pod pod-secrets-abd19d93-aa06-498c-9881-256acc332041 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:00.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3388" for this suite.
Aug 31 15:22:06.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:22:06.938: INFO: namespace secrets-3388 deletion completed in 6.072911158s

• [SLOW TEST:8.138 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:22:06.940: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-49a38f52-d00d-49c2-ad2d-3cf04eb56c65
STEP: Creating a pod to test consume configMaps
Aug 31 15:22:06.971: INFO: Waiting up to 5m0s for pod "pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718" in namespace "configmap-4771" to be "success or failure"
Aug 31 15:22:06.979: INFO: Pod "pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718": Phase="Pending", Reason="", readiness=false. Elapsed: 8.215121ms
Aug 31 15:22:08.982: INFO: Pod "pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011815366s
STEP: Saw pod success
Aug 31 15:22:08.982: INFO: Pod "pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718" satisfied condition "success or failure"
Aug 31 15:22:08.985: INFO: Trying to get logs from node vm119042 pod pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:22:08.999: INFO: Waiting for pod pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718 to disappear
Aug 31 15:22:09.001: INFO: Pod pod-configmaps-509e12d5-32b8-4d2a-9a08-12b205742718 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:09.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4771" for this suite.
Aug 31 15:22:15.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:22:15.096: INFO: namespace configmap-4771 deletion completed in 6.090768383s

• [SLOW TEST:8.157 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:22:15.099: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug 31 15:22:15.633: INFO: created pod pod-service-account-defaultsa
Aug 31 15:22:15.633: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug 31 15:22:15.638: INFO: created pod pod-service-account-mountsa
Aug 31 15:22:15.638: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug 31 15:22:15.643: INFO: created pod pod-service-account-nomountsa
Aug 31 15:22:15.643: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug 31 15:22:15.649: INFO: created pod pod-service-account-defaultsa-mountspec
Aug 31 15:22:15.649: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug 31 15:22:15.681: INFO: created pod pod-service-account-mountsa-mountspec
Aug 31 15:22:15.681: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug 31 15:22:15.686: INFO: created pod pod-service-account-nomountsa-mountspec
Aug 31 15:22:15.686: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug 31 15:22:15.693: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug 31 15:22:15.694: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug 31 15:22:15.699: INFO: created pod pod-service-account-mountsa-nomountspec
Aug 31 15:22:15.699: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug 31 15:22:15.707: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug 31 15:22:15.707: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:15.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1017" for this suite.
Aug 31 15:22:37.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:22:37.822: INFO: namespace svcaccounts-1017 deletion completed in 22.109789882s

• [SLOW TEST:22.724 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:22:37.823: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6279/secret-test-d527e2bb-f725-4af4-8ed0-a8bd76698df3
STEP: Creating a pod to test consume secrets
Aug 31 15:22:37.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166" in namespace "secrets-6279" to be "success or failure"
Aug 31 15:22:37.856: INFO: Pod "pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166": Phase="Pending", Reason="", readiness=false. Elapsed: 3.757999ms
Aug 31 15:22:39.860: INFO: Pod "pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007126539s
Aug 31 15:22:41.863: INFO: Pod "pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010245735s
STEP: Saw pod success
Aug 31 15:22:41.863: INFO: Pod "pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166" satisfied condition "success or failure"
Aug 31 15:22:41.866: INFO: Trying to get logs from node vm119042 pod pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166 container env-test: <nil>
STEP: delete the pod
Aug 31 15:22:41.880: INFO: Waiting for pod pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166 to disappear
Aug 31 15:22:41.881: INFO: Pod pod-configmaps-6f625379-c00c-41cf-b8e9-bc2242502166 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:41.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6279" for this suite.
Aug 31 15:22:47.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:22:47.952: INFO: namespace secrets-6279 deletion completed in 6.067042087s

• [SLOW TEST:10.129 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:22:47.952: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug 31 15:22:47.987: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:49.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2798" for this suite.
Aug 31 15:22:55.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:22:55.081: INFO: namespace replication-controller-2798 deletion completed in 6.067519624s

• [SLOW TEST:7.130 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:22:55.082: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug 31 15:22:55.112: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8268,SelfLink:/api/v1/namespaces/watch-8268/configmaps/e2e-watch-test-watch-closed,UID:599b7e98-3ee3-475d-804c-89e997bd8568,ResourceVersion:39486,Generation:0,CreationTimestamp:2022-08-31 15:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 31 15:22:55.112: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8268,SelfLink:/api/v1/namespaces/watch-8268/configmaps/e2e-watch-test-watch-closed,UID:599b7e98-3ee3-475d-804c-89e997bd8568,ResourceVersion:39487,Generation:0,CreationTimestamp:2022-08-31 15:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug 31 15:22:55.122: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8268,SelfLink:/api/v1/namespaces/watch-8268/configmaps/e2e-watch-test-watch-closed,UID:599b7e98-3ee3-475d-804c-89e997bd8568,ResourceVersion:39488,Generation:0,CreationTimestamp:2022-08-31 15:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 31 15:22:55.122: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8268,SelfLink:/api/v1/namespaces/watch-8268/configmaps/e2e-watch-test-watch-closed,UID:599b7e98-3ee3-475d-804c-89e997bd8568,ResourceVersion:39489,Generation:0,CreationTimestamp:2022-08-31 15:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:22:55.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8268" for this suite.
Aug 31 15:23:01.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:23:01.196: INFO: namespace watch-8268 deletion completed in 6.071500328s

• [SLOW TEST:6.115 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:23:01.196: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 31 15:23:02.237: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:23:02.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5152" for this suite.
Aug 31 15:23:08.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:23:08.313: INFO: namespace container-runtime-5152 deletion completed in 6.061873066s

• [SLOW TEST:7.117 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:23:08.313: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 31 15:23:08.339: INFO: namespace kubectl-7740
Aug 31 15:23:08.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-7740'
Aug 31 15:23:08.458: INFO: stderr: ""
Aug 31 15:23:08.458: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 31 15:23:09.462: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:23:09.462: INFO: Found 1 / 1
Aug 31 15:23:09.462: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug 31 15:23:09.464: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:23:09.464: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 31 15:23:09.464: INFO: wait on redis-master startup in kubectl-7740 
Aug 31 15:23:09.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 logs redis-master-w2f4f redis-master --namespace=kubectl-7740'
Aug 31 15:23:09.526: INFO: stderr: ""
Aug 31 15:23:09.526: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 31 Aug 15:23:09.092 # Server started, Redis version 3.2.12\n1:M 31 Aug 15:23:09.092 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 31 Aug 15:23:09.092 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug 31 15:23:09.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7740'
Aug 31 15:23:09.595: INFO: stderr: ""
Aug 31 15:23:09.595: INFO: stdout: "service/rm2 exposed\n"
Aug 31 15:23:09.609: INFO: Service rm2 in namespace kubectl-7740 found.
STEP: exposing service
Aug 31 15:23:11.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7740'
Aug 31 15:23:11.680: INFO: stderr: ""
Aug 31 15:23:11.680: INFO: stdout: "service/rm3 exposed\n"
Aug 31 15:23:11.684: INFO: Service rm3 in namespace kubectl-7740 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:23:13.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7740" for this suite.
Aug 31 15:23:35.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:23:35.775: INFO: namespace kubectl-7740 deletion completed in 22.081642152s

• [SLOW TEST:27.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:23:35.776: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:23:35.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2904" for this suite.
Aug 31 15:23:57.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:23:57.934: INFO: namespace pods-2904 deletion completed in 22.06832807s

• [SLOW TEST:22.158 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:23:57.934: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-1009
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 31 15:23:57.962: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 31 15:24:18.050: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.78:8080/dial?request=hostName&protocol=udp&host=10.244.0.70&port=8081&tries=1'] Namespace:pod-network-test-1009 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:24:18.050: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:24:18.126: INFO: Waiting for endpoints: map[]
Aug 31 15:24:18.129: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.78:8080/dial?request=hostName&protocol=udp&host=10.244.1.62&port=8081&tries=1'] Namespace:pod-network-test-1009 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:24:18.129: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:24:18.192: INFO: Waiting for endpoints: map[]
Aug 31 15:24:18.195: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.78:8080/dial?request=hostName&protocol=udp&host=10.244.2.77&port=8081&tries=1'] Namespace:pod-network-test-1009 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:24:18.195: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:24:18.276: INFO: Waiting for endpoints: map[]
Aug 31 15:24:18.278: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.2.78:8080/dial?request=hostName&protocol=udp&host=10.244.3.155&port=8081&tries=1'] Namespace:pod-network-test-1009 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:24:18.278: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:24:18.349: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:24:18.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1009" for this suite.
Aug 31 15:24:40.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:24:40.418: INFO: namespace pod-network-test-1009 deletion completed in 22.064760206s

• [SLOW TEST:42.483 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:24:40.418: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Aug 31 15:24:40.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-7206'
Aug 31 15:24:40.603: INFO: stderr: ""
Aug 31 15:24:40.603: INFO: stdout: "pod/pause created\n"
Aug 31 15:24:40.603: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug 31 15:24:40.603: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7206" to be "running and ready"
Aug 31 15:24:40.607: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.722939ms
Aug 31 15:24:42.611: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007719086s
Aug 31 15:24:42.611: INFO: Pod "pause" satisfied condition "running and ready"
Aug 31 15:24:42.611: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug 31 15:24:42.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 label pods pause testing-label=testing-label-value --namespace=kubectl-7206'
Aug 31 15:24:42.666: INFO: stderr: ""
Aug 31 15:24:42.666: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug 31 15:24:42.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pod pause -L testing-label --namespace=kubectl-7206'
Aug 31 15:24:42.715: INFO: stderr: ""
Aug 31 15:24:42.715: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug 31 15:24:42.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 label pods pause testing-label- --namespace=kubectl-7206'
Aug 31 15:24:42.773: INFO: stderr: ""
Aug 31 15:24:42.773: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug 31 15:24:42.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pod pause -L testing-label --namespace=kubectl-7206'
Aug 31 15:24:42.824: INFO: stderr: ""
Aug 31 15:24:42.824: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Aug 31 15:24:42.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-7206'
Aug 31 15:24:42.886: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:24:42.886: INFO: stdout: "pod \"pause\" force deleted\n"
Aug 31 15:24:42.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get rc,svc -l name=pause --no-headers --namespace=kubectl-7206'
Aug 31 15:24:42.960: INFO: stderr: "No resources found.\n"
Aug 31 15:24:42.960: INFO: stdout: ""
Aug 31 15:24:42.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 get pods -l name=pause --namespace=kubectl-7206 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug 31 15:24:43.015: INFO: stderr: ""
Aug 31 15:24:43.015: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:24:43.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7206" for this suite.
Aug 31 15:24:49.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:24:49.094: INFO: namespace kubectl-7206 deletion completed in 6.072467905s

• [SLOW TEST:8.676 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:24:49.094: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 31 15:24:49.115: INFO: Waiting up to 5m0s for pod "pod-aa639e1b-8b46-4932-924a-d2b8f9536736" in namespace "emptydir-8029" to be "success or failure"
Aug 31 15:24:49.118: INFO: Pod "pod-aa639e1b-8b46-4932-924a-d2b8f9536736": Phase="Pending", Reason="", readiness=false. Elapsed: 2.962613ms
Aug 31 15:24:51.122: INFO: Pod "pod-aa639e1b-8b46-4932-924a-d2b8f9536736": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006449413s
STEP: Saw pod success
Aug 31 15:24:51.122: INFO: Pod "pod-aa639e1b-8b46-4932-924a-d2b8f9536736" satisfied condition "success or failure"
Aug 31 15:24:51.124: INFO: Trying to get logs from node vm119042 pod pod-aa639e1b-8b46-4932-924a-d2b8f9536736 container test-container: <nil>
STEP: delete the pod
Aug 31 15:24:51.139: INFO: Waiting for pod pod-aa639e1b-8b46-4932-924a-d2b8f9536736 to disappear
Aug 31 15:24:51.141: INFO: Pod pod-aa639e1b-8b46-4932-924a-d2b8f9536736 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:24:51.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8029" for this suite.
Aug 31 15:24:57.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:24:57.210: INFO: namespace emptydir-8029 deletion completed in 6.065191546s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:24:57.212: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug 31 15:24:57.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-7428'
Aug 31 15:24:57.386: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug 31 15:24:57.386: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Aug 31 15:24:57.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete jobs e2e-test-nginx-job --namespace=kubectl-7428'
Aug 31 15:24:57.446: INFO: stderr: ""
Aug 31 15:24:57.446: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:24:57.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7428" for this suite.
Aug 31 15:25:19.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:25:19.517: INFO: namespace kubectl-7428 deletion completed in 22.066547598s

• [SLOW TEST:22.306 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:25:19.518: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug 31 15:25:19.538: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug 31 15:25:19.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:19.654: INFO: stderr: ""
Aug 31 15:25:19.654: INFO: stdout: "service/redis-slave created\n"
Aug 31 15:25:19.654: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug 31 15:25:19.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:19.804: INFO: stderr: ""
Aug 31 15:25:19.804: INFO: stdout: "service/redis-master created\n"
Aug 31 15:25:19.805: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug 31 15:25:19.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:19.912: INFO: stderr: ""
Aug 31 15:25:19.912: INFO: stdout: "service/frontend created\n"
Aug 31 15:25:19.912: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug 31 15:25:19.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:20.032: INFO: stderr: ""
Aug 31 15:25:20.032: INFO: stdout: "deployment.apps/frontend created\n"
Aug 31 15:25:20.032: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug 31 15:25:20.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:20.161: INFO: stderr: ""
Aug 31 15:25:20.161: INFO: stdout: "deployment.apps/redis-master created\n"
Aug 31 15:25:20.161: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug 31 15:25:20.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-3426'
Aug 31 15:25:20.273: INFO: stderr: ""
Aug 31 15:25:20.273: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug 31 15:25:20.273: INFO: Waiting for all frontend pods to be Running.
Aug 31 15:25:25.325: INFO: Waiting for frontend to serve content.
Aug 31 15:25:25.336: INFO: Trying to add a new entry to the guestbook.
Aug 31 15:25:25.346: INFO: Verifying that added entry can be retrieved.
Aug 31 15:25:25.355: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 31 15:25:30.366: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 31 15:25:35.375: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 31 15:25:40.385: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Aug 31 15:25:45.397: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Aug 31 15:25:50.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.491: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.491: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug 31 15:25:50.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.565: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.565: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 31 15:25:50.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.629: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.629: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 31 15:25:50.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.681: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug 31 15:25:50.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.779: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.779: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug 31 15:25:50.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 delete --grace-period=0 --force -f - --namespace=kubectl-3426'
Aug 31 15:25:50.875: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug 31 15:25:50.875: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:25:50.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3426" for this suite.
Aug 31 15:26:28.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:26:28.973: INFO: namespace kubectl-3426 deletion completed in 38.088940608s

• [SLOW TEST:69.456 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:26:28.973: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-60cf1c7d-4324-4480-998b-f90e3781439d
STEP: Creating a pod to test consume secrets
Aug 31 15:26:29.005: INFO: Waiting up to 5m0s for pod "pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4" in namespace "secrets-6924" to be "success or failure"
Aug 31 15:26:29.009: INFO: Pod "pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108763ms
Aug 31 15:26:31.012: INFO: Pod "pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007566828s
STEP: Saw pod success
Aug 31 15:26:31.012: INFO: Pod "pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4" satisfied condition "success or failure"
Aug 31 15:26:31.015: INFO: Trying to get logs from node vm119042 pod pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:26:31.027: INFO: Waiting for pod pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4 to disappear
Aug 31 15:26:31.030: INFO: Pod pod-secrets-861bdc76-2832-44e1-a8b6-8b449d37aed4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:26:31.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6924" for this suite.
Aug 31 15:26:37.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:26:37.101: INFO: namespace secrets-6924 deletion completed in 6.068141675s

• [SLOW TEST:8.128 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:26:37.103: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-q77z
STEP: Creating a pod to test atomic-volume-subpath
Aug 31 15:26:37.134: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q77z" in namespace "subpath-130" to be "success or failure"
Aug 31 15:26:37.137: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415599ms
Aug 31 15:26:39.141: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 2.006254601s
Aug 31 15:26:41.144: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 4.010020621s
Aug 31 15:26:43.148: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 6.013368453s
Aug 31 15:26:45.151: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 8.016845235s
Aug 31 15:26:47.154: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 10.019987812s
Aug 31 15:26:49.158: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 12.023980032s
Aug 31 15:26:51.163: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 14.028273415s
Aug 31 15:26:53.166: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 16.031303053s
Aug 31 15:26:55.169: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 18.035034598s
Aug 31 15:26:57.173: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Running", Reason="", readiness=true. Elapsed: 20.038276784s
Aug 31 15:26:59.178: INFO: Pod "pod-subpath-test-configmap-q77z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043884916s
STEP: Saw pod success
Aug 31 15:26:59.178: INFO: Pod "pod-subpath-test-configmap-q77z" satisfied condition "success or failure"
Aug 31 15:26:59.181: INFO: Trying to get logs from node vm119042 pod pod-subpath-test-configmap-q77z container test-container-subpath-configmap-q77z: <nil>
STEP: delete the pod
Aug 31 15:26:59.193: INFO: Waiting for pod pod-subpath-test-configmap-q77z to disappear
Aug 31 15:26:59.196: INFO: Pod pod-subpath-test-configmap-q77z no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q77z
Aug 31 15:26:59.196: INFO: Deleting pod "pod-subpath-test-configmap-q77z" in namespace "subpath-130"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:26:59.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-130" for this suite.
Aug 31 15:27:05.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:27:05.263: INFO: namespace subpath-130 deletion completed in 6.06271813s

• [SLOW TEST:28.161 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:27:05.264: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 31 15:27:05.325: INFO: Number of nodes with available pods: 0
Aug 31 15:27:05.325: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:27:06.332: INFO: Number of nodes with available pods: 0
Aug 31 15:27:06.332: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:27:07.332: INFO: Number of nodes with available pods: 4
Aug 31 15:27:07.332: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug 31 15:27:07.349: INFO: Number of nodes with available pods: 3
Aug 31 15:27:07.349: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:08.356: INFO: Number of nodes with available pods: 3
Aug 31 15:27:08.356: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:09.357: INFO: Number of nodes with available pods: 3
Aug 31 15:27:09.357: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:10.356: INFO: Number of nodes with available pods: 3
Aug 31 15:27:10.356: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:11.356: INFO: Number of nodes with available pods: 3
Aug 31 15:27:11.356: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:12.356: INFO: Number of nodes with available pods: 3
Aug 31 15:27:12.356: INFO: Node vm119042 is running more than one daemon pod
Aug 31 15:27:13.356: INFO: Number of nodes with available pods: 4
Aug 31 15:27:13.356: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8095, will wait for the garbage collector to delete the pods
Aug 31 15:27:13.417: INFO: Deleting DaemonSet.extensions daemon-set took: 5.482923ms
Aug 31 15:27:13.517: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.840118ms
Aug 31 15:27:20.121: INFO: Number of nodes with available pods: 0
Aug 31 15:27:20.121: INFO: Number of running nodes: 0, number of available pods: 0
Aug 31 15:27:20.123: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8095/daemonsets","resourceVersion":"40507"},"items":null}

Aug 31 15:27:20.125: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8095/pods","resourceVersion":"40507"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:27:20.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8095" for this suite.
Aug 31 15:27:26.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:27:26.200: INFO: namespace daemonsets-8095 deletion completed in 6.062663216s

• [SLOW TEST:20.937 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:27:26.201: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 31 15:27:26.218: INFO: PodSpec: initContainers in spec.initContainers
Aug 31 15:28:11.226: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5e4a648b-a5be-4959-9e6c-be5b5cc4d3f9", GenerateName:"", Namespace:"init-container-1625", SelfLink:"/api/v1/namespaces/init-container-1625/pods/pod-init-5e4a648b-a5be-4959-9e6c-be5b5cc4d3f9", UID:"abd6f7cf-4dab-483e-9141-428b85cd275a", ResourceVersion:"40652", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63797556446, loc:(*time.Location)(0x7edea20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"218789995"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-dhx5t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00257e000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dhx5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dhx5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-dhx5t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00284c6e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"vm119042", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003f7e9c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00284c770)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00284c7a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00284c7a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00284c7ac), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556446, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556446, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556446, loc:(*time.Location)(0x7edea20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556446, loc:(*time.Location)(0x7edea20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.119.42", PodIP:"10.244.1.72", StartTime:(*v1.Time)(0xc0037a4720), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000c0b500)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000c0b570)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://7644b3dc80fd54eefe866442890d2c0ba0c406d86d1e4e6f9f9a8b6664eafb8e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037a4760), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037a4740), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:28:11.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1625" for this suite.
Aug 31 15:28:33.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:28:33.300: INFO: namespace init-container-1625 deletion completed in 22.067382599s

• [SLOW TEST:67.099 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:28:33.300: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-435
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-435 to expose endpoints map[]
Aug 31 15:28:33.336: INFO: successfully validated that service endpoint-test2 in namespace services-435 exposes endpoints map[] (3.870449ms elapsed)
STEP: Creating pod pod1 in namespace services-435
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-435 to expose endpoints map[pod1:[80]]
Aug 31 15:28:35.362: INFO: successfully validated that service endpoint-test2 in namespace services-435 exposes endpoints map[pod1:[80]] (2.017409816s elapsed)
STEP: Creating pod pod2 in namespace services-435
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-435 to expose endpoints map[pod1:[80] pod2:[80]]
Aug 31 15:28:37.392: INFO: successfully validated that service endpoint-test2 in namespace services-435 exposes endpoints map[pod1:[80] pod2:[80]] (2.025047401s elapsed)
STEP: Deleting pod pod1 in namespace services-435
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-435 to expose endpoints map[pod2:[80]]
Aug 31 15:28:38.412: INFO: successfully validated that service endpoint-test2 in namespace services-435 exposes endpoints map[pod2:[80]] (1.015639999s elapsed)
STEP: Deleting pod pod2 in namespace services-435
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-435 to expose endpoints map[]
Aug 31 15:28:39.422: INFO: successfully validated that service endpoint-test2 in namespace services-435 exposes endpoints map[] (1.005980581s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:28:39.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-435" for this suite.
Aug 31 15:29:01.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:29:01.507: INFO: namespace services-435 deletion completed in 22.069386919s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:28.207 seconds]
[sig-network] Services
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:29:01.508: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:29:01.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428" in namespace "projected-1988" to be "success or failure"
Aug 31 15:29:01.534: INFO: Pod "downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428": Phase="Pending", Reason="", readiness=false. Elapsed: 3.202761ms
Aug 31 15:29:03.538: INFO: Pod "downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006950453s
STEP: Saw pod success
Aug 31 15:29:03.538: INFO: Pod "downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428" satisfied condition "success or failure"
Aug 31 15:29:03.541: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428 container client-container: <nil>
STEP: delete the pod
Aug 31 15:29:03.554: INFO: Waiting for pod downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428 to disappear
Aug 31 15:29:03.556: INFO: Pod downwardapi-volume-d5ebb769-2bdc-4693-9212-1f8a9ca3e428 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:29:03.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1988" for this suite.
Aug 31 15:29:09.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:29:09.624: INFO: namespace projected-1988 deletion completed in 6.063759675s

• [SLOW TEST:8.116 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:29:09.624: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug 31 15:29:09.734: INFO: Number of nodes with available pods: 0
Aug 31 15:29:09.734: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:29:10.741: INFO: Number of nodes with available pods: 1
Aug 31 15:29:10.741: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:29:11.740: INFO: Number of nodes with available pods: 4
Aug 31 15:29:11.740: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug 31 15:29:11.759: INFO: Number of nodes with available pods: 3
Aug 31 15:29:11.759: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:29:12.767: INFO: Number of nodes with available pods: 3
Aug 31 15:29:12.767: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:29:13.767: INFO: Number of nodes with available pods: 3
Aug 31 15:29:13.767: INFO: Node vm119041 is running more than one daemon pod
Aug 31 15:29:14.765: INFO: Number of nodes with available pods: 4
Aug 31 15:29:14.765: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9960, will wait for the garbage collector to delete the pods
Aug 31 15:29:14.828: INFO: Deleting DaemonSet.extensions daemon-set took: 4.728166ms
Aug 31 15:29:14.929: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.74697ms
Aug 31 15:29:20.032: INFO: Number of nodes with available pods: 0
Aug 31 15:29:20.032: INFO: Number of running nodes: 0, number of available pods: 0
Aug 31 15:29:20.035: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9960/daemonsets","resourceVersion":"40941"},"items":null}

Aug 31 15:29:20.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9960/pods","resourceVersion":"40941"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:29:20.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9960" for this suite.
Aug 31 15:29:26.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:29:26.121: INFO: namespace daemonsets-9960 deletion completed in 6.065204739s

• [SLOW TEST:16.497 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:29:26.123: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug 31 15:29:26.145: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug 31 15:29:26.396: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug 31 15:29:28.443: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:30.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:32.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:34.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:36.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:38.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:40.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:42.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:44.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:46.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:48.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:50.448: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:52.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:54.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:56.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:29:58.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:30:00.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:30:02.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:30:04.446: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:30:06.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63797556566, loc:(*time.Location)(0x7edea20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug 31 15:30:08.972: INFO: Waited 520.034765ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:09.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4003" for this suite.
Aug 31 15:30:15.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:30:15.972: INFO: namespace aggregator-4003 deletion completed in 6.16238017s

• [SLOW TEST:49.849 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:30:15.972: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug 31 15:30:16.003: INFO: Waiting up to 5m0s for pod "pod-95759c8f-989a-4683-afca-f90ec1d428a4" in namespace "emptydir-3584" to be "success or failure"
Aug 31 15:30:16.008: INFO: Pod "pod-95759c8f-989a-4683-afca-f90ec1d428a4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.988689ms
Aug 31 15:30:18.012: INFO: Pod "pod-95759c8f-989a-4683-afca-f90ec1d428a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00874563s
STEP: Saw pod success
Aug 31 15:30:18.012: INFO: Pod "pod-95759c8f-989a-4683-afca-f90ec1d428a4" satisfied condition "success or failure"
Aug 31 15:30:18.016: INFO: Trying to get logs from node vm119042 pod pod-95759c8f-989a-4683-afca-f90ec1d428a4 container test-container: <nil>
STEP: delete the pod
Aug 31 15:30:18.030: INFO: Waiting for pod pod-95759c8f-989a-4683-afca-f90ec1d428a4 to disappear
Aug 31 15:30:18.033: INFO: Pod pod-95759c8f-989a-4683-afca-f90ec1d428a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:18.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3584" for this suite.
Aug 31 15:30:24.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:30:24.111: INFO: namespace emptydir-3584 deletion completed in 6.069561339s

• [SLOW TEST:8.139 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:30:24.112: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug 31 15:30:24.139: INFO: Waiting up to 5m0s for pod "pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece" in namespace "emptydir-6269" to be "success or failure"
Aug 31 15:30:24.145: INFO: Pod "pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece": Phase="Pending", Reason="", readiness=false. Elapsed: 5.955312ms
Aug 31 15:30:26.149: INFO: Pod "pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009604946s
STEP: Saw pod success
Aug 31 15:30:26.149: INFO: Pod "pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece" satisfied condition "success or failure"
Aug 31 15:30:26.151: INFO: Trying to get logs from node vm119042 pod pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece container test-container: <nil>
STEP: delete the pod
Aug 31 15:30:26.165: INFO: Waiting for pod pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece to disappear
Aug 31 15:30:26.167: INFO: Pod pod-a1ce08ee-25b8-4dd6-85b5-94a50670dece no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:26.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6269" for this suite.
Aug 31 15:30:32.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:30:32.244: INFO: namespace emptydir-6269 deletion completed in 6.072594117s

• [SLOW TEST:8.132 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:30:32.244: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-1bfd8621-90db-44fd-8430-1dc9bab42862
STEP: Creating a pod to test consume secrets
Aug 31 15:30:32.323: INFO: Waiting up to 5m0s for pod "pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3" in namespace "secrets-5605" to be "success or failure"
Aug 31 15:30:32.327: INFO: Pod "pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.595016ms
Aug 31 15:30:34.330: INFO: Pod "pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006878477s
STEP: Saw pod success
Aug 31 15:30:34.330: INFO: Pod "pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3" satisfied condition "success or failure"
Aug 31 15:30:34.334: INFO: Trying to get logs from node vm119042 pod pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:30:34.347: INFO: Waiting for pod pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3 to disappear
Aug 31 15:30:34.349: INFO: Pod pod-secrets-d0b969c0-8871-4218-a11d-103c32c813d3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:34.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5605" for this suite.
Aug 31 15:30:40.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:30:40.431: INFO: namespace secrets-5605 deletion completed in 6.077514303s

• [SLOW TEST:8.187 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:30:40.432: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug 31 15:30:40.467: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41260,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug 31 15:30:40.467: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41261,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug 31 15:30:40.467: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41262,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug 31 15:30:50.489: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41279,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug 31 15:30:50.489: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41280,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug 31 15:30:50.489: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-2436,SelfLink:/api/v1/namespaces/watch-2436/configmaps/e2e-watch-test-label-changed,UID:677d1500-e227-4764-8555-97301e1fd445,ResourceVersion:41281,Generation:0,CreationTimestamp:2022-08-31 15:30:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:50.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2436" for this suite.
Aug 31 15:30:56.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:30:56.558: INFO: namespace watch-2436 deletion completed in 6.066444682s

• [SLOW TEST:16.126 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:30:56.559: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-58f9d7b2-63c0-434e-8696-0e31d39f6a49
STEP: Creating a pod to test consume secrets
Aug 31 15:30:56.591: INFO: Waiting up to 5m0s for pod "pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2" in namespace "secrets-8507" to be "success or failure"
Aug 31 15:30:56.596: INFO: Pod "pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.129625ms
Aug 31 15:30:58.600: INFO: Pod "pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008609515s
STEP: Saw pod success
Aug 31 15:30:58.600: INFO: Pod "pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2" satisfied condition "success or failure"
Aug 31 15:30:58.602: INFO: Trying to get logs from node vm119042 pod pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2 container secret-volume-test: <nil>
STEP: delete the pod
Aug 31 15:30:58.616: INFO: Waiting for pod pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2 to disappear
Aug 31 15:30:58.619: INFO: Pod pod-secrets-fe446623-fc90-43d9-9f11-9e79e97dfed2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:30:58.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8507" for this suite.
Aug 31 15:31:04.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:31:04.685: INFO: namespace secrets-8507 deletion completed in 6.06239682s

• [SLOW TEST:8.126 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:31:04.687: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug 31 15:31:04.711: INFO: Waiting up to 5m0s for pod "var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0" in namespace "var-expansion-7523" to be "success or failure"
Aug 31 15:31:04.717: INFO: Pod "var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.878263ms
Aug 31 15:31:06.720: INFO: Pod "var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008665667s
STEP: Saw pod success
Aug 31 15:31:06.720: INFO: Pod "var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0" satisfied condition "success or failure"
Aug 31 15:31:06.723: INFO: Trying to get logs from node vm119042 pod var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0 container dapi-container: <nil>
STEP: delete the pod
Aug 31 15:31:06.736: INFO: Waiting for pod var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0 to disappear
Aug 31 15:31:06.738: INFO: Pod var-expansion-3174029a-d6af-4514-97f7-dcbb5084eca0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:31:06.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7523" for this suite.
Aug 31 15:31:12.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:31:12.807: INFO: namespace var-expansion-7523 deletion completed in 6.065382439s

• [SLOW TEST:8.120 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:31:12.807: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:31:12.825: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug 31 15:31:12.832: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug 31 15:31:17.835: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug 31 15:31:17.835: INFO: Creating deployment "test-rolling-update-deployment"
Aug 31 15:31:17.839: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug 31 15:31:17.843: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug 31 15:31:19.849: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug 31 15:31:19.851: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 31 15:31:19.858: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-5258,SelfLink:/apis/apps/v1/namespaces/deployment-5258/deployments/test-rolling-update-deployment,UID:f4844495-348a-4ff1-a596-5ad1cebd0504,ResourceVersion:41425,Generation:1,CreationTimestamp:2022-08-31 15:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2022-08-31 15:31:17 +0000 UTC 2022-08-31 15:31:17 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-08-31 15:31:18 +0000 UTC 2022-08-31 15:31:17 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug 31 15:31:19.861: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-5258,SelfLink:/apis/apps/v1/namespaces/deployment-5258/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:aed67cf6-a22c-4b0b-aa59-51af6e252094,ResourceVersion:41414,Generation:1,CreationTimestamp:2022-08-31 15:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f4844495-348a-4ff1-a596-5ad1cebd0504 0xc002e5be67 0xc002e5be68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug 31 15:31:19.861: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug 31 15:31:19.861: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-5258,SelfLink:/apis/apps/v1/namespaces/deployment-5258/replicasets/test-rolling-update-controller,UID:db760fa8-3ec2-4d7c-9ad0-a9ac50efc1b5,ResourceVersion:41424,Generation:2,CreationTimestamp:2022-08-31 15:31:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f4844495-348a-4ff1-a596-5ad1cebd0504 0xc002e5bd97 0xc002e5bd98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 15:31:19.864: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-7c5qd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-7c5qd,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-5258,SelfLink:/api/v1/namespaces/deployment-5258/pods/test-rolling-update-deployment-79f6b9d75c-7c5qd,UID:8a759fee-815e-4246-a624-b0e523b7e086,ResourceVersion:41413,Generation:0,CreationTimestamp:2022-08-31 15:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c aed67cf6-a22c-4b0b-aa59-51af6e252094 0xc0033572d7 0xc0033572d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xjrch {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xjrch,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xjrch true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003357350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003357370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:31:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:31:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:31:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:31:17 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:10.244.0.77,StartTime:2022-08-31 15:31:17 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2022-08-31 15:31:18 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://e6e11f7008010fe3bb52473303a62572f828ac1d7cfe370c702901adde2ea82b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:31:19.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5258" for this suite.
Aug 31 15:31:25.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:31:25.937: INFO: namespace deployment-5258 deletion completed in 6.070896378s

• [SLOW TEST:13.130 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:31:25.937: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0831 15:31:26.517234      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug 31 15:31:26.517: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:31:26.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6229" for this suite.
Aug 31 15:31:32.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:31:32.590: INFO: namespace gc-6229 deletion completed in 6.068294708s

• [SLOW TEST:6.653 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:31:32.591: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:31:32.612: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:31:34.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8138" for this suite.
Aug 31 15:32:18.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:32:18.761: INFO: namespace pods-8138 deletion completed in 44.067199147s

• [SLOW TEST:46.171 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:32:18.762: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-48d0c943-1b6c-40a9-b20c-a8104f92c0f0
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:32:20.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4463" for this suite.
Aug 31 15:32:42.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:32:42.885: INFO: namespace configmap-4463 deletion completed in 22.063868289s

• [SLOW TEST:24.124 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:32:42.886: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-0d9dae28-dd04-4d03-abc3-19dd03ec815f
STEP: Creating a pod to test consume configMaps
Aug 31 15:32:42.916: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13" in namespace "projected-3432" to be "success or failure"
Aug 31 15:32:42.921: INFO: Pod "pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.244241ms
Aug 31 15:32:44.924: INFO: Pod "pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008324862s
STEP: Saw pod success
Aug 31 15:32:44.924: INFO: Pod "pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13" satisfied condition "success or failure"
Aug 31 15:32:44.927: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:32:44.939: INFO: Waiting for pod pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13 to disappear
Aug 31 15:32:44.942: INFO: Pod pod-projected-configmaps-bcfa1c89-b623-462c-8df3-2f0bbbf9ab13 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:32:44.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3432" for this suite.
Aug 31 15:32:50.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:32:51.018: INFO: namespace projected-3432 deletion completed in 6.072041365s

• [SLOW TEST:8.132 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:32:51.019: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-625
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug 31 15:32:51.040: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug 31 15:33:13.130: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.160 8081 | grep -v '^\s*$'] Namespace:pod-network-test-625 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:33:13.130: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:33:14.208: INFO: Found all expected endpoints: [netserver-0]
Aug 31 15:33:14.212: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.85 8081 | grep -v '^\s*$'] Namespace:pod-network-test-625 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:33:14.212: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:33:15.296: INFO: Found all expected endpoints: [netserver-1]
Aug 31 15:33:15.299: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.84 8081 | grep -v '^\s*$'] Namespace:pod-network-test-625 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:33:15.299: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:33:16.381: INFO: Found all expected endpoints: [netserver-2]
Aug 31 15:33:16.384: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-625 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:33:16.384: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:33:17.457: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:33:17.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-625" for this suite.
Aug 31 15:33:39.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:33:39.520: INFO: namespace pod-network-test-625 deletion completed in 22.058921049s

• [SLOW TEST:48.501 seconds]
[sig-network] Networking
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:33:39.522: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug 31 15:33:39.557: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-059459328 proxy --unix-socket=/tmp/kubectl-proxy-unix183113219/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:33:39.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7173" for this suite.
Aug 31 15:33:45.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:33:45.669: INFO: namespace kubectl-7173 deletion completed in 6.061807181s

• [SLOW TEST:6.147 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:33:45.669: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug 31 15:33:45.693: INFO: Waiting up to 5m0s for pod "downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c" in namespace "downward-api-3906" to be "success or failure"
Aug 31 15:33:45.695: INFO: Pod "downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.912301ms
Aug 31 15:33:47.698: INFO: Pod "downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005451594s
STEP: Saw pod success
Aug 31 15:33:47.698: INFO: Pod "downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c" satisfied condition "success or failure"
Aug 31 15:33:47.701: INFO: Trying to get logs from node vm119042 pod downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c container dapi-container: <nil>
STEP: delete the pod
Aug 31 15:33:47.716: INFO: Waiting for pod downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c to disappear
Aug 31 15:33:47.718: INFO: Pod downward-api-b5daec7b-9434-46df-b5ad-1ad22add626c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:33:47.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3906" for this suite.
Aug 31 15:33:53.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:33:53.792: INFO: namespace downward-api-3906 deletion completed in 6.070410301s

• [SLOW TEST:8.123 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:33:53.792: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:33:53.813: INFO: Creating ReplicaSet my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38
Aug 31 15:33:53.820: INFO: Pod name my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38: Found 0 pods out of 1
Aug 31 15:33:58.824: INFO: Pod name my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38: Found 1 pods out of 1
Aug 31 15:33:58.824: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38" is running
Aug 31 15:33:58.826: INFO: Pod "my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38-nskww" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 15:33:53 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 15:33:55 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 15:33:55 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-08-31 15:33:53 +0000 UTC Reason: Message:}])
Aug 31 15:33:58.826: INFO: Trying to dial the pod
Aug 31 15:34:03.835: INFO: Controller my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38: Got expected result from replica 1 [my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38-nskww]: "my-hostname-basic-d3b8b847-aba7-4886-8311-fcdb6445bc38-nskww", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:34:03.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9119" for this suite.
Aug 31 15:34:09.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:34:09.908: INFO: namespace replicaset-9119 deletion completed in 6.06856885s

• [SLOW TEST:16.116 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:34:09.912: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:34:09.941: INFO: Waiting up to 5m0s for pod "downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57" in namespace "projected-515" to be "success or failure"
Aug 31 15:34:09.952: INFO: Pod "downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57": Phase="Pending", Reason="", readiness=false. Elapsed: 10.660125ms
Aug 31 15:34:11.956: INFO: Pod "downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014546815s
Aug 31 15:34:13.959: INFO: Pod "downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017971292s
STEP: Saw pod success
Aug 31 15:34:13.959: INFO: Pod "downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57" satisfied condition "success or failure"
Aug 31 15:34:13.963: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57 container client-container: <nil>
STEP: delete the pod
Aug 31 15:34:13.977: INFO: Waiting for pod downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57 to disappear
Aug 31 15:34:13.979: INFO: Pod downwardapi-volume-429b1cf4-14c3-4dc0-9131-2a1c97ca8c57 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:34:13.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-515" for this suite.
Aug 31 15:34:19.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:34:20.051: INFO: namespace projected-515 deletion completed in 6.068550472s

• [SLOW TEST:10.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:34:20.052: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5141cb2d-c925-4806-b755-9936ef220fbb
STEP: Creating a pod to test consume configMaps
Aug 31 15:34:20.080: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07" in namespace "projected-6335" to be "success or failure"
Aug 31 15:34:20.085: INFO: Pod "pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07": Phase="Pending", Reason="", readiness=false. Elapsed: 5.179387ms
Aug 31 15:34:22.089: INFO: Pod "pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008527565s
STEP: Saw pod success
Aug 31 15:34:22.089: INFO: Pod "pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07" satisfied condition "success or failure"
Aug 31 15:34:22.092: INFO: Trying to get logs from node vm119042 pod pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:34:22.107: INFO: Waiting for pod pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07 to disappear
Aug 31 15:34:22.109: INFO: Pod pod-projected-configmaps-71c25050-66af-4b01-9855-1d32e97fab07 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:34:22.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6335" for this suite.
Aug 31 15:34:28.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:34:28.177: INFO: namespace projected-6335 deletion completed in 6.063346796s

• [SLOW TEST:8.125 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:34:28.177: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug 31 15:34:28.203: INFO: Waiting up to 5m0s for pod "var-expansion-fdc48450-febc-4618-adaf-32811e751fbf" in namespace "var-expansion-5095" to be "success or failure"
Aug 31 15:34:28.209: INFO: Pod "var-expansion-fdc48450-febc-4618-adaf-32811e751fbf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.406225ms
Aug 31 15:34:30.213: INFO: Pod "var-expansion-fdc48450-febc-4618-adaf-32811e751fbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009803339s
STEP: Saw pod success
Aug 31 15:34:30.213: INFO: Pod "var-expansion-fdc48450-febc-4618-adaf-32811e751fbf" satisfied condition "success or failure"
Aug 31 15:34:30.215: INFO: Trying to get logs from node vm119042 pod var-expansion-fdc48450-febc-4618-adaf-32811e751fbf container dapi-container: <nil>
STEP: delete the pod
Aug 31 15:34:30.229: INFO: Waiting for pod var-expansion-fdc48450-febc-4618-adaf-32811e751fbf to disappear
Aug 31 15:34:30.231: INFO: Pod var-expansion-fdc48450-febc-4618-adaf-32811e751fbf no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:34:30.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5095" for this suite.
Aug 31 15:34:36.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:34:36.303: INFO: namespace var-expansion-5095 deletion completed in 6.067782399s

• [SLOW TEST:8.126 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:34:36.304: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug 31 15:34:36.588: INFO: Pod name wrapped-volume-race-b81bcdc5-29fc-4f86-934e-1a5a5daa0bd3: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b81bcdc5-29fc-4f86-934e-1a5a5daa0bd3 in namespace emptydir-wrapper-8840, will wait for the garbage collector to delete the pods
Aug 31 15:34:40.689: INFO: Deleting ReplicationController wrapped-volume-race-b81bcdc5-29fc-4f86-934e-1a5a5daa0bd3 took: 12.342197ms
Aug 31 15:34:40.889: INFO: Terminating ReplicationController wrapped-volume-race-b81bcdc5-29fc-4f86-934e-1a5a5daa0bd3 pods took: 200.25966ms
STEP: Creating RC which spawns configmap-volume pods
Aug 31 15:35:20.103: INFO: Pod name wrapped-volume-race-cf0d0039-7df5-483f-8c4c-6eefaa0cc4ef: Found 0 pods out of 5
Aug 31 15:35:25.109: INFO: Pod name wrapped-volume-race-cf0d0039-7df5-483f-8c4c-6eefaa0cc4ef: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cf0d0039-7df5-483f-8c4c-6eefaa0cc4ef in namespace emptydir-wrapper-8840, will wait for the garbage collector to delete the pods
Aug 31 15:35:25.181: INFO: Deleting ReplicationController wrapped-volume-race-cf0d0039-7df5-483f-8c4c-6eefaa0cc4ef took: 6.433738ms
Aug 31 15:35:25.281: INFO: Terminating ReplicationController wrapped-volume-race-cf0d0039-7df5-483f-8c4c-6eefaa0cc4ef pods took: 100.342045ms
STEP: Creating RC which spawns configmap-volume pods
Aug 31 15:36:10.198: INFO: Pod name wrapped-volume-race-ef3a43b0-c7ce-45bb-b1f9-62f22ae6c28f: Found 0 pods out of 5
Aug 31 15:36:15.203: INFO: Pod name wrapped-volume-race-ef3a43b0-c7ce-45bb-b1f9-62f22ae6c28f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ef3a43b0-c7ce-45bb-b1f9-62f22ae6c28f in namespace emptydir-wrapper-8840, will wait for the garbage collector to delete the pods
Aug 31 15:36:15.275: INFO: Deleting ReplicationController wrapped-volume-race-ef3a43b0-c7ce-45bb-b1f9-62f22ae6c28f took: 6.854928ms
Aug 31 15:36:15.375: INFO: Terminating ReplicationController wrapped-volume-race-ef3a43b0-c7ce-45bb-b1f9-62f22ae6c28f pods took: 100.489938ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:37:00.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8840" for this suite.
Aug 31 15:37:06.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:37:06.304: INFO: namespace emptydir-wrapper-8840 deletion completed in 6.075975696s

• [SLOW TEST:150.001 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:37:06.305: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3278.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3278.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3278.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3278.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.3.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.3.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.3.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.3.241_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3278.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3278.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3278.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3278.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3278.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3278.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 241.3.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.3.241_udp@PTR;check="$$(dig +tcp +noall +answer +search 241.3.102.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.102.3.241_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 15:37:10.390: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.394: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.397: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.400: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.408: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.411: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.418: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.421: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.424: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.427: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.435: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.438: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:10.443: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:15.447: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.451: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.454: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.456: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.464: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.467: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.474: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.477: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.484: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.488: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.496: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.499: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:15.505: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:20.448: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.451: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.455: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.458: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.466: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.469: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.476: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.479: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.482: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.485: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.492: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.496: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:20.501: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:25.448: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.452: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.455: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.458: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.466: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.468: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.476: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.479: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.482: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.485: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.493: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.496: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:25.501: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:30.448: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.451: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.454: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.457: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.466: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.472: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.486: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.490: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.493: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.496: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.504: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.507: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:30.512: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:35.448: INFO: Unable to read wheezy_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.452: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.455: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.458: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.466: INFO: Unable to read wheezy_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.468: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.476: INFO: Unable to read jessie_udp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.479: INFO: Unable to read jessie_tcp@dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.482: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.485: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.492: INFO: Unable to read jessie_udp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.495: INFO: Unable to read jessie_tcp@PodARecord from pod dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656: the server could not find the requested resource (get pods dns-test-8e579894-49a5-4054-ae89-71696a30e656)
Aug 31 15:37:35.502: INFO: Lookups using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 failed for: [wheezy_udp@dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@dns-test-service.dns-3278.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@dns-test-service.dns-3278.svc.cluster.local jessie_tcp@dns-test-service.dns-3278.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3278.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:37:40.491: INFO: DNS probes using dns-3278/dns-test-8e579894-49a5-4054-ae89-71696a30e656 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:37:40.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3278" for this suite.
Aug 31 15:37:46.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:37:46.661: INFO: namespace dns-3278 deletion completed in 6.079752445s

• [SLOW TEST:40.356 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:37:46.662: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-2799/configmap-test-1fa9740e-88df-4e99-a3b3-7f00ae401c36
STEP: Creating a pod to test consume configMaps
Aug 31 15:37:46.746: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6" in namespace "configmap-2799" to be "success or failure"
Aug 31 15:37:46.751: INFO: Pod "pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.215435ms
Aug 31 15:37:48.754: INFO: Pod "pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008402456s
STEP: Saw pod success
Aug 31 15:37:48.755: INFO: Pod "pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6" satisfied condition "success or failure"
Aug 31 15:37:48.757: INFO: Trying to get logs from node vm119042 pod pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6 container env-test: <nil>
STEP: delete the pod
Aug 31 15:37:48.773: INFO: Waiting for pod pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6 to disappear
Aug 31 15:37:48.775: INFO: Pod pod-configmaps-8f461ad0-c0a8-4dec-90e3-5b3bdcafb0b6 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:37:48.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2799" for this suite.
Aug 31 15:37:54.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:37:54.850: INFO: namespace configmap-2799 deletion completed in 6.072528371s

• [SLOW TEST:8.188 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:37:54.852: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug 31 15:37:56.888: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:37:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7088" for this suite.
Aug 31 15:38:02.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:38:02.972: INFO: namespace container-runtime-7088 deletion completed in 6.072893848s

• [SLOW TEST:8.121 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:38:02.972: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-f960ba5b-557f-44fa-9a71-1bd45a6577f9
STEP: Creating a pod to test consume configMaps
Aug 31 15:38:03.018: INFO: Waiting up to 5m0s for pod "pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081" in namespace "configmap-2805" to be "success or failure"
Aug 31 15:38:03.027: INFO: Pod "pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081": Phase="Pending", Reason="", readiness=false. Elapsed: 8.336528ms
Aug 31 15:38:05.030: INFO: Pod "pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012006186s
STEP: Saw pod success
Aug 31 15:38:05.031: INFO: Pod "pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081" satisfied condition "success or failure"
Aug 31 15:38:05.033: INFO: Trying to get logs from node vm119042 pod pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081 container configmap-volume-test: <nil>
STEP: delete the pod
Aug 31 15:38:05.046: INFO: Waiting for pod pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081 to disappear
Aug 31 15:38:05.048: INFO: Pod pod-configmaps-c59a065e-cb95-4a42-af68-ba70f835b081 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:38:05.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2805" for this suite.
Aug 31 15:38:11.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:38:11.119: INFO: namespace configmap-2805 deletion completed in 6.066759867s

• [SLOW TEST:8.147 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:38:11.120: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:38:11.147: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea" in namespace "projected-1687" to be "success or failure"
Aug 31 15:38:11.149: INFO: Pod "downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612836ms
Aug 31 15:38:13.153: INFO: Pod "downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006229784s
STEP: Saw pod success
Aug 31 15:38:13.153: INFO: Pod "downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea" satisfied condition "success or failure"
Aug 31 15:38:13.156: INFO: Trying to get logs from node vm119043 pod downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea container client-container: <nil>
STEP: delete the pod
Aug 31 15:38:13.172: INFO: Waiting for pod downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea to disappear
Aug 31 15:38:13.175: INFO: Pod downwardapi-volume-3d281846-f551-4898-8058-2b09a09480ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:38:13.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1687" for this suite.
Aug 31 15:38:19.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:38:19.240: INFO: namespace projected-1687 deletion completed in 6.061661433s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:38:19.240: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-3f59fb65-37d5-4efc-abda-f463511f1d7d in namespace container-probe-5312
Aug 31 15:38:21.272: INFO: Started pod busybox-3f59fb65-37d5-4efc-abda-f463511f1d7d in namespace container-probe-5312
STEP: checking the pod's current state and verifying that restartCount is present
Aug 31 15:38:21.275: INFO: Initial restart count of pod busybox-3f59fb65-37d5-4efc-abda-f463511f1d7d is 0
Aug 31 15:39:11.368: INFO: Restart count of pod container-probe-5312/busybox-3f59fb65-37d5-4efc-abda-f463511f1d7d is now 1 (50.092593344s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:39:11.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5312" for this suite.
Aug 31 15:39:17.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:39:17.462: INFO: namespace container-probe-5312 deletion completed in 6.0813493s

• [SLOW TEST:58.222 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:39:17.463: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug 31 15:39:21.512: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.512: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.585: INFO: Exec stderr: ""
Aug 31 15:39:21.585: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.585: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.659: INFO: Exec stderr: ""
Aug 31 15:39:21.659: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.659: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.725: INFO: Exec stderr: ""
Aug 31 15:39:21.725: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.725: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.801: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug 31 15:39:21.801: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.801: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.874: INFO: Exec stderr: ""
Aug 31 15:39:21.874: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.874: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:21.948: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug 31 15:39:21.948: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:21.948: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:22.043: INFO: Exec stderr: ""
Aug 31 15:39:22.043: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:22.043: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:22.119: INFO: Exec stderr: ""
Aug 31 15:39:22.119: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:22.119: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:22.190: INFO: Exec stderr: ""
Aug 31 15:39:22.190: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1959 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug 31 15:39:22.190: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
Aug 31 15:39:22.263: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:39:22.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1959" for this suite.
Aug 31 15:40:08.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:40:08.340: INFO: namespace e2e-kubelet-etc-hosts-1959 deletion completed in 46.072842853s

• [SLOW TEST:50.877 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:40:08.341: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5868
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug 31 15:40:08.426: INFO: Found 0 stateful pods, waiting for 3
Aug 31 15:40:18.430: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 15:40:18.430: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 15:40:18.430: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug 31 15:40:18.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-5868 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:40:18.627: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:40:18.627: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:40:18.627: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug 31 15:40:28.655: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug 31 15:40:38.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-5868 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:40:38.804: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:40:38.804: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:40:38.804: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug 31 15:40:48.819: INFO: Waiting for StatefulSet statefulset-5868/ss2 to complete update
Aug 31 15:40:48.819: INFO: Waiting for Pod statefulset-5868/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 31 15:40:48.819: INFO: Waiting for Pod statefulset-5868/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 31 15:40:48.819: INFO: Waiting for Pod statefulset-5868/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 31 15:40:58.825: INFO: Waiting for StatefulSet statefulset-5868/ss2 to complete update
Aug 31 15:40:58.825: INFO: Waiting for Pod statefulset-5868/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug 31 15:40:58.825: INFO: Waiting for Pod statefulset-5868/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Aug 31 15:41:08.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-5868 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug 31 15:41:08.958: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug 31 15:41:08.958: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug 31 15:41:08.958: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug 31 15:41:18.986: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug 31 15:41:29.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 exec --namespace=statefulset-5868 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug 31 15:41:29.116: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug 31 15:41:29.116: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug 31 15:41:29.116: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug 31 15:41:39.131: INFO: Deleting all statefulset in ns statefulset-5868
Aug 31 15:41:39.133: INFO: Scaling statefulset ss2 to 0
Aug 31 15:42:09.146: INFO: Waiting for statefulset status.replicas updated to 0
Aug 31 15:42:09.148: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:42:09.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5868" for this suite.
Aug 31 15:42:15.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:42:15.227: INFO: namespace statefulset-5868 deletion completed in 6.064269815s

• [SLOW TEST:126.886 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:42:15.227: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug 31 15:42:15.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 create -f - --namespace=kubectl-1428'
Aug 31 15:42:15.446: INFO: stderr: ""
Aug 31 15:42:15.446: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug 31 15:42:16.450: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:42:16.450: INFO: Found 1 / 1
Aug 31 15:42:16.450: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug 31 15:42:16.452: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:42:16.452: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug 31 15:42:16.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 patch pod redis-master-67cfv --namespace=kubectl-1428 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug 31 15:42:16.514: INFO: stderr: ""
Aug 31 15:42:16.514: INFO: stdout: "pod/redis-master-67cfv patched\n"
STEP: checking annotations
Aug 31 15:42:16.519: INFO: Selector matched 1 pods for map[app:redis]
Aug 31 15:42:16.519: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:42:16.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1428" for this suite.
Aug 31 15:42:38.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:42:38.596: INFO: namespace kubectl-1428 deletion completed in 22.073127186s

• [SLOW TEST:23.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:42:38.596: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug 31 15:42:38.618: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug 31 15:42:38.624: INFO: Waiting for terminating namespaces to be deleted...
Aug 31 15:42:38.627: INFO: 
Logging pods the kubelet thinks is on node vm119041 before test
Aug 31 15:42:38.632: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-kkc9r from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 15:42:38.632: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 31 15:42:38.632: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 15:42:38.632: INFO: kube-flannel-ds-r6tpw from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.632: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 15:42:38.632: INFO: metrics-server-54cdcdcd69-x5nfx from kube-system started at 2022-08-31 12:10:22 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.632: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 15:42:38.632: INFO: 
Logging pods the kubelet thinks is on node vm119042 before test
Aug 31 15:42:38.638: INFO: kube-flannel-ds-8hj77 from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.638: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 15:42:38.638: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-q6p6z from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 15:42:38.638: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 31 15:42:38.638: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 15:42:38.638: INFO: sonobuoy from sonobuoy started at 2022-08-31 14:20:22 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.638: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug 31 15:42:38.638: INFO: 
Logging pods the kubelet thinks is on node vm119043 before test
Aug 31 15:42:38.643: INFO: coredns-545b9dffff-sq27r from kube-system started at 2022-08-31 12:10:06 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.643: INFO: 	Container coredns ready: true, restart count 0
Aug 31 15:42:38.643: INFO: kube-flannel-ds-d9h4h from kube-system started at 2022-08-31 12:09:07 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.644: INFO: 	Container kube-flannel ready: true, restart count 0
Aug 31 15:42:38.644: INFO: metrics-server-54cdcdcd69-gb9zj from kube-system started at 2022-08-31 12:10:09 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.644: INFO: 	Container metrics-server ready: true, restart count 0
Aug 31 15:42:38.644: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-dtglv from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 15:42:38.644: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 31 15:42:38.644: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 15:42:38.644: INFO: 
Logging pods the kubelet thinks is on node vm119044 before test
Aug 31 15:42:38.650: INFO: sonobuoy-e2e-job-1bebe861b7bb41b0 from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 15:42:38.650: INFO: 	Container e2e ready: true, restart count 0
Aug 31 15:42:38.650: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug 31 15:42:38.650: INFO: sonobuoy-systemd-logs-daemon-set-673f990a21f74630-sdc9n from sonobuoy started at 2022-08-31 14:20:23 +0000 UTC (2 container statuses recorded)
Aug 31 15:42:38.650: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug 31 15:42:38.650: INFO: 	Container systemd-logs ready: true, restart count 0
Aug 31 15:42:38.650: INFO: kube-flannel-ds-pgpzl from kube-system started at 2022-08-31 12:43:40 +0000 UTC (1 container statuses recorded)
Aug 31 15:42:38.650: INFO: 	Container kube-flannel ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node vm119041
STEP: verifying the node has the label node vm119042
STEP: verifying the node has the label node vm119043
STEP: verifying the node has the label node vm119044
Aug 31 15:42:38.703: INFO: Pod coredns-545b9dffff-sq27r requesting resource cpu=100m on Node vm119043
Aug 31 15:42:38.703: INFO: Pod kube-flannel-ds-8hj77 requesting resource cpu=100m on Node vm119042
Aug 31 15:42:38.703: INFO: Pod kube-flannel-ds-d9h4h requesting resource cpu=100m on Node vm119043
Aug 31 15:42:38.704: INFO: Pod kube-flannel-ds-pgpzl requesting resource cpu=100m on Node vm119044
Aug 31 15:42:38.704: INFO: Pod kube-flannel-ds-r6tpw requesting resource cpu=100m on Node vm119041
Aug 31 15:42:38.704: INFO: Pod metrics-server-54cdcdcd69-gb9zj requesting resource cpu=100m on Node vm119043
Aug 31 15:42:38.704: INFO: Pod metrics-server-54cdcdcd69-x5nfx requesting resource cpu=100m on Node vm119041
Aug 31 15:42:38.704: INFO: Pod sonobuoy requesting resource cpu=0m on Node vm119042
Aug 31 15:42:38.704: INFO: Pod sonobuoy-e2e-job-1bebe861b7bb41b0 requesting resource cpu=0m on Node vm119044
Aug 31 15:42:38.704: INFO: Pod sonobuoy-systemd-logs-daemon-set-673f990a21f74630-dtglv requesting resource cpu=0m on Node vm119043
Aug 31 15:42:38.704: INFO: Pod sonobuoy-systemd-logs-daemon-set-673f990a21f74630-kkc9r requesting resource cpu=0m on Node vm119041
Aug 31 15:42:38.704: INFO: Pod sonobuoy-systemd-logs-daemon-set-673f990a21f74630-q6p6z requesting resource cpu=0m on Node vm119042
Aug 31 15:42:38.704: INFO: Pod sonobuoy-systemd-logs-daemon-set-673f990a21f74630-sdc9n requesting resource cpu=0m on Node vm119044
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1902498d-ce72-4da0-b69a-c772967b716b.17107852a0e5f60e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3242/filler-pod-1902498d-ce72-4da0-b69a-c772967b716b to vm119044]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1902498d-ce72-4da0-b69a-c772967b716b.17107852c3b05769], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1902498d-ce72-4da0-b69a-c772967b716b.17107852c5e2aa41], Reason = [Created], Message = [Created container filler-pod-1902498d-ce72-4da0-b69a-c772967b716b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1902498d-ce72-4da0-b69a-c772967b716b.17107852cac34c1f], Reason = [Started], Message = [Started container filler-pod-1902498d-ce72-4da0-b69a-c772967b716b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1.17107852a1ff5101], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3242/filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1 to vm119041]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1.17107852c3e1b464], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1.17107852c72aca21], Reason = [Created], Message = [Created container filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1.17107852cc528b45], Reason = [Started], Message = [Started container filler-pod-1b2409e3-b5fb-45a2-b77b-7108421bd3e1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e.171078529d277e60], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3242/filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e to vm119042]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e.17107852bde61fb4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e.17107852c04e5fa5], Reason = [Created], Message = [Created container filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e.17107852c6c547cd], Reason = [Started], Message = [Started container filler-pod-bbcccbaa-ccc4-47db-9794-21462809a29e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b.171078529e87dcb3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3242/filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b to vm119043]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b.17107852bef972f5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b.17107852c1741621], Reason = [Created], Message = [Created container filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b.17107852c6ecced9], Reason = [Started], Message = [Started container filler-pod-f4bf5270-8afb-4ef4-9cea-8ea615791e1b]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17107853195a7779], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu.]
STEP: removing the label node off the node vm119041
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vm119042
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vm119043
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node vm119044
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:42:41.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3242" for this suite.
Aug 31 15:42:47.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:42:47.922: INFO: namespace sched-pred-3242 deletion completed in 6.064274451s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.327 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:42:47.923: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9667/configmap-test-f158d0e8-2f4d-4528-a192-77de59a36800
STEP: Creating a pod to test consume configMaps
Aug 31 15:42:47.952: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada" in namespace "configmap-9667" to be "success or failure"
Aug 31 15:42:47.956: INFO: Pod "pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada": Phase="Pending", Reason="", readiness=false. Elapsed: 3.678136ms
Aug 31 15:42:49.959: INFO: Pod "pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007182955s
STEP: Saw pod success
Aug 31 15:42:49.959: INFO: Pod "pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada" satisfied condition "success or failure"
Aug 31 15:42:49.963: INFO: Trying to get logs from node vm119042 pod pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada container env-test: <nil>
STEP: delete the pod
Aug 31 15:42:49.978: INFO: Waiting for pod pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada to disappear
Aug 31 15:42:49.980: INFO: Pod pod-configmaps-8e8eb77b-b67e-44cb-967e-b9b04b3eeada no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:42:49.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9667" for this suite.
Aug 31 15:42:55.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:42:56.050: INFO: namespace configmap-9667 deletion completed in 6.066761598s

• [SLOW TEST:8.127 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:42:56.051: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:42:56.069: INFO: Creating deployment "nginx-deployment"
Aug 31 15:42:56.074: INFO: Waiting for observed generation 1
Aug 31 15:42:58.078: INFO: Waiting for all required pods to come up
Aug 31 15:42:58.081: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug 31 15:43:00.092: INFO: Waiting for deployment "nginx-deployment" to complete
Aug 31 15:43:00.096: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug 31 15:43:00.104: INFO: Updating deployment nginx-deployment
Aug 31 15:43:00.104: INFO: Waiting for observed generation 2
Aug 31 15:43:02.114: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug 31 15:43:02.117: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug 31 15:43:02.119: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 31 15:43:02.125: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug 31 15:43:02.125: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug 31 15:43:02.128: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug 31 15:43:02.132: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug 31 15:43:02.132: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug 31 15:43:02.138: INFO: Updating deployment nginx-deployment
Aug 31 15:43:02.138: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug 31 15:43:02.142: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug 31 15:43:02.144: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug 31 15:43:04.155: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3509,SelfLink:/apis/apps/v1/namespaces/deployment-3509/deployments/nginx-deployment,UID:0250e456-29e2-497e-90b2-105438e846b0,ResourceVersion:44294,Generation:3,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2022-08-31 15:43:02 +0000 UTC 2022-08-31 15:43:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2022-08-31 15:43:02 +0000 UTC 2022-08-31 15:42:56 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug 31 15:43:04.158: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-3509,SelfLink:/apis/apps/v1/namespaces/deployment-3509/replicasets/nginx-deployment-55fb7cb77f,UID:122a9223-67f1-4f1b-8d93-2a7600937c16,ResourceVersion:44289,Generation:3,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0250e456-29e2-497e-90b2-105438e846b0 0xc0036f26c7 0xc0036f26c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug 31 15:43:04.158: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug 31 15:43:04.158: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-3509,SelfLink:/apis/apps/v1/namespaces/deployment-3509/replicasets/nginx-deployment-7b8c6f4498,UID:adfc5aac-8031-4a5f-9170-631f0d9b7745,ResourceVersion:44273,Generation:3,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0250e456-29e2-497e-90b2-105438e846b0 0xc0036f2797 0xc0036f2798}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-2rgxk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2rgxk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-2rgxk,UID:90fb4981-bf44-4083-b551-72ca13dce7f6,ResourceVersion:44284,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3137 0xc0036f3138}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f31b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f31d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-5wxch" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5wxch,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-5wxch,UID:fa6ca575-d0c4-4b2a-9199-ecb5b8ebe0df,ResourceVersion:44201,Generation:0,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f32a0 0xc0036f32a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:,StartTime:2022-08-31 15:43:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-8rk9g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8rk9g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-8rk9g,UID:aa2391a3-8a67-4f2b-8eca-48cb50a5bff6,ResourceVersion:44173,Generation:0,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3410 0xc0036f3411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f34b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-chxss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-chxss,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-chxss,UID:50f1c89a-58b2-48c6-afc9-a4fac394d77d,ResourceVersion:44203,Generation:0,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3580 0xc0036f3581}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-fj8st" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fj8st,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-fj8st,UID:203bd041-0ee3-41a0-8ca8-a43e403781a1,ResourceVersion:44181,Generation:0,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3700 0xc0036f3701}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3780} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f37a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:,StartTime:2022-08-31 15:43:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-fxsth" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-fxsth,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-fxsth,UID:d56bc610-6904-483b-847b-ff9adc8f8ef0,ResourceVersion:44307,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3870 0xc0036f3871}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f38f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-hqqwt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hqqwt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-hqqwt,UID:787e3586-ba89-4e68-b2aa-bc4b1a861ba8,ResourceVersion:44309,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f39e0 0xc0036f39e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3a60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3a80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-hr6vm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hr6vm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-hr6vm,UID:ab369b51-1bd9-4794-9440-7bcf9805f311,ResourceVersion:44306,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3b50 0xc0036f3b51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3bf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-pdvf2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-pdvf2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-pdvf2,UID:dae772be-d759-4fa1-86ce-a3ee58a03db1,ResourceVersion:44286,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3cc0 0xc0036f3cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-q5p6f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q5p6f,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-q5p6f,UID:4cb8d4ea-23f3-4615-af1a-ec54f16f7820,ResourceVersion:44292,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3e30 0xc0036f3e31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0036f3eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0036f3ed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.164: INFO: Pod "nginx-deployment-55fb7cb77f-qjr2s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qjr2s,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-qjr2s,UID:74f26652-4ec2-4be3-b0bb-f397123eeb26,ResourceVersion:44299,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc0036f3fa0 0xc0036f3fa1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-55fb7cb77f-sdnhq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sdnhq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-sdnhq,UID:a9f6324e-0269-4afd-bd90-2983a690e636,ResourceVersion:44318,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc00392a110 0xc00392a111}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a1b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-55fb7cb77f-ss5rp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ss5rp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-55fb7cb77f-ss5rp,UID:62063748-55a8-448b-ac90-2442a1516a87,ResourceVersion:44182,Generation:0,CreationTimestamp:2022-08-31 15:43:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 122a9223-67f1-4f1b-8d93-2a7600937c16 0xc00392a280 0xc00392a281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:00 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-2nnlh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2nnlh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-2nnlh,UID:2e386926-2765-4510-b67f-84c8b3c4a8b6,ResourceVersion:44148,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392a530 0xc00392a531}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a5a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a5c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:10.244.1.105,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ed64d740baf641093d873045dd482a2c92b99034bc7c9461ce495a51b4a58467}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-5x7h2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5x7h2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-5x7h2,UID:e8f2da31-7b10-447b-8ab8-653831adccaa,ResourceVersion:44138,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392a697 0xc00392a698}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a710} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a730}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:10.244.0.97,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c9183e665f68a1b2a06cb7a55c2a8a2a9d606fa51bf1ec9009f963db91d315cf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-6hr7b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6hr7b,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-6hr7b,UID:4fab7614-1feb-4eca-8d2e-fa60b3291d1e,ResourceVersion:44285,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392a800 0xc00392a801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-6m5bn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6m5bn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-6m5bn,UID:86dda36b-9996-4b35-b327-0c0f2e19aa93,ResourceVersion:44109,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392a957 0xc00392a958}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392a9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392a9f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:10.244.3.165,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2a510e5c45908b2bd04910ee4ee42b7b1d289014ec47f55729599e4782a0eb29}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-7574h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7574h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-7574h,UID:d5584273-3356-4353-8503-ecf192603c0b,ResourceVersion:44104,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392aac7 0xc00392aac8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392ab40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392ab60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:10.244.3.166,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0370fa4ae61750a75381a7e08dc5cbf046e798586b18d98f8b9f9cd1937067b4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-982zx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-982zx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-982zx,UID:19376080-875f-4ac5-ba17-65b7e8cfadea,ResourceVersion:44241,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392ac37 0xc00392ac38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392acb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392acd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-cldwg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cldwg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-cldwg,UID:dea949ae-7adb-42f1-9c44-4e684207c025,ResourceVersion:44304,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392ad97 0xc00392ad98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392ae10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392ae30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-gl2xm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gl2xm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-gl2xm,UID:62876430-38fb-463d-8f44-b7d12b8e02c2,ResourceVersion:44151,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392aef7 0xc00392aef8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392af70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392af90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:10.244.1.104,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://00e19a74c9f31632158bb99e0d107a8deadf487c2bba35cd3f22cbd065d26dfb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.165: INFO: Pod "nginx-deployment-7b8c6f4498-jrc55" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jrc55,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-jrc55,UID:dc3fe995-ff5f-44a6-bf45-c62cc6c94f47,ResourceVersion:44296,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b067 0xc00392b068}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-qhkwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qhkwr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-qhkwr,UID:310b001d-2050-4fcf-a39b-8bb706ed6765,ResourceVersion:44312,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b1c7 0xc00392b1c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-qlbsw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qlbsw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-qlbsw,UID:d1fe0f8f-e9f0-4f86-9256-154b3fae9893,ResourceVersion:44142,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b327 0xc00392b328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b3c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:10.244.0.98,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:58 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9d0107c963a0732616b5cb27773e4fd1822e7a18d0166dce0a3c2fdbf00a03b2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-rlxgf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rlxgf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-rlxgf,UID:e7af98f4-3e1a-4a80-b31e-de4584ee2041,ResourceVersion:44141,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b490 0xc00392b491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:10.244.2.91,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ef7ff801b0be438d644a337524518e284ec254b5554f149f99b4f93a8d9e760b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-rpwf8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rpwf8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-rpwf8,UID:31234983-b4cb-43bb-aef8-555328d696db,ResourceVersion:44300,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b5f0 0xc00392b5f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-rwzgk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rwzgk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-rwzgk,UID:86d3b3e7-cfaf-4597-8777-5cb409944db2,ResourceVersion:44106,Generation:0,CreationTimestamp:2022-08-31 15:42:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b747 0xc00392b748}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b7c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b7e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:42:56 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:10.244.3.164,StartTime:2022-08-31 15:42:56 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2022-08-31 15:42:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f65b00999ab454741c2d4477f0b7dce0d09aa40f3de2bd07c502b889e4cdcb24}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-snx5m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-snx5m,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-snx5m,UID:0ca84738-84be-4901-b558-437e4b5b4edd,ResourceVersion:44316,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392b8b7 0xc00392b8b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392b930} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392b950}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-vdz58" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vdz58,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-vdz58,UID:994fb164-512f-4a1c-8561-c3fb177d7bdc,ResourceVersion:44279,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392ba17 0xc00392ba18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119044,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392ba90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392bab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.44,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-w7zc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-w7zc6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-w7zc6,UID:05466869-7dd8-405d-b107-110ee5536ea9,ResourceVersion:44262,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392bb77 0xc00392bb78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392bbf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392bc10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-wrqg4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-wrqg4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-wrqg4,UID:31d45eff-2ed8-40b7-bde4-c6a3a6ad5096,ResourceVersion:44298,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392bcd7 0xc00392bcd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119042,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392bd50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392bd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.42,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.166: INFO: Pod "nginx-deployment-7b8c6f4498-xngxq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xngxq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-xngxq,UID:edee6f3b-4f03-41dc-91fd-f8b5a9d071a0,ResourceVersion:44261,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392be37 0xc00392be38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119041,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00392beb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00392bed0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.41,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug 31 15:43:04.167: INFO: Pod "nginx-deployment-7b8c6f4498-xvkj4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xvkj4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3509,SelfLink:/api/v1/namespaces/deployment-3509/pods/nginx-deployment-7b8c6f4498-xvkj4,UID:1ec901cf-176d-4205-b04a-788a8fd6ffe7,ResourceVersion:44263,Generation:0,CreationTimestamp:2022-08-31 15:43:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 adfc5aac-8031-4a5f-9170-631f0d9b7745 0xc00392bf97 0xc00392bf98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqmv8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqmv8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqmv8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:vm119043,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002f5c020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002f5c040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-08-31 15:43:02 +0000 UTC  }],Message:,Reason:,HostIP:192.168.119.43,PodIP:,StartTime:2022-08-31 15:43:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:43:04.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3509" for this suite.
Aug 31 15:43:12.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:43:12.249: INFO: namespace deployment-3509 deletion completed in 8.071563848s

• [SLOW TEST:16.198 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:43:12.250: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-s28j
STEP: Creating a pod to test atomic-volume-subpath
Aug 31 15:43:12.282: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-s28j" in namespace "subpath-7228" to be "success or failure"
Aug 31 15:43:12.287: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Pending", Reason="", readiness=false. Elapsed: 5.502849ms
Aug 31 15:43:14.291: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 2.009089898s
Aug 31 15:43:16.294: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 4.01198848s
Aug 31 15:43:18.297: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 6.015266353s
Aug 31 15:43:20.300: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 8.01816124s
Aug 31 15:43:22.303: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 10.021416513s
Aug 31 15:43:24.307: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 12.025547197s
Aug 31 15:43:26.311: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 14.028894912s
Aug 31 15:43:28.314: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 16.031987987s
Aug 31 15:43:30.318: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 18.035735498s
Aug 31 15:43:32.321: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Running", Reason="", readiness=true. Elapsed: 20.039118331s
Aug 31 15:43:34.324: INFO: Pod "pod-subpath-test-configmap-s28j": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.042237375s
STEP: Saw pod success
Aug 31 15:43:34.324: INFO: Pod "pod-subpath-test-configmap-s28j" satisfied condition "success or failure"
Aug 31 15:43:34.327: INFO: Trying to get logs from node vm119042 pod pod-subpath-test-configmap-s28j container test-container-subpath-configmap-s28j: <nil>
STEP: delete the pod
Aug 31 15:43:34.342: INFO: Waiting for pod pod-subpath-test-configmap-s28j to disappear
Aug 31 15:43:34.345: INFO: Pod pod-subpath-test-configmap-s28j no longer exists
STEP: Deleting pod pod-subpath-test-configmap-s28j
Aug 31 15:43:34.345: INFO: Deleting pod "pod-subpath-test-configmap-s28j" in namespace "subpath-7228"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:43:34.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7228" for this suite.
Aug 31 15:43:40.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:43:40.415: INFO: namespace subpath-7228 deletion completed in 6.064692321s

• [SLOW TEST:28.165 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:43:40.415: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 31 15:43:40.442: INFO: Waiting up to 5m0s for pod "pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578" in namespace "emptydir-133" to be "success or failure"
Aug 31 15:43:40.445: INFO: Pod "pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578": Phase="Pending", Reason="", readiness=false. Elapsed: 3.034001ms
Aug 31 15:43:42.448: INFO: Pod "pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005922055s
STEP: Saw pod success
Aug 31 15:43:42.448: INFO: Pod "pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578" satisfied condition "success or failure"
Aug 31 15:43:42.450: INFO: Trying to get logs from node vm119042 pod pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578 container test-container: <nil>
STEP: delete the pod
Aug 31 15:43:42.462: INFO: Waiting for pod pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578 to disappear
Aug 31 15:43:42.464: INFO: Pod pod-22d972a9-6d57-4ac9-b59d-cb6ff68c8578 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:43:42.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-133" for this suite.
Aug 31 15:43:48.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:43:48.534: INFO: namespace emptydir-133 deletion completed in 6.067329577s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:43:48.535: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:43:50.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8050" for this suite.
Aug 31 15:43:56.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:43:56.664: INFO: namespace emptydir-wrapper-8050 deletion completed in 6.064188009s

• [SLOW TEST:8.129 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:43:56.665: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Aug 31 15:44:06.736: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:44:06.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0831 15:44:06.736789      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4875" for this suite.
Aug 31 15:44:12.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:44:12.813: INFO: namespace gc-4875 deletion completed in 6.07269514s

• [SLOW TEST:16.149 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:44:12.814: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-5afe11e9-ad05-43de-9194-5c6a69edcc51 in namespace container-probe-4612
Aug 31 15:44:14.899: INFO: Started pod liveness-5afe11e9-ad05-43de-9194-5c6a69edcc51 in namespace container-probe-4612
STEP: checking the pod's current state and verifying that restartCount is present
Aug 31 15:44:14.902: INFO: Initial restart count of pod liveness-5afe11e9-ad05-43de-9194-5c6a69edcc51 is 0
Aug 31 15:44:32.941: INFO: Restart count of pod container-probe-4612/liveness-5afe11e9-ad05-43de-9194-5c6a69edcc51 is now 1 (18.038428029s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:44:32.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4612" for this suite.
Aug 31 15:44:38.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:44:39.024: INFO: namespace container-probe-4612 deletion completed in 6.069022693s

• [SLOW TEST:26.210 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:44:39.024: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-924fc982-f4e4-48a4-8625-7b88378b8e4f
STEP: Creating secret with name secret-projected-all-test-volume-4310dcd4-abc6-41b1-b287-f7c63c0d4312
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug 31 15:44:39.055: INFO: Waiting up to 5m0s for pod "projected-volume-8ff66d88-1664-4206-89dc-991bff515318" in namespace "projected-7273" to be "success or failure"
Aug 31 15:44:39.060: INFO: Pod "projected-volume-8ff66d88-1664-4206-89dc-991bff515318": Phase="Pending", Reason="", readiness=false. Elapsed: 4.699113ms
Aug 31 15:44:41.063: INFO: Pod "projected-volume-8ff66d88-1664-4206-89dc-991bff515318": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007941489s
STEP: Saw pod success
Aug 31 15:44:41.063: INFO: Pod "projected-volume-8ff66d88-1664-4206-89dc-991bff515318" satisfied condition "success or failure"
Aug 31 15:44:41.065: INFO: Trying to get logs from node vm119042 pod projected-volume-8ff66d88-1664-4206-89dc-991bff515318 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug 31 15:44:41.081: INFO: Waiting for pod projected-volume-8ff66d88-1664-4206-89dc-991bff515318 to disappear
Aug 31 15:44:41.084: INFO: Pod projected-volume-8ff66d88-1664-4206-89dc-991bff515318 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:44:41.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7273" for this suite.
Aug 31 15:44:47.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:44:47.153: INFO: namespace projected-7273 deletion completed in 6.065443599s

• [SLOW TEST:8.129 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:44:47.154: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9369.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9369.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9369.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9369.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9369.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9369.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug 31 15:44:49.204: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:49.207: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:49.215: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:49.217: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:49.217: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:44:54.227: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:54.231: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:54.239: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:54.243: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:54.243: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:44:59.227: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:59.229: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:59.239: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:59.241: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:44:59.243: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:45:04.227: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:04.230: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:04.239: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:04.242: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:04.242: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:45:09.227: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:09.231: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:09.239: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:09.241: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:09.241: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:45:14.227: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:14.230: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:14.239: INFO: Unable to read jessie_udp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:14.241: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3: the server could not find the requested resource (get pods dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3)
Aug 31 15:45:14.241: INFO: Lookups using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Aug 31 15:45:19.239: INFO: DNS probes using dns-9369/dns-test-f4790402-e742-42cf-a389-ed4867a8bfd3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:45:19.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9369" for this suite.
Aug 31 15:45:25.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:45:25.331: INFO: namespace dns-9369 deletion completed in 6.075402255s

• [SLOW TEST:38.178 seconds]
[sig-network] DNS
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:45:25.332: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:45:30.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6894" for this suite.
Aug 31 15:45:36.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:45:37.045: INFO: namespace watch-6894 deletion completed in 6.156621417s

• [SLOW TEST:11.713 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:45:37.046: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug 31 15:45:37.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-059459328 version'
Aug 31 15:45:37.111: INFO: stderr: ""
Aug 31 15:45:37.111: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.12\", GitCommit:\"e2a822d9f3c2fdb5c9bfbe64313cf9f657f0a725\", GitTreeState:\"clean\", BuildDate:\"2020-05-06T05:17:59Z\", GoVersion:\"go1.12.17\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.12\", GitCommit:\"e2a822d9f3c2fdb5c9bfbe64313cf9f657f0a725\", GitTreeState:\"clean\", BuildDate:\"2020-05-06T05:09:48Z\", GoVersion:\"go1.12.17\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:45:37.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8279" for this suite.
Aug 31 15:45:43.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:45:43.183: INFO: namespace kubectl-8279 deletion completed in 6.066959334s

• [SLOW TEST:6.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:45:43.186: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug 31 15:45:43.210: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:45:46.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3714" for this suite.
Aug 31 15:45:52.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:45:52.092: INFO: namespace init-container-3714 deletion completed in 6.074940739s

• [SLOW TEST:8.906 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:45:52.092: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug 31 15:45:52.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1" in namespace "projected-3237" to be "success or failure"
Aug 31 15:45:52.124: INFO: Pod "downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.59654ms
Aug 31 15:45:54.127: INFO: Pod "downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005966994s
STEP: Saw pod success
Aug 31 15:45:54.127: INFO: Pod "downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1" satisfied condition "success or failure"
Aug 31 15:45:54.129: INFO: Trying to get logs from node vm119042 pod downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1 container client-container: <nil>
STEP: delete the pod
Aug 31 15:45:54.144: INFO: Waiting for pod downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1 to disappear
Aug 31 15:45:54.146: INFO: Pod downwardapi-volume-e05ab293-480c-42d2-807e-3fcbff16eac1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:45:54.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3237" for this suite.
Aug 31 15:46:00.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:46:00.232: INFO: namespace projected-3237 deletion completed in 6.082650556s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:46:00.234: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug 31 15:46:00.290: INFO: Waiting up to 5m0s for pod "pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816" in namespace "emptydir-1462" to be "success or failure"
Aug 31 15:46:00.294: INFO: Pod "pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40796ms
Aug 31 15:46:02.298: INFO: Pod "pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008286457s
STEP: Saw pod success
Aug 31 15:46:02.298: INFO: Pod "pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816" satisfied condition "success or failure"
Aug 31 15:46:02.301: INFO: Trying to get logs from node vm119042 pod pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816 container test-container: <nil>
STEP: delete the pod
Aug 31 15:46:02.322: INFO: Waiting for pod pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816 to disappear
Aug 31 15:46:02.327: INFO: Pod pod-b76ee844-82a2-4a29-accf-5e1a3c2bd816 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:46:02.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1462" for this suite.
Aug 31 15:46:08.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:46:08.423: INFO: namespace emptydir-1462 deletion completed in 6.085508895s

• [SLOW TEST:8.189 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:46:08.425: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug 31 15:46:10.980: INFO: Successfully updated pod "labelsupdatec33ee4de-1c5b-4d2b-bc77-7a2b3bbf1911"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:46:15.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8498" for this suite.
Aug 31 15:46:37.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:46:37.086: INFO: namespace downward-api-8498 deletion completed in 22.071765115s

• [SLOW TEST:28.661 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug 31 15:46:37.087: INFO: >>> kubeConfig: /tmp/kubeconfig-059459328
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-97b183cc-d6ef-481b-becf-6204838741da in namespace container-probe-6312
Aug 31 15:46:39.123: INFO: Started pod busybox-97b183cc-d6ef-481b-becf-6204838741da in namespace container-probe-6312
STEP: checking the pod's current state and verifying that restartCount is present
Aug 31 15:46:39.124: INFO: Initial restart count of pod busybox-97b183cc-d6ef-481b-becf-6204838741da is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug 31 15:50:39.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6312" for this suite.
Aug 31 15:50:45.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug 31 15:50:45.640: INFO: namespace container-probe-6312 deletion completed in 6.07954827s

• [SLOW TEST:248.553 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.12-beta.0.35+d69e6d58f41274/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSAug 31 15:50:45.640: INFO: Running AfterSuite actions on all nodes
Aug 31 15:50:45.640: INFO: Running AfterSuite actions on node 1
Aug 31 15:50:45.640: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5387.781 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h29m48.531966768s
Test Suite Passed
